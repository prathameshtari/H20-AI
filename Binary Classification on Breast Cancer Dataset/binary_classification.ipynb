{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "import random, os, sys\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import logging\n",
    "import csv\n",
    "import optparse\n",
    "import time\n",
    "import json\n",
    "from distutils.util import strtobool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path=None\n",
    "all_variables=None\n",
    "test_path=None\n",
    "target=None\n",
    "nthreads=1 \n",
    "min_mem_size=6 \n",
    "run_time=333\n",
    "classification=False\n",
    "scale=False\n",
    "max_models=9    \n",
    "model_path=None\n",
    "balance_y=False \n",
    "balance_threshold=0.2\n",
    "name=None \n",
    "server_path=None  \n",
    "analysis=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "def alphabet(n):\n",
    "  alpha='0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'    \n",
    "  str=''\n",
    "  r=len(alpha)-1   \n",
    "  while len(str)<n:\n",
    "    i=random.randint(0,r)\n",
    "    str+=alpha[i]   \n",
    "  return str\n",
    "  \n",
    "  \n",
    "def set_meta_data(run_id,analysis,target,run_time,classification,scale,model,balance,balance_threshold,name,nthreads,min_mem_size):\n",
    "  m_data={}\n",
    "  m_data['run_id'] =run_id\n",
    "  m_data['start_time'] = time.time()\n",
    "  m_data['target']=target\n",
    "  m_data['max_models']=model\n",
    "  m_data['run_time']=run_time\n",
    "  m_data['scale']=scale\n",
    "  m_data['classification']=classification\n",
    "  m_data['scale']=False\n",
    "  m_data['balance']=balance\n",
    "  m_data['balance_threshold']=balance_threshold\n",
    "  m_data['project'] =name\n",
    "  m_data['end_time'] = time.time()\n",
    "  m_data['execution_time'] = 0.0\n",
    "  m_data['nthreads'] = nthreads\n",
    "  m_data['min_mem_size'] = min_mem_size\n",
    "  m_data['analysis'] = analysis\n",
    "  return m_data\n",
    "\n",
    "\n",
    "def dict_to_json(dct,n):\n",
    "  j = json.dumps(dct, indent=4)\n",
    "  f = open(n, 'w')\n",
    "  print(j, file=f)\n",
    "  f.close()\n",
    "  \n",
    "  \n",
    "def stackedensemble(mod):\n",
    "    coef_norm=None\n",
    "    try:\n",
    "      metalearner = h2o.get_model(mod.metalearner()['name'])\n",
    "      coef_norm=metalearner.coef_norm()\n",
    "    except:\n",
    "      pass        \n",
    "    return coef_norm\n",
    "\n",
    "def stackedensemble_df(df):\n",
    "    bm_algo={ 'GBM': None,'GLM': None,'DRF': None,'XRT': None,'Dee': None}\n",
    "    for index, row in df.iterrows():\n",
    "      if len(row['model_id'])>3:\n",
    "        key=row['model_id'][0:3]\n",
    "        if key in bm_algo:\n",
    "          if bm_algo[key] is None:\n",
    "                bm_algo[key]=row['model_id']\n",
    "    bm=list(bm_algo.values()) \n",
    "    bm=list(filter(None.__ne__, bm))             \n",
    "    return bm\n",
    "\n",
    "def se_stats(modl):\n",
    "    d={}\n",
    "    d['algo']=modl.algo\n",
    "    d['model_id']=modl.model_id   \n",
    "    d['auc']=modl.auc()   \n",
    "    d['roc']=modl.roc()\n",
    "    d['mse']=modl.mse()   \n",
    "    d['null_degrees_of_freedom']=modl.null_degrees_of_freedom()\n",
    "    d['null_deviance']=modl.null_deviance()\n",
    "    d['residual_degrees_of_freedom']=modl.residual_degrees_of_freedom()   \n",
    "    d['residual_deviance']=modl.residual_deviance()\n",
    "    d['rmse']=modl.rmse()\n",
    "    return d\n",
    "\n",
    "def get_model_by_algo(algo,models_dict):\n",
    "    mod=None\n",
    "    mod_id=None    \n",
    "    for m in list(models_dict.keys()):\n",
    "        if m[0:3]==algo:\n",
    "            mod_id=m\n",
    "            mod=h2o.get_model(m)      \n",
    "    return mod,mod_id     \n",
    "    \n",
    "    \n",
    "def gbm_stats(modl):\n",
    "    d={}\n",
    "    d['algo']=modl.algo\n",
    "    d['model_id']=modl.model_id   \n",
    "    d['varimp']=modl.varimp()  \n",
    "    return d\n",
    "    \n",
    "    \n",
    "def dl_stats(modl):\n",
    "    d={}\n",
    "    d['algo']=modl.algo\n",
    "    d['model_id']=modl.model_id   \n",
    "    d['varimp']=modl.varimp()  \n",
    "    return d\n",
    "    \n",
    "    \n",
    "def drf_stats(modl):\n",
    "    d={}\n",
    "    d['algo']=modl.algo\n",
    "    d['model_id']=modl.model_id   \n",
    "    d['varimp']=modl.varimp()  \n",
    "    d['roc']=modl.roc()      \n",
    "    return d\n",
    "    \n",
    "def xrt_stats(modl):\n",
    "    d={}\n",
    "    d['algo']=modl.algo\n",
    "    d['model_id']=modl.model_id   \n",
    "    d['varimp']=modl.varimp()  \n",
    "    d['roc']=modl.roc()      \n",
    "    return d\n",
    "    \n",
    "    \n",
    "def glm_stats(modl):\n",
    "    d={}\n",
    "    d['algo']=modl.algo\n",
    "    d['model_id']=modl.model_id   \n",
    "    d['coef']=modl.coef()  \n",
    "    d['coef_norm']=modl.coef_norm()      \n",
    "    return d\n",
    "    \n",
    "def model_performance_stats(perf):\n",
    "    d={}\n",
    "    try:    \n",
    "      d['mse']=perf.mse()\n",
    "    except:\n",
    "      pass      \n",
    "    try:    \n",
    "      d['rmse']=perf.rmse() \n",
    "    except:\n",
    "      pass      \n",
    "    try:    \n",
    "      d['null_degrees_of_freedom']=perf.null_degrees_of_freedom()\n",
    "    except:\n",
    "      pass      \n",
    "    try:    \n",
    "      d['residual_degrees_of_freedom']=perf.residual_degrees_of_freedom()\n",
    "    except:\n",
    "      pass      \n",
    "    try:    \n",
    "      d['residual_deviance']=perf.residual_deviance() \n",
    "    except:\n",
    "      pass      \n",
    "    try:    \n",
    "      d['null_deviance']=perf.null_deviance() \n",
    "    except:\n",
    "      pass      \n",
    "    try:    \n",
    "      d['aic']=perf.aic() \n",
    "    except:\n",
    "      pass      \n",
    "    try:\n",
    "      d['logloss']=perf.logloss() \n",
    "    except:\n",
    "      pass    \n",
    "    try:\n",
    "      d['auc']=perf.auc()\n",
    "    except:\n",
    "      pass  \n",
    "    try:\n",
    "      d['gini']=perf.gini()\n",
    "    except:\n",
    "      pass    \n",
    "    return d\n",
    "    \n",
    "def impute_missing_values(df, x, scal=False):\n",
    "    # determine column types\n",
    "    ints, reals, enums = [], [], []\n",
    "    for key, val in df.types.items():\n",
    "        if key in x:\n",
    "            if val == 'enum':\n",
    "                enums.append(key)\n",
    "            elif val == 'int':\n",
    "                ints.append(key)            \n",
    "            else: \n",
    "                reals.append(key)    \n",
    "    _ = df[reals].impute(method='mean')\n",
    "    _ = df[ints].impute(method='median')\n",
    "    if scal:\n",
    "        df[reals] = df[reals].scale()\n",
    "        df[ints] = df[ints].scale()    \n",
    "    return\n",
    "\n",
    "\n",
    "def get_independent_variables(df, targ):\n",
    "    C = [name for name in df.columns if name != targ]\n",
    "    # determine column types\n",
    "    ints, reals, enums = [], [], []\n",
    "    for key, val in df.types.items():\n",
    "        if key in C:\n",
    "            if val == 'enum':\n",
    "                enums.append(key)\n",
    "            elif val == 'int':\n",
    "                ints.append(key)            \n",
    "            else: \n",
    "                reals.append(key)    \n",
    "    x=ints+enums+reals\n",
    "    return x\n",
    "    \n",
    "def get_all_variables_csv(i):\n",
    "    ivd={}\n",
    "    try:\n",
    "      iv = pd.read_csv(i,header=None)\n",
    "    except:\n",
    "      sys.exit(1)    \n",
    "    col=iv.values.tolist()[0]\n",
    "    dt=iv.values.tolist()[1]\n",
    "    i=0\n",
    "    for c in col:\n",
    "      ivd[c.strip()]=dt[i].strip()\n",
    "      i+=1        \n",
    "    return ivd\n",
    "    \n",
    "    \n",
    "\n",
    "def check_all_variables(df,dct,y=None):     \n",
    "    targ=list(dct.keys())     \n",
    "    for key, val in df.types.items():\n",
    "        if key in targ:\n",
    "          if dct[key] not in ['real','int','enum']:                      \n",
    "            targ.remove(key)  \n",
    "    for key, val in df.types.items():\n",
    "        if key in targ:            \n",
    "          if dct[key] != val:\n",
    "            print('convert ',key,' ',dct[key],' ',val)\n",
    "            if dct[key]=='enum':\n",
    "                try:\n",
    "                  df[key] = df[key].asfactor() \n",
    "                except:\n",
    "                  targ.remove(key)                 \n",
    "            if dct[key]=='int': \n",
    "                try:                \n",
    "                  df[key] = df[key].asnumeric() \n",
    "                except:\n",
    "                  targ.remove(key)                  \n",
    "            if dct[key]=='real':\n",
    "                try:                \n",
    "                  df[key] = df[key].asnumeric()  \n",
    "                except:\n",
    "                  targ.remove(key)                  \n",
    "    if y is None:\n",
    "      y=df.columns[-1] \n",
    "    if y in targ:\n",
    "      targ.remove(y)\n",
    "    else:\n",
    "      y=targ.pop()            \n",
    "    return targ    \n",
    "    \n",
    "def predictions(mod,data,run_id):\n",
    "    test = h2o.import_file(data)\n",
    "    mod_perf=mod_best.model_performance(test)\n",
    "              \n",
    "    stats_test={}\n",
    "    stats_test=model_performance_stats(mod_perf)\n",
    "\n",
    "    n=run_id+'_test_stats.json'\n",
    "    dict_to_json(stats_test,n) \n",
    "\n",
    "    try:    \n",
    "      cf=mod_perf.confusion_matrix(metrics=[\"f1\",\"f2\",\"f0point5\",\"accuracy\",\"precision\",\"recall\",\"specificity\",\"absolute_mcc\",\"min_per_class_accuracy\",\"mean_per_class_accuracy\"])\n",
    "      cf_df=cf[0].table.as_data_frame()\n",
    "      cf_df.to_csv(run_id+'_test_confusion_matrix.csv')\n",
    "    except:\n",
    "      pass\n",
    "\n",
    "    predictions = mod_best.predict(test)\n",
    "    predictions_df=test.cbind(predictions).as_data_frame() \n",
    "    predictions_df.to_csv(run_id+'_predictions.csv')\n",
    "    return\n",
    "\n",
    "def predictions_test(mod,test,run_id):\n",
    "    mod_perf=mod_best.model_performance(test)          \n",
    "    stats_test={}\n",
    "    stats_test=model_performance_stats(mod_perf)\n",
    "    n=run_id+'_test_stats.json'\n",
    "    dict_to_json(stats_test,n) \n",
    "    try:\n",
    "      cf=mod_perf.confusion_matrix(metrics=[\"f1\",\"f2\",\"f0point5\",\"accuracy\",\"precision\",\"recall\",\"specificity\",\"absolute_mcc\",\"min_per_class_accuracy\",\"mean_per_class_accuracy\"])\n",
    "      cf_df=cf[0].table.as_data_frame()\n",
    "      cf_df.to_csv(run_id+'_test_confusion_matrix.csv')\n",
    "    except:\n",
    "      pass\n",
    "    predictions = mod_best.predict(test)    \n",
    "    predictions_df=test.cbind(predictions).as_data_frame() \n",
    "    predictions_df.to_csv(run_id+'_predictions.csv')\n",
    "    return predictions\n",
    "\n",
    "def check_X(x,df):\n",
    "    for name in x:\n",
    "        if name not in df.columns:\n",
    "          x.remove(name)  \n",
    "    return x    \n",
    "    \n",
    "    \n",
    "def get_stacked_ensemble(lst):\n",
    "    se=None\n",
    "    for model in model_set:\n",
    "      if 'BestOfFamily' in model:\n",
    "        se=model\n",
    "    if se is None:     \n",
    "      for model in model_set:\n",
    "        if 'AllModels'in model:\n",
    "          se=model           \n",
    "    return se       \n",
    "    \n",
    "def get_variables_types(df):\n",
    "    d={}\n",
    "    for key, val in df.types.items():\n",
    "        d[key]=val           \n",
    "    return d    \n",
    "    \n",
    "#  End Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Plotting Confusion Matrix\n",
    "def print_confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14):\n",
    "    \"\"\"Prints a confusion matrix, as returned by sklearn.metrics.confusion_matrix, as a heatmap.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    confusion_matrix: numpy.ndarray\n",
    "        The numpy.ndarray object returned from a call to sklearn.metrics.confusion_matrix. \n",
    "        Similarly constructed ndarrays can also be used.\n",
    "    class_names: list\n",
    "        An ordered list of class names, in the order they index the given confusion matrix.\n",
    "    figsize: tuple\n",
    "        A 2-long tuple, the first value determining the horizontal size of the ouputted figure,\n",
    "        the second determining the vertical size. Defaults to (10,7).\n",
    "    fontsize: int\n",
    "        Font size for axes labels. Defaults to 14.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.figure.Figure\n",
    "        The resulting confusion matrix figure\n",
    "    \"\"\"\n",
    "    df_cm = pd.DataFrame(\n",
    "        confusion_matrix, index=class_names, columns=class_names, \n",
    "    )\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    plt.ylabel('True Values')\n",
    "    plt.xlabel('Predicted Values')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path='breast_cancer.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = os.path.join(os.path.abspath(os.curdir),data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_variables=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31NZIQ11j\n"
     ]
    }
   ],
   "source": [
    "run_id=alphabet(9)\n",
    "# run_id to std out\n",
    "print (run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "server_path=os.path.abspath(os.curdir)\n",
    "os.chdir(server_path) \n",
    "run_dir = os.path.join(server_path,run_id)\n",
    "os.mkdir(run_dir)\n",
    "os.chdir(run_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:11242..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "; Java HotSpot(TM) 64-Bit Server VM (build 25.144-b01, mixed mode)\n",
      "  Starting server from C:\\Users\\ptari\\Anaconda3\\lib\\site-packages\\h2o\\backend\\bin\\h2o.jar\n",
      "  Ice root: C:\\Users\\ptari\\AppData\\Local\\Temp\\tmpmcz72dxm\n",
      "  JVM stdout: C:\\Users\\ptari\\AppData\\Local\\Temp\\tmpmcz72dxm\\h2o_ptari_started_from_python.out\n",
      "  JVM stderr: C:\\Users\\ptari\\AppData\\Local\\Temp\\tmpmcz72dxm\\h2o_ptari_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:11242\n",
      "Connecting to H2O server at http://127.0.0.1:11242... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>04 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>America/New_York</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.20.0.8</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>1 month and 11 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_ptari_w7desc</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>5.750 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:11242</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.6.1 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  -------------------------------\n",
       "H2O cluster uptime:         04 secs\n",
       "H2O cluster timezone:       America/New_York\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.20.0.8\n",
       "H2O cluster version age:    1 month and 11 days\n",
       "H2O cluster name:           H2O_from_python_ptari_w7desc\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    5.750 Gb\n",
       "H2O cluster total cores:    4\n",
       "H2O cluster allowed cores:  4\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:11242\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.6.1 final\n",
       "--------------------------  -------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 65535 Highest port no\n",
    "port_no=random.randint(5555,55555)\n",
    "h2o.init(strict_version_check=False,min_mem_size_GB=min_mem_size,port=port_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'run_id': '31NZIQ11j', 'start_time': 1541106858.8285453, 'target': None, 'max_models': 9, 'run_time': 333, 'scale': False, 'classification': False, 'balance': False, 'balance_threshold': 0.2, 'project': None, 'end_time': 1541106858.8285453, 'execution_time': 0.0, 'nthreads': 1, 'min_mem_size': 6, 'analysis': 0}\n"
     ]
    }
   ],
   "source": [
    "# meta data\n",
    "meta_data = set_meta_data(run_id,analysis,target,run_time,classification,scale,max_models,balance_y,balance_threshold,name,nthreads,min_mem_size)\n",
    "print(meta_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ptari\\Desktop\\INFO 7245\\Assignment 2\\assignment 2.2\\breast_cancer.csv\n"
     ]
    }
   ],
   "source": [
    "print(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "df = h2o.import_file(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">              id</th><th style=\"text-align: right;\">  radius_mean</th><th style=\"text-align: right;\">  texture_mean</th><th style=\"text-align: right;\">  perimeter_mean</th><th style=\"text-align: right;\">  area_mean</th><th style=\"text-align: right;\">  smoothness_mean</th><th style=\"text-align: right;\">  compactness_mean</th><th style=\"text-align: right;\">  concavity_mean</th><th style=\"text-align: right;\">  concave points_mean</th><th style=\"text-align: right;\">  symmetry_mean</th><th style=\"text-align: right;\">  fractal_dimension_mean</th><th style=\"text-align: right;\">  radius_se</th><th style=\"text-align: right;\">  texture_se</th><th style=\"text-align: right;\">  perimeter_se</th><th style=\"text-align: right;\">  area_se</th><th style=\"text-align: right;\">  smoothness_se</th><th style=\"text-align: right;\">  compactness_se</th><th style=\"text-align: right;\">  concavity_se</th><th style=\"text-align: right;\">  concave points_se</th><th style=\"text-align: right;\">  symmetry_se</th><th style=\"text-align: right;\">  fractal_dimension_se</th><th style=\"text-align: right;\">  radius_worst</th><th style=\"text-align: right;\">  texture_worst</th><th style=\"text-align: right;\">  perimeter_worst</th><th style=\"text-align: right;\">  area_worst</th><th style=\"text-align: right;\">  smoothness_worst</th><th style=\"text-align: right;\">  compactness_worst</th><th style=\"text-align: right;\">  concavity_worst</th><th style=\"text-align: right;\">  concave points_worst</th><th style=\"text-align: right;\">  symmetry_worst</th><th style=\"text-align: right;\">  fractal_dimension_worst</th><th>diagnosis  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">842302          </td><td style=\"text-align: right;\">        17.99</td><td style=\"text-align: right;\">         10.38</td><td style=\"text-align: right;\">          122.8 </td><td style=\"text-align: right;\">     1001  </td><td style=\"text-align: right;\">          0.1184 </td><td style=\"text-align: right;\">           0.2776 </td><td style=\"text-align: right;\">         0.3001 </td><td style=\"text-align: right;\">              0.1471 </td><td style=\"text-align: right;\">         0.2419</td><td style=\"text-align: right;\">                 0.07871</td><td style=\"text-align: right;\">     1.095 </td><td style=\"text-align: right;\">      0.9053</td><td style=\"text-align: right;\">         8.589</td><td style=\"text-align: right;\">   153.4 </td><td style=\"text-align: right;\">       0.006399</td><td style=\"text-align: right;\">         0.04904</td><td style=\"text-align: right;\">       0.05373</td><td style=\"text-align: right;\">            0.01587</td><td style=\"text-align: right;\">      0.03003</td><td style=\"text-align: right;\">              0.006193</td><td style=\"text-align: right;\">         25.38</td><td style=\"text-align: right;\">          17.33</td><td style=\"text-align: right;\">           184.6 </td><td style=\"text-align: right;\">      2019  </td><td style=\"text-align: right;\">            0.1622</td><td style=\"text-align: right;\">             0.6656</td><td style=\"text-align: right;\">           0.7119</td><td style=\"text-align: right;\">                0.2654</td><td style=\"text-align: right;\">          0.4601</td><td style=\"text-align: right;\">                  0.1189 </td><td>M          </td></tr>\n",
       "<tr><td style=\"text-align: right;\">842517          </td><td style=\"text-align: right;\">        20.57</td><td style=\"text-align: right;\">         17.77</td><td style=\"text-align: right;\">          132.9 </td><td style=\"text-align: right;\">     1326  </td><td style=\"text-align: right;\">          0.08474</td><td style=\"text-align: right;\">           0.07864</td><td style=\"text-align: right;\">         0.0869 </td><td style=\"text-align: right;\">              0.07017</td><td style=\"text-align: right;\">         0.1812</td><td style=\"text-align: right;\">                 0.05667</td><td style=\"text-align: right;\">     0.5435</td><td style=\"text-align: right;\">      0.7339</td><td style=\"text-align: right;\">         3.398</td><td style=\"text-align: right;\">    74.08</td><td style=\"text-align: right;\">       0.005225</td><td style=\"text-align: right;\">         0.01308</td><td style=\"text-align: right;\">       0.0186 </td><td style=\"text-align: right;\">            0.0134 </td><td style=\"text-align: right;\">      0.01389</td><td style=\"text-align: right;\">              0.003532</td><td style=\"text-align: right;\">         24.99</td><td style=\"text-align: right;\">          23.41</td><td style=\"text-align: right;\">           158.8 </td><td style=\"text-align: right;\">      1956  </td><td style=\"text-align: right;\">            0.1238</td><td style=\"text-align: right;\">             0.1866</td><td style=\"text-align: right;\">           0.2416</td><td style=\"text-align: right;\">                0.186 </td><td style=\"text-align: right;\">          0.275 </td><td style=\"text-align: right;\">                  0.08902</td><td>M          </td></tr>\n",
       "<tr><td style=\"text-align: right;\">     8.43009e+07</td><td style=\"text-align: right;\">        19.69</td><td style=\"text-align: right;\">         21.25</td><td style=\"text-align: right;\">          130   </td><td style=\"text-align: right;\">     1203  </td><td style=\"text-align: right;\">          0.1096 </td><td style=\"text-align: right;\">           0.1599 </td><td style=\"text-align: right;\">         0.1974 </td><td style=\"text-align: right;\">              0.1279 </td><td style=\"text-align: right;\">         0.2069</td><td style=\"text-align: right;\">                 0.05999</td><td style=\"text-align: right;\">     0.7456</td><td style=\"text-align: right;\">      0.7869</td><td style=\"text-align: right;\">         4.585</td><td style=\"text-align: right;\">    94.03</td><td style=\"text-align: right;\">       0.00615 </td><td style=\"text-align: right;\">         0.04006</td><td style=\"text-align: right;\">       0.03832</td><td style=\"text-align: right;\">            0.02058</td><td style=\"text-align: right;\">      0.0225 </td><td style=\"text-align: right;\">              0.004571</td><td style=\"text-align: right;\">         23.57</td><td style=\"text-align: right;\">          25.53</td><td style=\"text-align: right;\">           152.5 </td><td style=\"text-align: right;\">      1709  </td><td style=\"text-align: right;\">            0.1444</td><td style=\"text-align: right;\">             0.4245</td><td style=\"text-align: right;\">           0.4504</td><td style=\"text-align: right;\">                0.243 </td><td style=\"text-align: right;\">          0.3613</td><td style=\"text-align: right;\">                  0.08758</td><td>M          </td></tr>\n",
       "<tr><td style=\"text-align: right;\">     8.43483e+07</td><td style=\"text-align: right;\">        11.42</td><td style=\"text-align: right;\">         20.38</td><td style=\"text-align: right;\">           77.58</td><td style=\"text-align: right;\">      386.1</td><td style=\"text-align: right;\">          0.1425 </td><td style=\"text-align: right;\">           0.2839 </td><td style=\"text-align: right;\">         0.2414 </td><td style=\"text-align: right;\">              0.1052 </td><td style=\"text-align: right;\">         0.2597</td><td style=\"text-align: right;\">                 0.09744</td><td style=\"text-align: right;\">     0.4956</td><td style=\"text-align: right;\">      1.156 </td><td style=\"text-align: right;\">         3.445</td><td style=\"text-align: right;\">    27.23</td><td style=\"text-align: right;\">       0.00911 </td><td style=\"text-align: right;\">         0.07458</td><td style=\"text-align: right;\">       0.05661</td><td style=\"text-align: right;\">            0.01867</td><td style=\"text-align: right;\">      0.05963</td><td style=\"text-align: right;\">              0.009208</td><td style=\"text-align: right;\">         14.91</td><td style=\"text-align: right;\">          26.5 </td><td style=\"text-align: right;\">            98.87</td><td style=\"text-align: right;\">       567.7</td><td style=\"text-align: right;\">            0.2098</td><td style=\"text-align: right;\">             0.8663</td><td style=\"text-align: right;\">           0.6869</td><td style=\"text-align: right;\">                0.2575</td><td style=\"text-align: right;\">          0.6638</td><td style=\"text-align: right;\">                  0.173  </td><td>M          </td></tr>\n",
       "<tr><td style=\"text-align: right;\">     8.43584e+07</td><td style=\"text-align: right;\">        20.29</td><td style=\"text-align: right;\">         14.34</td><td style=\"text-align: right;\">          135.1 </td><td style=\"text-align: right;\">     1297  </td><td style=\"text-align: right;\">          0.1003 </td><td style=\"text-align: right;\">           0.1328 </td><td style=\"text-align: right;\">         0.198  </td><td style=\"text-align: right;\">              0.1043 </td><td style=\"text-align: right;\">         0.1809</td><td style=\"text-align: right;\">                 0.05883</td><td style=\"text-align: right;\">     0.7572</td><td style=\"text-align: right;\">      0.7813</td><td style=\"text-align: right;\">         5.438</td><td style=\"text-align: right;\">    94.44</td><td style=\"text-align: right;\">       0.01149 </td><td style=\"text-align: right;\">         0.02461</td><td style=\"text-align: right;\">       0.05688</td><td style=\"text-align: right;\">            0.01885</td><td style=\"text-align: right;\">      0.01756</td><td style=\"text-align: right;\">              0.005115</td><td style=\"text-align: right;\">         22.54</td><td style=\"text-align: right;\">          16.67</td><td style=\"text-align: right;\">           152.2 </td><td style=\"text-align: right;\">      1575  </td><td style=\"text-align: right;\">            0.1374</td><td style=\"text-align: right;\">             0.205 </td><td style=\"text-align: right;\">           0.4   </td><td style=\"text-align: right;\">                0.1625</td><td style=\"text-align: right;\">          0.2364</td><td style=\"text-align: right;\">                  0.07678</td><td>M          </td></tr>\n",
       "<tr><td style=\"text-align: right;\">843786          </td><td style=\"text-align: right;\">        12.45</td><td style=\"text-align: right;\">         15.7 </td><td style=\"text-align: right;\">           82.57</td><td style=\"text-align: right;\">      477.1</td><td style=\"text-align: right;\">          0.1278 </td><td style=\"text-align: right;\">           0.17   </td><td style=\"text-align: right;\">         0.1578 </td><td style=\"text-align: right;\">              0.08089</td><td style=\"text-align: right;\">         0.2087</td><td style=\"text-align: right;\">                 0.07613</td><td style=\"text-align: right;\">     0.3345</td><td style=\"text-align: right;\">      0.8902</td><td style=\"text-align: right;\">         2.217</td><td style=\"text-align: right;\">    27.19</td><td style=\"text-align: right;\">       0.00751 </td><td style=\"text-align: right;\">         0.03345</td><td style=\"text-align: right;\">       0.03672</td><td style=\"text-align: right;\">            0.01137</td><td style=\"text-align: right;\">      0.02165</td><td style=\"text-align: right;\">              0.005082</td><td style=\"text-align: right;\">         15.47</td><td style=\"text-align: right;\">          23.75</td><td style=\"text-align: right;\">           103.4 </td><td style=\"text-align: right;\">       741.6</td><td style=\"text-align: right;\">            0.1791</td><td style=\"text-align: right;\">             0.5249</td><td style=\"text-align: right;\">           0.5355</td><td style=\"text-align: right;\">                0.1741</td><td style=\"text-align: right;\">          0.3985</td><td style=\"text-align: right;\">                  0.1244 </td><td>M          </td></tr>\n",
       "<tr><td style=\"text-align: right;\">844359          </td><td style=\"text-align: right;\">        18.25</td><td style=\"text-align: right;\">         19.98</td><td style=\"text-align: right;\">          119.6 </td><td style=\"text-align: right;\">     1040  </td><td style=\"text-align: right;\">          0.09463</td><td style=\"text-align: right;\">           0.109  </td><td style=\"text-align: right;\">         0.1127 </td><td style=\"text-align: right;\">              0.074  </td><td style=\"text-align: right;\">         0.1794</td><td style=\"text-align: right;\">                 0.05742</td><td style=\"text-align: right;\">     0.4467</td><td style=\"text-align: right;\">      0.7732</td><td style=\"text-align: right;\">         3.18 </td><td style=\"text-align: right;\">    53.91</td><td style=\"text-align: right;\">       0.004314</td><td style=\"text-align: right;\">         0.01382</td><td style=\"text-align: right;\">       0.02254</td><td style=\"text-align: right;\">            0.01039</td><td style=\"text-align: right;\">      0.01369</td><td style=\"text-align: right;\">              0.002179</td><td style=\"text-align: right;\">         22.88</td><td style=\"text-align: right;\">          27.66</td><td style=\"text-align: right;\">           153.2 </td><td style=\"text-align: right;\">      1606  </td><td style=\"text-align: right;\">            0.1442</td><td style=\"text-align: right;\">             0.2576</td><td style=\"text-align: right;\">           0.3784</td><td style=\"text-align: right;\">                0.1932</td><td style=\"text-align: right;\">          0.3063</td><td style=\"text-align: right;\">                  0.08368</td><td>M          </td></tr>\n",
       "<tr><td style=\"text-align: right;\">     8.44582e+07</td><td style=\"text-align: right;\">        13.71</td><td style=\"text-align: right;\">         20.83</td><td style=\"text-align: right;\">           90.2 </td><td style=\"text-align: right;\">      577.9</td><td style=\"text-align: right;\">          0.1189 </td><td style=\"text-align: right;\">           0.1645 </td><td style=\"text-align: right;\">         0.09366</td><td style=\"text-align: right;\">              0.05985</td><td style=\"text-align: right;\">         0.2196</td><td style=\"text-align: right;\">                 0.07451</td><td style=\"text-align: right;\">     0.5835</td><td style=\"text-align: right;\">      1.377 </td><td style=\"text-align: right;\">         3.856</td><td style=\"text-align: right;\">    50.96</td><td style=\"text-align: right;\">       0.008805</td><td style=\"text-align: right;\">         0.03029</td><td style=\"text-align: right;\">       0.02488</td><td style=\"text-align: right;\">            0.01448</td><td style=\"text-align: right;\">      0.01486</td><td style=\"text-align: right;\">              0.005412</td><td style=\"text-align: right;\">         17.06</td><td style=\"text-align: right;\">          28.14</td><td style=\"text-align: right;\">           110.6 </td><td style=\"text-align: right;\">       897  </td><td style=\"text-align: right;\">            0.1654</td><td style=\"text-align: right;\">             0.3682</td><td style=\"text-align: right;\">           0.2678</td><td style=\"text-align: right;\">                0.1556</td><td style=\"text-align: right;\">          0.3196</td><td style=\"text-align: right;\">                  0.1151 </td><td>M          </td></tr>\n",
       "<tr><td style=\"text-align: right;\">844981          </td><td style=\"text-align: right;\">        13   </td><td style=\"text-align: right;\">         21.82</td><td style=\"text-align: right;\">           87.5 </td><td style=\"text-align: right;\">      519.8</td><td style=\"text-align: right;\">          0.1273 </td><td style=\"text-align: right;\">           0.1932 </td><td style=\"text-align: right;\">         0.1859 </td><td style=\"text-align: right;\">              0.09353</td><td style=\"text-align: right;\">         0.235 </td><td style=\"text-align: right;\">                 0.07389</td><td style=\"text-align: right;\">     0.3063</td><td style=\"text-align: right;\">      1.002 </td><td style=\"text-align: right;\">         2.406</td><td style=\"text-align: right;\">    24.32</td><td style=\"text-align: right;\">       0.005731</td><td style=\"text-align: right;\">         0.03502</td><td style=\"text-align: right;\">       0.03553</td><td style=\"text-align: right;\">            0.01226</td><td style=\"text-align: right;\">      0.02143</td><td style=\"text-align: right;\">              0.003749</td><td style=\"text-align: right;\">         15.49</td><td style=\"text-align: right;\">          30.73</td><td style=\"text-align: right;\">           106.2 </td><td style=\"text-align: right;\">       739.3</td><td style=\"text-align: right;\">            0.1703</td><td style=\"text-align: right;\">             0.5401</td><td style=\"text-align: right;\">           0.539 </td><td style=\"text-align: right;\">                0.206 </td><td style=\"text-align: right;\">          0.4378</td><td style=\"text-align: right;\">                  0.1072 </td><td>M          </td></tr>\n",
       "<tr><td style=\"text-align: right;\">     8.4501e+07 </td><td style=\"text-align: right;\">        12.46</td><td style=\"text-align: right;\">         24.04</td><td style=\"text-align: right;\">           83.97</td><td style=\"text-align: right;\">      475.9</td><td style=\"text-align: right;\">          0.1186 </td><td style=\"text-align: right;\">           0.2396 </td><td style=\"text-align: right;\">         0.2273 </td><td style=\"text-align: right;\">              0.08543</td><td style=\"text-align: right;\">         0.203 </td><td style=\"text-align: right;\">                 0.08243</td><td style=\"text-align: right;\">     0.2976</td><td style=\"text-align: right;\">      1.599 </td><td style=\"text-align: right;\">         2.039</td><td style=\"text-align: right;\">    23.94</td><td style=\"text-align: right;\">       0.007149</td><td style=\"text-align: right;\">         0.07217</td><td style=\"text-align: right;\">       0.07743</td><td style=\"text-align: right;\">            0.01432</td><td style=\"text-align: right;\">      0.01789</td><td style=\"text-align: right;\">              0.01008 </td><td style=\"text-align: right;\">         15.09</td><td style=\"text-align: right;\">          40.68</td><td style=\"text-align: right;\">            97.65</td><td style=\"text-align: right;\">       711.4</td><td style=\"text-align: right;\">            0.1853</td><td style=\"text-align: right;\">             1.058 </td><td style=\"text-align: right;\">           1.105 </td><td style=\"text-align: right;\">                0.221 </td><td style=\"text-align: right;\">          0.4366</td><td style=\"text-align: right;\">                  0.2075 </td><td>M          </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:569\n",
      "Cols:32\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th>id                </th><th>radius_mean       </th><th>texture_mean      </th><th>perimeter_mean   </th><th>area_mean        </th><th>smoothness_mean     </th><th>compactness_mean    </th><th>concavity_mean     </th><th>concave points_mean  </th><th>symmetry_mean       </th><th>fractal_dimension_mean  </th><th>radius_se          </th><th>texture_se        </th><th>perimeter_se      </th><th>area_se          </th><th>smoothness_se       </th><th>compactness_se      </th><th>concavity_se        </th><th>concave points_se   </th><th>symmetry_se         </th><th>fractal_dimension_se  </th><th>radius_worst      </th><th>texture_worst     </th><th>perimeter_worst   </th><th>area_worst       </th><th>smoothness_worst    </th><th>compactness_worst  </th><th>concavity_worst    </th><th>concave points_worst  </th><th>symmetry_worst     </th><th>fractal_dimension_worst  </th><th>diagnosis  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>type   </td><td>int               </td><td>real              </td><td>real              </td><td>real             </td><td>real             </td><td>real                </td><td>real                </td><td>real               </td><td>real                 </td><td>real                </td><td>real                    </td><td>real               </td><td>real              </td><td>real              </td><td>real             </td><td>real                </td><td>real                </td><td>real                </td><td>real                </td><td>real                </td><td>real                  </td><td>real              </td><td>real              </td><td>real              </td><td>real             </td><td>real                </td><td>real               </td><td>real               </td><td>real                  </td><td>real               </td><td>real                     </td><td>enum       </td></tr>\n",
       "<tr><td>mins   </td><td>8670.0            </td><td>6.981             </td><td>9.71              </td><td>43.79            </td><td>143.5            </td><td>0.05263             </td><td>0.01938             </td><td>0.0                </td><td>0.0                  </td><td>0.106               </td><td>0.04996                 </td><td>0.1115             </td><td>0.3602            </td><td>0.757             </td><td>6.802            </td><td>0.001713            </td><td>0.002252            </td><td>0.0                 </td><td>0.0                 </td><td>0.007882            </td><td>0.0008948             </td><td>7.93              </td><td>12.02             </td><td>50.41             </td><td>185.2            </td><td>0.07117             </td><td>0.02729            </td><td>0.0                </td><td>0.0                   </td><td>0.1565             </td><td>0.05504                  </td><td>           </td></tr>\n",
       "<tr><td>mean   </td><td>30371831.43233744 </td><td>14.127291739894554</td><td>19.289648506151142</td><td>91.96903339191564</td><td>654.8891036906855</td><td>0.09636028119507907 </td><td>0.10434098418277679 </td><td>0.0887993158172232 </td><td>0.04891914586994728  </td><td>0.18116186291739897 </td><td>0.06279760984182778     </td><td>0.40517205623901575</td><td>1.2168534270650264</td><td>2.8660592267135327</td><td>40.337079086116  </td><td>0.007040978910369069</td><td>0.025478138840070295</td><td>0.031893716344463974</td><td>0.011796137082601056</td><td>0.02054229876977153 </td><td>0.0037949038664323374 </td><td>16.269189806678384</td><td>25.677223198594024</td><td>107.26121265377856</td><td>880.5831282952548</td><td>0.13236859402460457 </td><td>0.2542650439367311 </td><td>0.27218848330404216</td><td>0.11460622319859404   </td><td>0.2900755711775044 </td><td>0.0839458172231986       </td><td>           </td></tr>\n",
       "<tr><td>maxs   </td><td>911320502.0       </td><td>28.11             </td><td>39.28             </td><td>188.5            </td><td>2501.0           </td><td>0.1634              </td><td>0.3454              </td><td>0.4268             </td><td>0.2012               </td><td>0.304               </td><td>0.09744                 </td><td>2.873              </td><td>4.885             </td><td>21.98             </td><td>542.2            </td><td>0.03113             </td><td>0.1354              </td><td>0.396               </td><td>0.05279             </td><td>0.07895             </td><td>0.02984               </td><td>36.04             </td><td>49.54             </td><td>251.2             </td><td>4254.0           </td><td>0.2226              </td><td>1.058              </td><td>1.252              </td><td>0.291                 </td><td>0.6638             </td><td>0.2075                   </td><td>           </td></tr>\n",
       "<tr><td>sigma  </td><td>125020585.61222365</td><td>3.524048826212078 </td><td>4.30103576816695  </td><td>24.2989810387549 </td><td>351.914129181653 </td><td>0.014064128137673616</td><td>0.052812757932512194</td><td>0.07971980870789348</td><td>0.038802844859153605 </td><td>0.027414281336035712</td><td>0.00706036279508446     </td><td>0.2773127329861039 </td><td>0.5516483926172022</td><td>2.0218545540421076</td><td>45.49100551613181</td><td>0.003002517943839066</td><td>0.017908179325677388</td><td>0.030186060322988408</td><td>0.006170285174046869</td><td>0.008266371528798397</td><td>0.002646070967089195  </td><td>4.833241580469323 </td><td>6.146257623038319 </td><td>33.602542269036356</td><td>569.356992669949 </td><td>0.022832429404835472</td><td>0.157336488913742  </td><td>0.2086242806081323 </td><td>0.06573234119594207   </td><td>0.06186746753751869</td><td>0.018061267348893986     </td><td>           </td></tr>\n",
       "<tr><td>zeros  </td><td>0                 </td><td>0                 </td><td>0                 </td><td>0                </td><td>0                </td><td>0                   </td><td>0                   </td><td>13                 </td><td>13                   </td><td>0                   </td><td>0                       </td><td>0                  </td><td>0                 </td><td>0                 </td><td>0                </td><td>0                   </td><td>0                   </td><td>13                  </td><td>13                  </td><td>0                   </td><td>0                     </td><td>0                 </td><td>0                 </td><td>0                 </td><td>0                </td><td>0                   </td><td>0                  </td><td>13                 </td><td>13                    </td><td>0                  </td><td>0                        </td><td>           </td></tr>\n",
       "<tr><td>missing</td><td>0                 </td><td>0                 </td><td>0                 </td><td>0                </td><td>0                </td><td>0                   </td><td>0                   </td><td>0                  </td><td>0                    </td><td>0                   </td><td>0                       </td><td>0                  </td><td>0                 </td><td>0                 </td><td>0                </td><td>0                   </td><td>0                   </td><td>0                   </td><td>0                   </td><td>0                   </td><td>0                     </td><td>0                 </td><td>0                 </td><td>0                 </td><td>0                </td><td>0                   </td><td>0                  </td><td>0                  </td><td>0                     </td><td>0                  </td><td>0                        </td><td>0          </td></tr>\n",
       "<tr><td>0      </td><td>842302.0          </td><td>17.99             </td><td>10.38             </td><td>122.8            </td><td>1001.0           </td><td>0.1184              </td><td>0.2776              </td><td>0.3001             </td><td>0.1471               </td><td>0.2419              </td><td>0.07871                 </td><td>1.095              </td><td>0.9053            </td><td>8.589             </td><td>153.4            </td><td>0.006399            </td><td>0.04904             </td><td>0.05373             </td><td>0.01587             </td><td>0.03003             </td><td>0.006193              </td><td>25.38             </td><td>17.33             </td><td>184.6             </td><td>2019.0           </td><td>0.1622              </td><td>0.6656             </td><td>0.7119             </td><td>0.2654                </td><td>0.4601             </td><td>0.1189                   </td><td>M          </td></tr>\n",
       "<tr><td>1      </td><td>842517.0          </td><td>20.57             </td><td>17.77             </td><td>132.9            </td><td>1326.0           </td><td>0.08474             </td><td>0.07864             </td><td>0.0869             </td><td>0.07017              </td><td>0.1812              </td><td>0.05667                 </td><td>0.5435             </td><td>0.7339            </td><td>3.398             </td><td>74.08            </td><td>0.005225            </td><td>0.01308             </td><td>0.0186              </td><td>0.0134              </td><td>0.01389             </td><td>0.003532              </td><td>24.99             </td><td>23.41             </td><td>158.8             </td><td>1956.0           </td><td>0.1238              </td><td>0.1866             </td><td>0.2416             </td><td>0.186                 </td><td>0.275              </td><td>0.08902                  </td><td>M          </td></tr>\n",
       "<tr><td>2      </td><td>84300903.0        </td><td>19.69             </td><td>21.25             </td><td>130.0            </td><td>1203.0           </td><td>0.1096              </td><td>0.1599              </td><td>0.1974             </td><td>0.1279               </td><td>0.2069              </td><td>0.05999                 </td><td>0.7456             </td><td>0.7869            </td><td>4.585             </td><td>94.03            </td><td>0.00615             </td><td>0.04006             </td><td>0.03832             </td><td>0.02058             </td><td>0.0225              </td><td>0.004571              </td><td>23.57             </td><td>25.53             </td><td>152.5             </td><td>1709.0           </td><td>0.1444              </td><td>0.4245             </td><td>0.4504             </td><td>0.243                 </td><td>0.3613             </td><td>0.08758                  </td><td>M          </td></tr>\n",
       "<tr><td>3      </td><td>84348301.0        </td><td>11.42             </td><td>20.38             </td><td>77.58            </td><td>386.1            </td><td>0.1425              </td><td>0.2839              </td><td>0.2414             </td><td>0.1052               </td><td>0.2597              </td><td>0.09744                 </td><td>0.4956             </td><td>1.156             </td><td>3.445             </td><td>27.23            </td><td>0.00911             </td><td>0.07458             </td><td>0.05661             </td><td>0.01867             </td><td>0.05963             </td><td>0.009208              </td><td>14.91             </td><td>26.5              </td><td>98.87             </td><td>567.7            </td><td>0.2098              </td><td>0.8663             </td><td>0.6869             </td><td>0.2575                </td><td>0.6638             </td><td>0.173                    </td><td>M          </td></tr>\n",
       "<tr><td>4      </td><td>84358402.0        </td><td>20.29             </td><td>14.34             </td><td>135.1            </td><td>1297.0           </td><td>0.1003              </td><td>0.1328              </td><td>0.198              </td><td>0.1043               </td><td>0.1809              </td><td>0.05883                 </td><td>0.7572             </td><td>0.7813            </td><td>5.438             </td><td>94.44            </td><td>0.01149             </td><td>0.02461             </td><td>0.05688             </td><td>0.01885             </td><td>0.01756             </td><td>0.005115              </td><td>22.54             </td><td>16.67             </td><td>152.2             </td><td>1575.0           </td><td>0.1374              </td><td>0.205              </td><td>0.4                </td><td>0.1625                </td><td>0.2364             </td><td>0.07678                  </td><td>M          </td></tr>\n",
       "<tr><td>5      </td><td>843786.0          </td><td>12.45             </td><td>15.7              </td><td>82.57            </td><td>477.1            </td><td>0.1278              </td><td>0.17                </td><td>0.1578             </td><td>0.08089              </td><td>0.2087              </td><td>0.07613                 </td><td>0.3345             </td><td>0.8902            </td><td>2.217             </td><td>27.19            </td><td>0.00751             </td><td>0.03345             </td><td>0.03672             </td><td>0.01137             </td><td>0.02165             </td><td>0.005082              </td><td>15.47             </td><td>23.75             </td><td>103.4             </td><td>741.6            </td><td>0.1791              </td><td>0.5249             </td><td>0.5355             </td><td>0.1741                </td><td>0.3985             </td><td>0.1244                   </td><td>M          </td></tr>\n",
       "<tr><td>6      </td><td>844359.0          </td><td>18.25             </td><td>19.98             </td><td>119.6            </td><td>1040.0           </td><td>0.09463             </td><td>0.109               </td><td>0.1127             </td><td>0.074                </td><td>0.1794              </td><td>0.05742                 </td><td>0.4467             </td><td>0.7732            </td><td>3.18              </td><td>53.91            </td><td>0.004314            </td><td>0.01382             </td><td>0.02254             </td><td>0.01039             </td><td>0.01369             </td><td>0.002179              </td><td>22.88             </td><td>27.66             </td><td>153.2             </td><td>1606.0           </td><td>0.1442              </td><td>0.2576             </td><td>0.3784             </td><td>0.1932                </td><td>0.3063             </td><td>0.08368                  </td><td>M          </td></tr>\n",
       "<tr><td>7      </td><td>84458202.0        </td><td>13.71             </td><td>20.83             </td><td>90.2             </td><td>577.9            </td><td>0.1189              </td><td>0.1645              </td><td>0.09366            </td><td>0.05985              </td><td>0.2196              </td><td>0.07451                 </td><td>0.5835             </td><td>1.377             </td><td>3.856             </td><td>50.96            </td><td>0.008805            </td><td>0.03029             </td><td>0.02488             </td><td>0.01448             </td><td>0.01486             </td><td>0.005412              </td><td>17.06             </td><td>28.14             </td><td>110.6             </td><td>897.0            </td><td>0.1654              </td><td>0.3682             </td><td>0.2678             </td><td>0.1556                </td><td>0.3196             </td><td>0.1151                   </td><td>M          </td></tr>\n",
       "<tr><td>8      </td><td>844981.0          </td><td>13.0              </td><td>21.82             </td><td>87.5             </td><td>519.8            </td><td>0.1273              </td><td>0.1932              </td><td>0.1859             </td><td>0.09353              </td><td>0.235               </td><td>0.07389                 </td><td>0.3063             </td><td>1.002             </td><td>2.406             </td><td>24.32            </td><td>0.005731            </td><td>0.03502             </td><td>0.03553             </td><td>0.01226             </td><td>0.02143             </td><td>0.003749              </td><td>15.49             </td><td>30.73             </td><td>106.2             </td><td>739.3            </td><td>0.1703              </td><td>0.5401             </td><td>0.539              </td><td>0.206                 </td><td>0.4378             </td><td>0.1072                   </td><td>M          </td></tr>\n",
       "<tr><td>9      </td><td>84501001.0        </td><td>12.46             </td><td>24.04             </td><td>83.97            </td><td>475.9            </td><td>0.1186              </td><td>0.2396              </td><td>0.2273             </td><td>0.08543              </td><td>0.203               </td><td>0.08243                 </td><td>0.2976             </td><td>1.599             </td><td>2.039             </td><td>23.94            </td><td>0.007149            </td><td>0.07217             </td><td>0.07743             </td><td>0.01432             </td><td>0.01789             </td><td>0.01008               </td><td>15.09             </td><td>40.68             </td><td>97.65             </td><td>711.4            </td><td>0.1853              </td><td>1.058              </td><td>1.105              </td><td>0.221                 </td><td>0.4366             </td><td>0.2075                   </td><td>M          </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dependent variable\n",
    "# assign target and inputs for classification or regression\n",
    "if target==None:\n",
    "  target=df.columns[-1]   \n",
    "y = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diagnosis\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(all_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if all_variables is not None:\n",
    "  ivd=get_all_variables_csv(all_variables)\n",
    "  print(ivd)    \n",
    "  X=check_all_variables(df,ivd,y)\n",
    "  print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# independent variables\n",
    "\n",
    "X = []  \n",
    "if all_variables is None:\n",
    "  X=get_independent_variables(df, target)  \n",
    "else: \n",
    "  ivd=get_all_variables_csv(all_variables)    \n",
    "  X=check_all_variables(df, ivd)\n",
    "\n",
    "\n",
    "X=check_X(X,df)\n",
    "\n",
    "\n",
    "# Add independent variables\n",
    "\n",
    "meta_data['X']=X  \n",
    "\n",
    "\n",
    "# impute missing values\n",
    "\n",
    "_=impute_missing_values(df,X, scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if analysis == 3:\n",
    "  classification=False\n",
    "elif analysis == 2:\n",
    "  classification=True\n",
    "elif analysis == 1:\n",
    "  classification=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Force target to be factors\n",
    "# Only 'int' or 'string' are allowed for asfactor(), got Target (Total orders):real \n",
    "\n",
    "if classification:\n",
    "    df[y] = df[y].asfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_y(y,df):\n",
    "  ok=False\n",
    "  C = [name for name in df.columns if name == y]\n",
    "  for key, val in df.types.items():\n",
    "    if key in C:\n",
    "      if val in ['real','int','enum']:        \n",
    "        ok=True         \n",
    "  return ok, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ok,val=check_y(y,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enum\n"
     ]
    }
   ],
   "source": [
    "print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(ok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['B', 'M']]\n"
     ]
    }
   ],
   "source": [
    "if val=='enum':\n",
    "    print(df[y].levels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'area_mean': 'real',\n",
       " 'area_se': 'real',\n",
       " 'area_worst': 'real',\n",
       " 'compactness_mean': 'real',\n",
       " 'compactness_se': 'real',\n",
       " 'compactness_worst': 'real',\n",
       " 'concave points_mean': 'real',\n",
       " 'concave points_se': 'real',\n",
       " 'concave points_worst': 'real',\n",
       " 'concavity_mean': 'real',\n",
       " 'concavity_se': 'real',\n",
       " 'concavity_worst': 'real',\n",
       " 'diagnosis': 'enum',\n",
       " 'fractal_dimension_mean': 'real',\n",
       " 'fractal_dimension_se': 'real',\n",
       " 'fractal_dimension_worst': 'real',\n",
       " 'id': 'int',\n",
       " 'perimeter_mean': 'real',\n",
       " 'perimeter_se': 'real',\n",
       " 'perimeter_worst': 'real',\n",
       " 'radius_mean': 'real',\n",
       " 'radius_se': 'real',\n",
       " 'radius_worst': 'real',\n",
       " 'smoothness_mean': 'real',\n",
       " 'smoothness_se': 'real',\n",
       " 'smoothness_worst': 'real',\n",
       " 'symmetry_mean': 'real',\n",
       " 'symmetry_se': 'real',\n",
       " 'symmetry_worst': 'real',\n",
       " 'texture_mean': 'real',\n",
       " 'texture_se': 'real',\n",
       " 'texture_worst': 'real'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allV=get_variables_types(df)\n",
    "allV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_data['variables']=allV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split into training and test for showing how to predict\n",
    "train, test = df.split_frame([0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up AutoML\n",
    "\n",
    "aml = H2OAutoML(max_runtime_secs=run_time,project_name = name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "aml.train(x=X,y=y,training_frame=train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_data['model_execution_time'] = time.time() - model_start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>auc</th>\n",
       "      <th>logloss</th>\n",
       "      <th>mean_per_class_error</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GBM_grid_0_AutoML_20181101_171828_model_19</td>\n",
       "      <td>0.994951</td>\n",
       "      <td>0.084078</td>\n",
       "      <td>0.028044</td>\n",
       "      <td>0.149942</td>\n",
       "      <td>0.022483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GBM_grid_0_AutoML_20181101_171828_model_30</td>\n",
       "      <td>0.993720</td>\n",
       "      <td>0.087116</td>\n",
       "      <td>0.030744</td>\n",
       "      <td>0.148942</td>\n",
       "      <td>0.022184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GBM_grid_0_AutoML_20181101_171828_model_6</td>\n",
       "      <td>0.993494</td>\n",
       "      <td>0.083322</td>\n",
       "      <td>0.024327</td>\n",
       "      <td>0.144018</td>\n",
       "      <td>0.020741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GBM_grid_0_AutoML_20181101_171828_model_1</td>\n",
       "      <td>0.993369</td>\n",
       "      <td>0.095012</td>\n",
       "      <td>0.026186</td>\n",
       "      <td>0.152650</td>\n",
       "      <td>0.023302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GBM_grid_0_AutoML_20181101_171828_model_16</td>\n",
       "      <td>0.993143</td>\n",
       "      <td>0.126343</td>\n",
       "      <td>0.028383</td>\n",
       "      <td>0.169952</td>\n",
       "      <td>0.028884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GBM_grid_0_AutoML_20181101_171828_model_11</td>\n",
       "      <td>0.992892</td>\n",
       "      <td>0.088425</td>\n",
       "      <td>0.022807</td>\n",
       "      <td>0.148049</td>\n",
       "      <td>0.021919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GBM_grid_0_AutoML_20181101_171828_model_15</td>\n",
       "      <td>0.992716</td>\n",
       "      <td>0.122421</td>\n",
       "      <td>0.029903</td>\n",
       "      <td>0.166348</td>\n",
       "      <td>0.027672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GBM_grid_0_AutoML_20181101_171828_model_20</td>\n",
       "      <td>0.992716</td>\n",
       "      <td>0.090809</td>\n",
       "      <td>0.020948</td>\n",
       "      <td>0.148629</td>\n",
       "      <td>0.022091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>StackedEnsemble_BestOfFamily_0_AutoML_20181101...</td>\n",
       "      <td>0.992088</td>\n",
       "      <td>0.078124</td>\n",
       "      <td>0.021288</td>\n",
       "      <td>0.140211</td>\n",
       "      <td>0.019659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GLM_grid_0_AutoML_20181101_171828_model_0</td>\n",
       "      <td>0.992038</td>\n",
       "      <td>0.084287</td>\n",
       "      <td>0.025507</td>\n",
       "      <td>0.141896</td>\n",
       "      <td>0.020135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GBM_grid_0_AutoML_20181101_171828_model_4</td>\n",
       "      <td>0.991912</td>\n",
       "      <td>0.089195</td>\n",
       "      <td>0.020948</td>\n",
       "      <td>0.147155</td>\n",
       "      <td>0.021655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GBM_grid_0_AutoML_20181101_171828_model_8</td>\n",
       "      <td>0.991862</td>\n",
       "      <td>0.085686</td>\n",
       "      <td>0.025846</td>\n",
       "      <td>0.142762</td>\n",
       "      <td>0.020381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GBM_grid_0_AutoML_20181101_171828_model_2</td>\n",
       "      <td>0.991736</td>\n",
       "      <td>0.098847</td>\n",
       "      <td>0.034462</td>\n",
       "      <td>0.160139</td>\n",
       "      <td>0.025645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GBM_grid_0_AutoML_20181101_171828_model_3</td>\n",
       "      <td>0.991385</td>\n",
       "      <td>0.100212</td>\n",
       "      <td>0.029564</td>\n",
       "      <td>0.155999</td>\n",
       "      <td>0.024336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GBM_grid_0_AutoML_20181101_171828_model_9</td>\n",
       "      <td>0.990958</td>\n",
       "      <td>0.097699</td>\n",
       "      <td>0.022807</td>\n",
       "      <td>0.137939</td>\n",
       "      <td>0.019027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>GBM_grid_0_AutoML_20181101_171828_model_24</td>\n",
       "      <td>0.990907</td>\n",
       "      <td>0.093146</td>\n",
       "      <td>0.025846</td>\n",
       "      <td>0.149242</td>\n",
       "      <td>0.022273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DeepLearning_grid_0_AutoML_20181101_171828_mod...</td>\n",
       "      <td>0.990882</td>\n",
       "      <td>0.235197</td>\n",
       "      <td>0.024327</td>\n",
       "      <td>0.153467</td>\n",
       "      <td>0.023552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>GBM_grid_0_AutoML_20181101_171828_model_5</td>\n",
       "      <td>0.989589</td>\n",
       "      <td>0.126021</td>\n",
       "      <td>0.035479</td>\n",
       "      <td>0.181506</td>\n",
       "      <td>0.032944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>GBM_grid_0_AutoML_20181101_171828_model_25</td>\n",
       "      <td>0.989325</td>\n",
       "      <td>0.204021</td>\n",
       "      <td>0.041219</td>\n",
       "      <td>0.184691</td>\n",
       "      <td>0.034111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>GBM_grid_0_AutoML_20181101_171828_model_13</td>\n",
       "      <td>0.989325</td>\n",
       "      <td>0.141038</td>\n",
       "      <td>0.038519</td>\n",
       "      <td>0.181473</td>\n",
       "      <td>0.032932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>GBM_grid_0_AutoML_20181101_171828_model_27</td>\n",
       "      <td>0.989275</td>\n",
       "      <td>0.141328</td>\n",
       "      <td>0.036999</td>\n",
       "      <td>0.181453</td>\n",
       "      <td>0.032925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>StackedEnsemble_AllModels_0_AutoML_20181101_17...</td>\n",
       "      <td>0.988848</td>\n",
       "      <td>0.076259</td>\n",
       "      <td>0.023988</td>\n",
       "      <td>0.132483</td>\n",
       "      <td>0.017552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>GBM_grid_0_AutoML_20181101_171828_model_7</td>\n",
       "      <td>0.988810</td>\n",
       "      <td>0.140655</td>\n",
       "      <td>0.031762</td>\n",
       "      <td>0.175325</td>\n",
       "      <td>0.030739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>GBM_grid_0_AutoML_20181101_171828_model_26</td>\n",
       "      <td>0.988634</td>\n",
       "      <td>0.320965</td>\n",
       "      <td>0.042236</td>\n",
       "      <td>0.196083</td>\n",
       "      <td>0.038448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>GBM_grid_0_AutoML_20181101_171828_model_28</td>\n",
       "      <td>0.988370</td>\n",
       "      <td>0.152488</td>\n",
       "      <td>0.040377</td>\n",
       "      <td>0.188195</td>\n",
       "      <td>0.035417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>XRT_0_AutoML_20181101_171828</td>\n",
       "      <td>0.988245</td>\n",
       "      <td>0.244923</td>\n",
       "      <td>0.029564</td>\n",
       "      <td>0.166772</td>\n",
       "      <td>0.027813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>GBM_grid_0_AutoML_20181101_171828_model_29</td>\n",
       "      <td>0.987768</td>\n",
       "      <td>0.191367</td>\n",
       "      <td>0.050010</td>\n",
       "      <td>0.213969</td>\n",
       "      <td>0.045783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>DRF_0_AutoML_20181101_171828</td>\n",
       "      <td>0.986989</td>\n",
       "      <td>0.257922</td>\n",
       "      <td>0.048315</td>\n",
       "      <td>0.181033</td>\n",
       "      <td>0.032773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>GBM_grid_0_AutoML_20181101_171828_model_14</td>\n",
       "      <td>0.986474</td>\n",
       "      <td>0.254744</td>\n",
       "      <td>0.039536</td>\n",
       "      <td>0.244523</td>\n",
       "      <td>0.059791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>GBM_grid_0_AutoML_20181101_171828_model_21</td>\n",
       "      <td>0.985620</td>\n",
       "      <td>0.167150</td>\n",
       "      <td>0.054393</td>\n",
       "      <td>0.197807</td>\n",
       "      <td>0.039128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>GBM_grid_0_AutoML_20181101_171828_model_0</td>\n",
       "      <td>0.985105</td>\n",
       "      <td>0.143244</td>\n",
       "      <td>0.044258</td>\n",
       "      <td>0.185215</td>\n",
       "      <td>0.034305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>GBM_grid_0_AutoML_20181101_171828_model_10</td>\n",
       "      <td>0.978650</td>\n",
       "      <td>0.187929</td>\n",
       "      <td>0.052032</td>\n",
       "      <td>0.209580</td>\n",
       "      <td>0.043924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>DeepLearning_0_AutoML_20181101_171828</td>\n",
       "      <td>0.977067</td>\n",
       "      <td>0.191331</td>\n",
       "      <td>0.052371</td>\n",
       "      <td>0.202730</td>\n",
       "      <td>0.041099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>GBM_grid_0_AutoML_20181101_171828_model_12</td>\n",
       "      <td>0.972785</td>\n",
       "      <td>0.497331</td>\n",
       "      <td>0.049156</td>\n",
       "      <td>0.200047</td>\n",
       "      <td>0.040019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>GBM_grid_0_AutoML_20181101_171828_model_18</td>\n",
       "      <td>0.863672</td>\n",
       "      <td>0.628657</td>\n",
       "      <td>0.189742</td>\n",
       "      <td>0.467911</td>\n",
       "      <td>0.218941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>GBM_grid_0_AutoML_20181101_171828_model_17</td>\n",
       "      <td>0.863308</td>\n",
       "      <td>0.628878</td>\n",
       "      <td>0.193459</td>\n",
       "      <td>0.468019</td>\n",
       "      <td>0.219042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>GBM_grid_0_AutoML_20181101_171828_model_22</td>\n",
       "      <td>0.861311</td>\n",
       "      <td>0.628815</td>\n",
       "      <td>0.191261</td>\n",
       "      <td>0.467990</td>\n",
       "      <td>0.219014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>GBM_grid_0_AutoML_20181101_171828_model_23</td>\n",
       "      <td>0.834949</td>\n",
       "      <td>0.631305</td>\n",
       "      <td>0.203255</td>\n",
       "      <td>0.469211</td>\n",
       "      <td>0.220159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             model_id       auc   logloss  \\\n",
       "0          GBM_grid_0_AutoML_20181101_171828_model_19  0.994951  0.084078   \n",
       "1          GBM_grid_0_AutoML_20181101_171828_model_30  0.993720  0.087116   \n",
       "2           GBM_grid_0_AutoML_20181101_171828_model_6  0.993494  0.083322   \n",
       "3           GBM_grid_0_AutoML_20181101_171828_model_1  0.993369  0.095012   \n",
       "4          GBM_grid_0_AutoML_20181101_171828_model_16  0.993143  0.126343   \n",
       "5          GBM_grid_0_AutoML_20181101_171828_model_11  0.992892  0.088425   \n",
       "6          GBM_grid_0_AutoML_20181101_171828_model_15  0.992716  0.122421   \n",
       "7          GBM_grid_0_AutoML_20181101_171828_model_20  0.992716  0.090809   \n",
       "8   StackedEnsemble_BestOfFamily_0_AutoML_20181101...  0.992088  0.078124   \n",
       "9           GLM_grid_0_AutoML_20181101_171828_model_0  0.992038  0.084287   \n",
       "10          GBM_grid_0_AutoML_20181101_171828_model_4  0.991912  0.089195   \n",
       "11          GBM_grid_0_AutoML_20181101_171828_model_8  0.991862  0.085686   \n",
       "12          GBM_grid_0_AutoML_20181101_171828_model_2  0.991736  0.098847   \n",
       "13          GBM_grid_0_AutoML_20181101_171828_model_3  0.991385  0.100212   \n",
       "14          GBM_grid_0_AutoML_20181101_171828_model_9  0.990958  0.097699   \n",
       "15         GBM_grid_0_AutoML_20181101_171828_model_24  0.990907  0.093146   \n",
       "16  DeepLearning_grid_0_AutoML_20181101_171828_mod...  0.990882  0.235197   \n",
       "17          GBM_grid_0_AutoML_20181101_171828_model_5  0.989589  0.126021   \n",
       "18         GBM_grid_0_AutoML_20181101_171828_model_25  0.989325  0.204021   \n",
       "19         GBM_grid_0_AutoML_20181101_171828_model_13  0.989325  0.141038   \n",
       "20         GBM_grid_0_AutoML_20181101_171828_model_27  0.989275  0.141328   \n",
       "21  StackedEnsemble_AllModels_0_AutoML_20181101_17...  0.988848  0.076259   \n",
       "22          GBM_grid_0_AutoML_20181101_171828_model_7  0.988810  0.140655   \n",
       "23         GBM_grid_0_AutoML_20181101_171828_model_26  0.988634  0.320965   \n",
       "24         GBM_grid_0_AutoML_20181101_171828_model_28  0.988370  0.152488   \n",
       "25                       XRT_0_AutoML_20181101_171828  0.988245  0.244923   \n",
       "26         GBM_grid_0_AutoML_20181101_171828_model_29  0.987768  0.191367   \n",
       "27                       DRF_0_AutoML_20181101_171828  0.986989  0.257922   \n",
       "28         GBM_grid_0_AutoML_20181101_171828_model_14  0.986474  0.254744   \n",
       "29         GBM_grid_0_AutoML_20181101_171828_model_21  0.985620  0.167150   \n",
       "30          GBM_grid_0_AutoML_20181101_171828_model_0  0.985105  0.143244   \n",
       "31         GBM_grid_0_AutoML_20181101_171828_model_10  0.978650  0.187929   \n",
       "32              DeepLearning_0_AutoML_20181101_171828  0.977067  0.191331   \n",
       "33         GBM_grid_0_AutoML_20181101_171828_model_12  0.972785  0.497331   \n",
       "34         GBM_grid_0_AutoML_20181101_171828_model_18  0.863672  0.628657   \n",
       "35         GBM_grid_0_AutoML_20181101_171828_model_17  0.863308  0.628878   \n",
       "36         GBM_grid_0_AutoML_20181101_171828_model_22  0.861311  0.628815   \n",
       "37         GBM_grid_0_AutoML_20181101_171828_model_23  0.834949  0.631305   \n",
       "\n",
       "    mean_per_class_error      rmse       mse  \n",
       "0               0.028044  0.149942  0.022483  \n",
       "1               0.030744  0.148942  0.022184  \n",
       "2               0.024327  0.144018  0.020741  \n",
       "3               0.026186  0.152650  0.023302  \n",
       "4               0.028383  0.169952  0.028884  \n",
       "5               0.022807  0.148049  0.021919  \n",
       "6               0.029903  0.166348  0.027672  \n",
       "7               0.020948  0.148629  0.022091  \n",
       "8               0.021288  0.140211  0.019659  \n",
       "9               0.025507  0.141896  0.020135  \n",
       "10              0.020948  0.147155  0.021655  \n",
       "11              0.025846  0.142762  0.020381  \n",
       "12              0.034462  0.160139  0.025645  \n",
       "13              0.029564  0.155999  0.024336  \n",
       "14              0.022807  0.137939  0.019027  \n",
       "15              0.025846  0.149242  0.022273  \n",
       "16              0.024327  0.153467  0.023552  \n",
       "17              0.035479  0.181506  0.032944  \n",
       "18              0.041219  0.184691  0.034111  \n",
       "19              0.038519  0.181473  0.032932  \n",
       "20              0.036999  0.181453  0.032925  \n",
       "21              0.023988  0.132483  0.017552  \n",
       "22              0.031762  0.175325  0.030739  \n",
       "23              0.042236  0.196083  0.038448  \n",
       "24              0.040377  0.188195  0.035417  \n",
       "25              0.029564  0.166772  0.027813  \n",
       "26              0.050010  0.213969  0.045783  \n",
       "27              0.048315  0.181033  0.032773  \n",
       "28              0.039536  0.244523  0.059791  \n",
       "29              0.054393  0.197807  0.039128  \n",
       "30              0.044258  0.185215  0.034305  \n",
       "31              0.052032  0.209580  0.043924  \n",
       "32              0.052371  0.202730  0.041099  \n",
       "33              0.049156  0.200047  0.040019  \n",
       "34              0.189742  0.467911  0.218941  \n",
       "35              0.193459  0.468019  0.219042  \n",
       "36              0.191261  0.467990  0.219014  \n",
       "37              0.203255  0.469211  0.220159  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get leaderboard\n",
    "aml_leaderboard_df=aml.leaderboard.as_data_frame()\n",
    "aml_leaderboard_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# STart best model as first model\n",
    "\n",
    "model_set=aml_leaderboard_df['model_id']\n",
    "mod_best=h2o.get_model(model_set[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GBM_grid_0_AutoML_20181101_171828_model_19'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm = mod_best._id\n",
    "gbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.8966875174084215: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>B</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>B</td>\n",
       "<td>269.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/269.0)</td></tr>\n",
       "<tr><td>M</td>\n",
       "<td>0.0</td>\n",
       "<td>148.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/148.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>269.0</td>\n",
       "<td>148.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/417.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       B    M    Error    Rate\n",
       "-----  ---  ---  -------  -----------\n",
       "B      269  0    0        (0.0/269.0)\n",
       "M      0    148  0        (0.0/148.0)\n",
       "Total  269  148  0        (0.0/417.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_best.confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.8966875174084215: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>B</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>B</td>\n",
       "<td>269.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/269.0)</td></tr>\n",
       "<tr><td>M</td>\n",
       "<td>0.0</td>\n",
       "<td>148.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/148.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>269.0</td>\n",
       "<td>148.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/417.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       B    M    Error    Rate\n",
       "-----  ---  ---  -------  -----------\n",
       "B      269  0    0        (0.0/269.0)\n",
       "M      0    148  0        (0.0/148.0)\n",
       "Total  269  148  0        (0.0/417.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.8966875174084215: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>B</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>B</td>\n",
       "<td>269.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/269.0)</td></tr>\n",
       "<tr><td>M</td>\n",
       "<td>0.0</td>\n",
       "<td>148.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/148.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>269.0</td>\n",
       "<td>148.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/417.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       B    M    Error    Rate\n",
       "-----  ---  ---  -------  -----------\n",
       "B      269  0    0        (0.0/269.0)\n",
       "M      0    148  0        (0.0/148.0)\n",
       "Total  269  148  0        (0.0/417.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.8966875174084215: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>B</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>B</td>\n",
       "<td>269.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/269.0)</td></tr>\n",
       "<tr><td>M</td>\n",
       "<td>0.0</td>\n",
       "<td>148.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/148.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>269.0</td>\n",
       "<td>148.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/417.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       B    M    Error    Rate\n",
       "-----  ---  ---  -------  -----------\n",
       "B      269  0    0        (0.0/269.0)\n",
       "M      0    148  0        (0.0/148.0)\n",
       "Total  269  148  0        (0.0/417.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.8966875174084215: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>B</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>B</td>\n",
       "<td>269.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/269.0)</td></tr>\n",
       "<tr><td>M</td>\n",
       "<td>0.0</td>\n",
       "<td>148.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/148.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>269.0</td>\n",
       "<td>148.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/417.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       B    M    Error    Rate\n",
       "-----  ---  ---  -------  -----------\n",
       "B      269  0    0        (0.0/269.0)\n",
       "M      0    148  0        (0.0/148.0)\n",
       "Total  269  148  0        (0.0/417.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Act/Pred) for max precision @ threshold = 0.998127415902459: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>B</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>B</td>\n",
       "<td>269.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/269.0)</td></tr>\n",
       "<tr><td>M</td>\n",
       "<td>147.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9932</td>\n",
       "<td> (147.0/148.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>416.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.3525</td>\n",
       "<td> (147.0/417.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       B    M    Error    Rate\n",
       "-----  ---  ---  -------  -------------\n",
       "B      269  0    0        (0.0/269.0)\n",
       "M      147  1    0.9932   (147.0/148.0)\n",
       "Total  416  1    0.3525   (147.0/417.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.8966875174084215: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>B</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>B</td>\n",
       "<td>269.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/269.0)</td></tr>\n",
       "<tr><td>M</td>\n",
       "<td>0.0</td>\n",
       "<td>148.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/148.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>269.0</td>\n",
       "<td>148.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/417.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       B    M    Error    Rate\n",
       "-----  ---  ---  -------  -----------\n",
       "B      269  0    0        (0.0/269.0)\n",
       "M      0    148  0        (0.0/148.0)\n",
       "Total  269  148  0        (0.0/417.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Act/Pred) for max precision @ threshold = 0.998127415902459: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>B</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>B</td>\n",
       "<td>269.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/269.0)</td></tr>\n",
       "<tr><td>M</td>\n",
       "<td>147.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9932</td>\n",
       "<td> (147.0/148.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>416.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.3525</td>\n",
       "<td> (147.0/417.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       B    M    Error    Rate\n",
       "-----  ---  ---  -------  -------------\n",
       "B      269  0    0        (0.0/269.0)\n",
       "M      147  1    0.9932   (147.0/148.0)\n",
       "Total  416  1    0.3525   (147.0/417.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.8966875174084215: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>B</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>B</td>\n",
       "<td>269.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/269.0)</td></tr>\n",
       "<tr><td>M</td>\n",
       "<td>0.0</td>\n",
       "<td>148.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/148.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>269.0</td>\n",
       "<td>148.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/417.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       B    M    Error    Rate\n",
       "-----  ---  ---  -------  -----------\n",
       "B      269  0    0        (0.0/269.0)\n",
       "M      0    148  0        (0.0/148.0)\n",
       "Total  269  148  0        (0.0/417.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.8966875174084215: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>B</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>B</td>\n",
       "<td>269.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/269.0)</td></tr>\n",
       "<tr><td>M</td>\n",
       "<td>0.0</td>\n",
       "<td>148.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/148.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>269.0</td>\n",
       "<td>148.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/417.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       B    M    Error    Rate\n",
       "-----  ---  ---  -------  -----------\n",
       "B      269  0    0        (0.0/269.0)\n",
       "M      0    148  0        (0.0/148.0)\n",
       "Total  269  148  0        (0.0/417.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.8966875174084215: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>B</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>B</td>\n",
       "<td>269.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/269.0)</td></tr>\n",
       "<tr><td>M</td>\n",
       "<td>0.0</td>\n",
       "<td>148.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/148.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>269.0</td>\n",
       "<td>148.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/417.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       B    M    Error    Rate\n",
       "-----  ---  ---  -------  -----------\n",
       "B      269  0    0        (0.0/269.0)\n",
       "M      0    148  0        (0.0/148.0)\n",
       "Total  269  148  0        (0.0/417.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[, , , , , , , , , ]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_best.confusion_matrix(metrics=[\"f1\",\"f2\",\"f0point5\",\"accuracy\",\"precision\",\"recall\",\"specificity\",\"absolute_mcc\",\"min_per_class_accuracy\",\"mean_per_class_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function h2o.model.model_base.ModelBase._get_metrics>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_best._get_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "h2o.estimators.gbm.H2OGradientBoostingEstimator"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mod_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OGradientBoostingEstimator :  Gradient Boosting Machine\n",
      "Model Key:  GBM_grid_0_AutoML_20181101_171828_model_19\n",
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 8.725328652034925e-05\n",
      "RMSE: 0.009340946767879006\n",
      "LogLoss: 0.004594706366768465\n",
      "Mean Per-Class Error: 0.0\n",
      "AUC: 1.0\n",
      "Gini: 1.0\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.8966875174084215: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>B</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>B</td>\n",
       "<td>269.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/269.0)</td></tr>\n",
       "<tr><td>M</td>\n",
       "<td>0.0</td>\n",
       "<td>148.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/148.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>269.0</td>\n",
       "<td>148.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/417.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       B    M    Error    Rate\n",
       "-----  ---  ---  -------  -----------\n",
       "B      269  0    0        (0.0/269.0)\n",
       "M      0    148  0        (0.0/148.0)\n",
       "Total  269  148  0        (0.0/417.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.8966875</td>\n",
       "<td>1.0</td>\n",
       "<td>144.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.8966875</td>\n",
       "<td>1.0</td>\n",
       "<td>144.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.8966875</td>\n",
       "<td>1.0</td>\n",
       "<td>144.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.8966875</td>\n",
       "<td>1.0</td>\n",
       "<td>144.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9981274</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.8966875</td>\n",
       "<td>1.0</td>\n",
       "<td>144.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9981274</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.8966875</td>\n",
       "<td>1.0</td>\n",
       "<td>144.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.8966875</td>\n",
       "<td>1.0</td>\n",
       "<td>144.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.8966875</td>\n",
       "<td>1.0</td>\n",
       "<td>144.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value    idx\n",
       "---------------------------  -----------  -------  -----\n",
       "max f1                       0.896688     1        144\n",
       "max f2                       0.896688     1        144\n",
       "max f0point5                 0.896688     1        144\n",
       "max accuracy                 0.896688     1        144\n",
       "max precision                0.998127     1        0\n",
       "max recall                   0.896688     1        144\n",
       "max specificity              0.998127     1        0\n",
       "max absolute_mcc             0.896688     1        144\n",
       "max min_per_class_accuracy   0.896688     1        144\n",
       "max mean_per_class_accuracy  0.896688     1        144"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 35.49 %, avg score: 35.47 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0119904</td>\n",
       "<td>0.9981061</td>\n",
       "<td>2.8175676</td>\n",
       "<td>2.8175676</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9981154</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9981154</td>\n",
       "<td>0.0337838</td>\n",
       "<td>0.0337838</td>\n",
       "<td>181.7567568</td>\n",
       "<td>181.7567568</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0215827</td>\n",
       "<td>0.9980654</td>\n",
       "<td>2.8175676</td>\n",
       "<td>2.8175676</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9980811</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9981002</td>\n",
       "<td>0.0270270</td>\n",
       "<td>0.0608108</td>\n",
       "<td>181.7567568</td>\n",
       "<td>181.7567568</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0311751</td>\n",
       "<td>0.9980311</td>\n",
       "<td>2.8175676</td>\n",
       "<td>2.8175676</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9980464</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9980836</td>\n",
       "<td>0.0270270</td>\n",
       "<td>0.0878378</td>\n",
       "<td>181.7567568</td>\n",
       "<td>181.7567568</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0407674</td>\n",
       "<td>0.9980020</td>\n",
       "<td>2.8175676</td>\n",
       "<td>2.8175676</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9980098</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9980663</td>\n",
       "<td>0.0270270</td>\n",
       "<td>0.1148649</td>\n",
       "<td>181.7567568</td>\n",
       "<td>181.7567568</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0503597</td>\n",
       "<td>0.9979791</td>\n",
       "<td>2.8175676</td>\n",
       "<td>2.8175676</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9979909</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9980519</td>\n",
       "<td>0.0270270</td>\n",
       "<td>0.1418919</td>\n",
       "<td>181.7567568</td>\n",
       "<td>181.7567568</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1007194</td>\n",
       "<td>0.9978021</td>\n",
       "<td>2.8175676</td>\n",
       "<td>2.8175676</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9978845</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9979682</td>\n",
       "<td>0.1418919</td>\n",
       "<td>0.2837838</td>\n",
       "<td>181.7567568</td>\n",
       "<td>181.7567568</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1510791</td>\n",
       "<td>0.9974487</td>\n",
       "<td>2.8175676</td>\n",
       "<td>2.8175676</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9976834</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9978733</td>\n",
       "<td>0.1418919</td>\n",
       "<td>0.4256757</td>\n",
       "<td>181.7567568</td>\n",
       "<td>181.7567568</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2014388</td>\n",
       "<td>0.9967618</td>\n",
       "<td>2.8175676</td>\n",
       "<td>2.8175676</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9971709</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9976977</td>\n",
       "<td>0.1418919</td>\n",
       "<td>0.5675676</td>\n",
       "<td>181.7567568</td>\n",
       "<td>181.7567568</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.2997602</td>\n",
       "<td>0.9895620</td>\n",
       "<td>2.8175676</td>\n",
       "<td>2.8175676</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9943900</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9966128</td>\n",
       "<td>0.2770270</td>\n",
       "<td>0.8445946</td>\n",
       "<td>181.7567568</td>\n",
       "<td>181.7567568</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4004796</td>\n",
       "<td>0.0114924</td>\n",
       "<td>1.5429537</td>\n",
       "<td>2.4970060</td>\n",
       "<td>0.5476190</td>\n",
       "<td>0.5428435</td>\n",
       "<td>0.8862275</td>\n",
       "<td>0.8824911</td>\n",
       "<td>0.1554054</td>\n",
       "<td>1.0</td>\n",
       "<td>54.2953668</td>\n",
       "<td>149.7005988</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5011990</td>\n",
       "<td>0.0030950</td>\n",
       "<td>0.0</td>\n",
       "<td>1.9952153</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0055142</td>\n",
       "<td>0.7081340</td>\n",
       "<td>0.7062566</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>99.5215311</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.5995204</td>\n",
       "<td>0.0019100</td>\n",
       "<td>0.0</td>\n",
       "<td>1.668</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0023455</td>\n",
       "<td>0.592</td>\n",
       "<td>0.5908151</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.8</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7002398</td>\n",
       "<td>0.0015354</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4280822</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0016964</td>\n",
       "<td>0.5068493</td>\n",
       "<td>0.5060789</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.8082192</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7985612</td>\n",
       "<td>0.0012966</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2522523</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0013903</td>\n",
       "<td>0.4444444</td>\n",
       "<td>0.4439401</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.2252252</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8992806</td>\n",
       "<td>0.0011626</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1120000</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0012278</td>\n",
       "<td>0.3946667</td>\n",
       "<td>0.3943563</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.2000000</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0010426</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0010974</td>\n",
       "<td>0.3549161</td>\n",
       "<td>0.3547475</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain\n",
       "--  -------  --------------------------  -----------------  -------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------\n",
       "    1        0.0119904                   0.998106           2.81757  2.81757            1                0.998115    1                           0.998115            0.0337838       0.0337838                  181.757  181.757\n",
       "    2        0.0215827                   0.998065           2.81757  2.81757            1                0.998081    1                           0.9981              0.027027        0.0608108                  181.757  181.757\n",
       "    3        0.0311751                   0.998031           2.81757  2.81757            1                0.998046    1                           0.998084            0.027027        0.0878378                  181.757  181.757\n",
       "    4        0.0407674                   0.998002           2.81757  2.81757            1                0.99801     1                           0.998066            0.027027        0.114865                   181.757  181.757\n",
       "    5        0.0503597                   0.997979           2.81757  2.81757            1                0.997991    1                           0.998052            0.027027        0.141892                   181.757  181.757\n",
       "    6        0.100719                    0.997802           2.81757  2.81757            1                0.997885    1                           0.997968            0.141892        0.283784                   181.757  181.757\n",
       "    7        0.151079                    0.997449           2.81757  2.81757            1                0.997683    1                           0.997873            0.141892        0.425676                   181.757  181.757\n",
       "    8        0.201439                    0.996762           2.81757  2.81757            1                0.997171    1                           0.997698            0.141892        0.567568                   181.757  181.757\n",
       "    9        0.29976                     0.989562           2.81757  2.81757            1                0.99439     1                           0.996613            0.277027        0.844595                   181.757  181.757\n",
       "    10       0.40048                     0.0114924          1.54295  2.49701            0.547619         0.542843    0.886228                    0.882491            0.155405        1                          54.2954  149.701\n",
       "    11       0.501199                    0.00309498         0        1.99522            0                0.00551425  0.708134                    0.706257            0               1                          -100     99.5215\n",
       "    12       0.59952                     0.00190999         0        1.668              0                0.00234554  0.592                       0.590815            0               1                          -100     66.8\n",
       "    13       0.70024                     0.0015354          0        1.42808            0                0.00169639  0.506849                    0.506079            0               1                          -100     42.8082\n",
       "    14       0.798561                    0.00129664         0        1.25225            0                0.00139034  0.444444                    0.44394             0               1                          -100     25.2252\n",
       "    15       0.899281                    0.00116258         0        1.112              0                0.00122778  0.394667                    0.394356            0               1                          -100     11.2\n",
       "    16       1                           0.00104264         0        1                  0                0.00109736  0.354916                    0.354747            0               1                          -100     0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 0.04430163880167658\n",
      "RMSE: 0.2104795448533576\n",
      "LogLoss: 0.12347704631577848\n",
      "Mean Per-Class Error: 0.018867924528301883\n",
      "AUC: 0.9953980671882191\n",
      "Gini: 0.9907961343764382\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.11099959562203308: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>B</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>B</td>\n",
       "<td>51.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0377</td>\n",
       "<td> (2.0/53.0)</td></tr>\n",
       "<tr><td>M</td>\n",
       "<td>0.0</td>\n",
       "<td>41.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/41.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>51.0</td>\n",
       "<td>43.0</td>\n",
       "<td>0.0213</td>\n",
       "<td> (2.0/94.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       B    M    Error    Rate\n",
       "-----  ---  ---  -------  ----------\n",
       "B      51   2    0.0377   (2.0/53.0)\n",
       "M      0    41   0        (0.0/41.0)\n",
       "Total  51   43   0.0213   (2.0/94.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.1109996</td>\n",
       "<td>0.9761905</td>\n",
       "<td>42.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1109996</td>\n",
       "<td>0.9903382</td>\n",
       "<td>42.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.2772538</td>\n",
       "<td>0.9701493</td>\n",
       "<td>39.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.1109996</td>\n",
       "<td>0.9787234</td>\n",
       "<td>42.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9981232</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.1109996</td>\n",
       "<td>1.0</td>\n",
       "<td>42.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9981232</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.1109996</td>\n",
       "<td>0.9578662</td>\n",
       "<td>42.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.2588897</td>\n",
       "<td>0.9622642</td>\n",
       "<td>41.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.1109996</td>\n",
       "<td>0.9811321</td>\n",
       "<td>42.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.111        0.97619   42\n",
       "max f2                       0.111        0.990338  42\n",
       "max f0point5                 0.277254     0.970149  39\n",
       "max accuracy                 0.111        0.978723  42\n",
       "max precision                0.998123     1         0\n",
       "max recall                   0.111        1         42\n",
       "max specificity              0.998123     1         0\n",
       "max absolute_mcc             0.111        0.957866  42\n",
       "max min_per_class_accuracy   0.25889      0.962264  41\n",
       "max mean_per_class_accuracy  0.111        0.981132  42"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 43.62 %, avg score: 38.76 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0106383</td>\n",
       "<td>0.9981121</td>\n",
       "<td>2.2926829</td>\n",
       "<td>2.2926829</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9981232</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9981232</td>\n",
       "<td>0.0243902</td>\n",
       "<td>0.0243902</td>\n",
       "<td>129.2682927</td>\n",
       "<td>129.2682927</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0212766</td>\n",
       "<td>0.9981031</td>\n",
       "<td>2.2926829</td>\n",
       "<td>2.2926829</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9981112</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9981172</td>\n",
       "<td>0.0243902</td>\n",
       "<td>0.0487805</td>\n",
       "<td>129.2682927</td>\n",
       "<td>129.2682927</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0319149</td>\n",
       "<td>0.9980624</td>\n",
       "<td>2.2926829</td>\n",
       "<td>2.2926829</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9981018</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9981121</td>\n",
       "<td>0.0243902</td>\n",
       "<td>0.0731707</td>\n",
       "<td>129.2682927</td>\n",
       "<td>129.2682927</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0425532</td>\n",
       "<td>0.9980132</td>\n",
       "<td>2.2926829</td>\n",
       "<td>2.2926829</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9980519</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9980970</td>\n",
       "<td>0.0243902</td>\n",
       "<td>0.0975610</td>\n",
       "<td>129.2682927</td>\n",
       "<td>129.2682927</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0531915</td>\n",
       "<td>0.9979764</td>\n",
       "<td>2.2926829</td>\n",
       "<td>2.2926829</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9979981</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9980773</td>\n",
       "<td>0.0243902</td>\n",
       "<td>0.1219512</td>\n",
       "<td>129.2682927</td>\n",
       "<td>129.2682927</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1063830</td>\n",
       "<td>0.9976274</td>\n",
       "<td>2.2926829</td>\n",
       "<td>2.2926829</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9978195</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9979484</td>\n",
       "<td>0.1219512</td>\n",
       "<td>0.2439024</td>\n",
       "<td>129.2682927</td>\n",
       "<td>129.2682927</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1489362</td>\n",
       "<td>0.9970195</td>\n",
       "<td>2.2926829</td>\n",
       "<td>2.2926829</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9975151</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9978246</td>\n",
       "<td>0.0975610</td>\n",
       "<td>0.3414634</td>\n",
       "<td>129.2682927</td>\n",
       "<td>129.2682927</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2021277</td>\n",
       "<td>0.9952696</td>\n",
       "<td>2.2926829</td>\n",
       "<td>2.2926829</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9963954</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9974485</td>\n",
       "<td>0.1219512</td>\n",
       "<td>0.4634146</td>\n",
       "<td>129.2682927</td>\n",
       "<td>129.2682927</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.2978723</td>\n",
       "<td>0.9778763</td>\n",
       "<td>2.2926829</td>\n",
       "<td>2.2926829</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9901523</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9951033</td>\n",
       "<td>0.2195122</td>\n",
       "<td>0.6829268</td>\n",
       "<td>129.2682927</td>\n",
       "<td>129.2682927</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4042553</td>\n",
       "<td>0.3347559</td>\n",
       "<td>2.0634146</td>\n",
       "<td>2.2323492</td>\n",
       "<td>0.9</td>\n",
       "<td>0.6943734</td>\n",
       "<td>0.9736842</td>\n",
       "<td>0.9159638</td>\n",
       "<td>0.2195122</td>\n",
       "<td>0.9024390</td>\n",
       "<td>106.3414634</td>\n",
       "<td>123.2349166</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0384667</td>\n",
       "<td>1.0189702</td>\n",
       "<td>2.0</td>\n",
       "<td>0.4444444</td>\n",
       "<td>0.1631024</td>\n",
       "<td>0.8723404</td>\n",
       "<td>0.7717989</td>\n",
       "<td>0.0975610</td>\n",
       "<td>1.0</td>\n",
       "<td>1.8970190</td>\n",
       "<td>100.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.5957447</td>\n",
       "<td>0.0043168</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6785714</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0101406</td>\n",
       "<td>0.7321429</td>\n",
       "<td>0.6493895</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>67.8571429</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7021277</td>\n",
       "<td>0.0024024</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4242424</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0030699</td>\n",
       "<td>0.6212121</td>\n",
       "<td>0.5514623</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.4242424</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7978723</td>\n",
       "<td>0.0016681</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2533333</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0019583</td>\n",
       "<td>0.5466667</td>\n",
       "<td>0.4855218</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.3333333</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8936170</td>\n",
       "<td>0.0012750</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1190476</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0015016</td>\n",
       "<td>0.4880952</td>\n",
       "<td>0.4336625</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.9047619</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0010107</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0011077</td>\n",
       "<td>0.4361702</td>\n",
       "<td>0.3876460</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain\n",
       "--  -------  --------------------------  -----------------  -------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------\n",
       "    1        0.0106383                   0.998112           2.29268  2.29268            1                0.998123    1                           0.998123            0.0243902       0.0243902                  129.268  129.268\n",
       "    2        0.0212766                   0.998103           2.29268  2.29268            1                0.998111    1                           0.998117            0.0243902       0.0487805                  129.268  129.268\n",
       "    3        0.0319149                   0.998062           2.29268  2.29268            1                0.998102    1                           0.998112            0.0243902       0.0731707                  129.268  129.268\n",
       "    4        0.0425532                   0.998013           2.29268  2.29268            1                0.998052    1                           0.998097            0.0243902       0.097561                   129.268  129.268\n",
       "    5        0.0531915                   0.997976           2.29268  2.29268            1                0.997998    1                           0.998077            0.0243902       0.121951                   129.268  129.268\n",
       "    6        0.106383                    0.997627           2.29268  2.29268            1                0.99782     1                           0.997948            0.121951        0.243902                   129.268  129.268\n",
       "    7        0.148936                    0.997019           2.29268  2.29268            1                0.997515    1                           0.997825            0.097561        0.341463                   129.268  129.268\n",
       "    8        0.202128                    0.99527            2.29268  2.29268            1                0.996395    1                           0.997448            0.121951        0.463415                   129.268  129.268\n",
       "    9        0.297872                    0.977876           2.29268  2.29268            1                0.990152    1                           0.995103            0.219512        0.682927                   129.268  129.268\n",
       "    10       0.404255                    0.334756           2.06341  2.23235            0.9              0.694373    0.973684                    0.915964            0.219512        0.902439                   106.341  123.235\n",
       "    11       0.5                         0.0384667          1.01897  2                  0.444444         0.163102    0.87234                     0.771799            0.097561        1                          1.89702  100\n",
       "    12       0.595745                    0.00431683         0        1.67857            0                0.0101406   0.732143                    0.64939             0               1                          -100     67.8571\n",
       "    13       0.702128                    0.00240242         0        1.42424            0                0.00306995  0.621212                    0.551462            0               1                          -100     42.4242\n",
       "    14       0.797872                    0.00166812         0        1.25333            0                0.00195831  0.546667                    0.485522            0               1                          -100     25.3333\n",
       "    15       0.893617                    0.00127503         0        1.11905            0                0.00150158  0.488095                    0.433663            0               1                          -100     11.9048\n",
       "    16       1                           0.00101074         0        1                  0                0.00110774  0.43617                     0.387646            0               1                          -100     0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.022482582393773567\n",
      "RMSE: 0.14994193007219017\n",
      "LogLoss: 0.08407808466932246\n",
      "Mean Per-Class Error: 0.028044308248769134\n",
      "AUC: 0.9949512709735757\n",
      "Gini: 0.9899025419471514\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.3836965580654469: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>B</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>B</td>\n",
       "<td>263.0</td>\n",
       "<td>6.0</td>\n",
       "<td>0.0223</td>\n",
       "<td> (6.0/269.0)</td></tr>\n",
       "<tr><td>M</td>\n",
       "<td>5.0</td>\n",
       "<td>143.0</td>\n",
       "<td>0.0338</td>\n",
       "<td> (5.0/148.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>268.0</td>\n",
       "<td>149.0</td>\n",
       "<td>0.0264</td>\n",
       "<td> (11.0/417.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       B    M    Error    Rate\n",
       "-----  ---  ---  -------  ------------\n",
       "B      263  6    0.0223   (6.0/269.0)\n",
       "M      5    143  0.0338   (5.0/148.0)\n",
       "Total  268  149  0.0264   (11.0/417.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.3836966</td>\n",
       "<td>0.9629630</td>\n",
       "<td>144.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1587677</td>\n",
       "<td>0.9679573</td>\n",
       "<td>152.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.8299984</td>\n",
       "<td>0.9754335</td>\n",
       "<td>131.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.3836966</td>\n",
       "<td>0.9736211</td>\n",
       "<td>144.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9998891</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0086395</td>\n",
       "<td>1.0</td>\n",
       "<td>208.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9998891</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.3836966</td>\n",
       "<td>0.9424920</td>\n",
       "<td>144.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.3836966</td>\n",
       "<td>0.9662162</td>\n",
       "<td>144.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.3836966</td>\n",
       "<td>0.9719557</td>\n",
       "<td>144.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.383697     0.962963  144\n",
       "max f2                       0.158768     0.967957  152\n",
       "max f0point5                 0.829998     0.975434  131\n",
       "max accuracy                 0.383697     0.973621  144\n",
       "max precision                0.999889     1         0\n",
       "max recall                   0.00863954   1         208\n",
       "max specificity              0.999889     1         0\n",
       "max absolute_mcc             0.383697     0.942492  144\n",
       "max min_per_class_accuracy   0.383697     0.966216  144\n",
       "max mean_per_class_accuracy  0.383697     0.971956  144"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 35.49 %, avg score: 34.85 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0119904</td>\n",
       "<td>0.9998774</td>\n",
       "<td>2.8175676</td>\n",
       "<td>2.8175676</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9998837</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9998837</td>\n",
       "<td>0.0337838</td>\n",
       "<td>0.0337838</td>\n",
       "<td>181.7567568</td>\n",
       "<td>181.7567568</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0215827</td>\n",
       "<td>0.9998458</td>\n",
       "<td>2.8175676</td>\n",
       "<td>2.8175676</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9998662</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9998759</td>\n",
       "<td>0.0270270</td>\n",
       "<td>0.0608108</td>\n",
       "<td>181.7567568</td>\n",
       "<td>181.7567568</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0311751</td>\n",
       "<td>0.9997598</td>\n",
       "<td>2.8175676</td>\n",
       "<td>2.8175676</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9998043</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9998539</td>\n",
       "<td>0.0270270</td>\n",
       "<td>0.0878378</td>\n",
       "<td>181.7567568</td>\n",
       "<td>181.7567568</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0407674</td>\n",
       "<td>0.9993740</td>\n",
       "<td>2.8175676</td>\n",
       "<td>2.8175676</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9994904</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9997684</td>\n",
       "<td>0.0270270</td>\n",
       "<td>0.1148649</td>\n",
       "<td>181.7567568</td>\n",
       "<td>181.7567568</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0503597</td>\n",
       "<td>0.9993031</td>\n",
       "<td>2.8175676</td>\n",
       "<td>2.8175676</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9993546</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9996895</td>\n",
       "<td>0.0270270</td>\n",
       "<td>0.1418919</td>\n",
       "<td>181.7567568</td>\n",
       "<td>181.7567568</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1007194</td>\n",
       "<td>0.9963664</td>\n",
       "<td>2.8175676</td>\n",
       "<td>2.8175676</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9984672</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9990784</td>\n",
       "<td>0.1418919</td>\n",
       "<td>0.2837838</td>\n",
       "<td>181.7567568</td>\n",
       "<td>181.7567568</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1510791</td>\n",
       "<td>0.9927043</td>\n",
       "<td>2.8175676</td>\n",
       "<td>2.8175676</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9941530</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9974366</td>\n",
       "<td>0.1418919</td>\n",
       "<td>0.4256757</td>\n",
       "<td>181.7567568</td>\n",
       "<td>181.7567568</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2014388</td>\n",
       "<td>0.9884651</td>\n",
       "<td>2.8175676</td>\n",
       "<td>2.8175676</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9905942</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9957260</td>\n",
       "<td>0.1418919</td>\n",
       "<td>0.5675676</td>\n",
       "<td>181.7567568</td>\n",
       "<td>181.7567568</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.2997602</td>\n",
       "<td>0.9439135</td>\n",
       "<td>2.7488464</td>\n",
       "<td>2.7950270</td>\n",
       "<td>0.9756098</td>\n",
       "<td>0.9802184</td>\n",
       "<td>0.992</td>\n",
       "<td>0.9906395</td>\n",
       "<td>0.2702703</td>\n",
       "<td>0.8378378</td>\n",
       "<td>174.8846407</td>\n",
       "<td>179.5027027</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4004796</td>\n",
       "<td>0.0504009</td>\n",
       "<td>1.4087838</td>\n",
       "<td>2.4463910</td>\n",
       "<td>0.5</td>\n",
       "<td>0.4769098</td>\n",
       "<td>0.8682635</td>\n",
       "<td>0.8614380</td>\n",
       "<td>0.1418919</td>\n",
       "<td>0.9797297</td>\n",
       "<td>40.8783784</td>\n",
       "<td>144.6391002</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5011990</td>\n",
       "<td>0.0094797</td>\n",
       "<td>0.1341699</td>\n",
       "<td>1.9817341</td>\n",
       "<td>0.0476190</td>\n",
       "<td>0.0178849</td>\n",
       "<td>0.7033493</td>\n",
       "<td>0.6919202</td>\n",
       "<td>0.0135135</td>\n",
       "<td>0.9932432</td>\n",
       "<td>-86.5830116</td>\n",
       "<td>98.1734126</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.5995204</td>\n",
       "<td>0.0066210</td>\n",
       "<td>0.0687212</td>\n",
       "<td>1.668</td>\n",
       "<td>0.0243902</td>\n",
       "<td>0.0076992</td>\n",
       "<td>0.592</td>\n",
       "<td>0.5797079</td>\n",
       "<td>0.0067568</td>\n",
       "<td>1.0</td>\n",
       "<td>-93.1278840</td>\n",
       "<td>66.8</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7002398</td>\n",
       "<td>0.0043137</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4280822</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0055003</td>\n",
       "<td>0.5068493</td>\n",
       "<td>0.4971164</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.8082192</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7985612</td>\n",
       "<td>0.0024205</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2522523</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0036099</td>\n",
       "<td>0.4444444</td>\n",
       "<td>0.4363544</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.2252252</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8992806</td>\n",
       "<td>0.0003477</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1120000</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0007102</td>\n",
       "<td>0.3946667</td>\n",
       "<td>0.3875622</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.2000000</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000587</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001368</td>\n",
       "<td>0.3549161</td>\n",
       "<td>0.3485409</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0119904                   0.999877           2.81757    2.81757            1                0.999884     1                           0.999884            0.0337838       0.0337838                  181.757   181.757\n",
       "    2        0.0215827                   0.999846           2.81757    2.81757            1                0.999866     1                           0.999876            0.027027        0.0608108                  181.757   181.757\n",
       "    3        0.0311751                   0.99976            2.81757    2.81757            1                0.999804     1                           0.999854            0.027027        0.0878378                  181.757   181.757\n",
       "    4        0.0407674                   0.999374           2.81757    2.81757            1                0.99949      1                           0.999768            0.027027        0.114865                   181.757   181.757\n",
       "    5        0.0503597                   0.999303           2.81757    2.81757            1                0.999355     1                           0.99969             0.027027        0.141892                   181.757   181.757\n",
       "    6        0.100719                    0.996366           2.81757    2.81757            1                0.998467     1                           0.999078            0.141892        0.283784                   181.757   181.757\n",
       "    7        0.151079                    0.992704           2.81757    2.81757            1                0.994153     1                           0.997437            0.141892        0.425676                   181.757   181.757\n",
       "    8        0.201439                    0.988465           2.81757    2.81757            1                0.990594     1                           0.995726            0.141892        0.567568                   181.757   181.757\n",
       "    9        0.29976                     0.943913           2.74885    2.79503            0.97561          0.980218     0.992                       0.990639            0.27027         0.837838                   174.885   179.503\n",
       "    10       0.40048                     0.0504009          1.40878    2.44639            0.5              0.47691      0.868263                    0.861438            0.141892        0.97973                    40.8784   144.639\n",
       "    11       0.501199                    0.00947966         0.13417    1.98173            0.047619         0.0178849    0.703349                    0.69192             0.0135135       0.993243                   -86.583   98.1734\n",
       "    12       0.59952                     0.00662097         0.0687212  1.668              0.0243902        0.00769916   0.592                       0.579708            0.00675676      1                          -93.1279  66.8\n",
       "    13       0.70024                     0.0043137          0          1.42808            0                0.00550027   0.506849                    0.497116            0               1                          -100      42.8082\n",
       "    14       0.798561                    0.00242048         0          1.25225            0                0.00360995   0.444444                    0.436354            0               1                          -100      25.2252\n",
       "    15       0.899281                    0.000347677        0          1.112              0                0.000710158  0.394667                    0.387562            0               1                          -100      11.2\n",
       "    16       1                           5.86706e-05        0          1                  0                0.000136793  0.354916                    0.348541            0               1                          -100      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>mean</b></td>\n",
       "<td><b>sd</b></td>\n",
       "<td><b>cv_1_valid</b></td>\n",
       "<td><b>cv_2_valid</b></td>\n",
       "<td><b>cv_3_valid</b></td>\n",
       "<td><b>cv_4_valid</b></td>\n",
       "<td><b>cv_5_valid</b></td></tr>\n",
       "<tr><td>accuracy</td>\n",
       "<td>0.9831899</td>\n",
       "<td>0.0087041</td>\n",
       "<td>0.9880952</td>\n",
       "<td>0.9880952</td>\n",
       "<td>0.9759036</td>\n",
       "<td>0.9638554</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.9938086</td>\n",
       "<td>0.0032377</td>\n",
       "<td>0.9982353</td>\n",
       "<td>0.9923611</td>\n",
       "<td>0.9880503</td>\n",
       "<td>0.9903961</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.0168101</td>\n",
       "<td>0.0087041</td>\n",
       "<td>0.0119048</td>\n",
       "<td>0.0119048</td>\n",
       "<td>0.0240964</td>\n",
       "<td>0.0361446</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>1.4</td>\n",
       "<td>0.7211103</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>2.0</td>\n",
       "<td>3.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>0.9766667</td>\n",
       "<td>0.0129115</td>\n",
       "<td>0.9770115</td>\n",
       "<td>0.9913793</td>\n",
       "<td>0.9666666</td>\n",
       "<td>0.9482759</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>0.9774838</td>\n",
       "<td>0.0106269</td>\n",
       "<td>0.9855072</td>\n",
       "<td>0.9787234</td>\n",
       "<td>0.9666666</td>\n",
       "<td>0.9565217</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>0.9784235</td>\n",
       "<td>0.0108563</td>\n",
       "<td>0.9941521</td>\n",
       "<td>0.9663866</td>\n",
       "<td>0.9666666</td>\n",
       "<td>0.9649123</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>2.874148</td>\n",
       "<td>0.2923685</td>\n",
       "<td>2.4705882</td>\n",
       "<td>3.5</td>\n",
       "<td>2.7666667</td>\n",
       "<td>2.4411764</td>\n",
       "<td>3.1923077</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>0.0840978</td>\n",
       "<td>0.0261365</td>\n",
       "<td>0.0729495</td>\n",
       "<td>0.0870149</td>\n",
       "<td>0.1083685</td>\n",
       "<td>0.1307620</td>\n",
       "<td>0.0213942</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.0271633</td>\n",
       "<td>0.0110634</td>\n",
       "<td>0.02</td>\n",
       "<td>0.0416667</td>\n",
       "<td>0.0333333</td>\n",
       "<td>0.0408163</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.9640562</td>\n",
       "<td>0.0178754</td>\n",
       "<td>0.9757048</td>\n",
       "<td>0.9708877</td>\n",
       "<td>0.9477987</td>\n",
       "<td>0.9258897</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.9815904</td>\n",
       "<td>0.0086816</td>\n",
       "<td>0.99</td>\n",
       "<td>0.9791667</td>\n",
       "<td>0.9738994</td>\n",
       "<td>0.9648859</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.0184096</td>\n",
       "<td>0.0086816</td>\n",
       "<td>0.01</td>\n",
       "<td>0.0208333</td>\n",
       "<td>0.0261006</td>\n",
       "<td>0.0351140</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.0224844</td>\n",
       "<td>0.0073379</td>\n",
       "<td>0.0246353</td>\n",
       "<td>0.0195600</td>\n",
       "<td>0.0261688</td>\n",
       "<td>0.0369580</td>\n",
       "<td>0.0051001</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.9761905</td>\n",
       "<td>0.0153567</td>\n",
       "<td>0.9714286</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9666666</td>\n",
       "<td>0.9428572</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.9023985</td>\n",
       "<td>0.0296369</td>\n",
       "<td>0.8977491</td>\n",
       "<td>0.904156</td>\n",
       "<td>0.8866185</td>\n",
       "<td>0.8471766</td>\n",
       "<td>0.9762922</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.9791176</td>\n",
       "<td>0.0123770</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9583333</td>\n",
       "<td>0.9666666</td>\n",
       "<td>0.9705882</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.1444482</td>\n",
       "<td>0.0284531</td>\n",
       "<td>0.1569563</td>\n",
       "<td>0.1398571</td>\n",
       "<td>0.1617676</td>\n",
       "<td>0.1922447</td>\n",
       "<td>0.0714152</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.9840631</td>\n",
       "<td>0.0107334</td>\n",
       "<td>0.98</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9811321</td>\n",
       "<td>0.9591837</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "                         mean       sd          cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "-----------------------  ---------  ----------  ------------  ------------  ------------  ------------  ------------\n",
       "accuracy                 0.98319    0.00870412  0.988095      0.988095      0.975904      0.963855      1\n",
       "auc                      0.993809   0.0032377   0.998235      0.992361      0.98805       0.990396      1\n",
       "err                      0.0168101  0.00870412  0.0119048     0.0119048     0.0240964     0.0361446     0\n",
       "err_count                1.4        0.72111     1             1             2             3             0\n",
       "f0point5                 0.976667   0.0129115   0.977012      0.991379      0.966667      0.948276      1\n",
       "f1                       0.977484   0.0106269   0.985507      0.978723      0.966667      0.956522      1\n",
       "f2                       0.978424   0.0108563   0.994152      0.966387      0.966667      0.964912      1\n",
       "lift_top_group           2.87415    0.292368    2.47059       3.5           2.76667       2.44118       3.19231\n",
       "logloss                  0.0840978  0.0261365   0.0729495     0.0870149     0.108368      0.130762      0.0213942\n",
       "max_per_class_error      0.0271633  0.0110634   0.02          0.0416667     0.0333333     0.0408163     0\n",
       "mcc                      0.964056   0.0178754   0.975705      0.970888      0.947799      0.92589       1\n",
       "mean_per_class_accuracy  0.98159    0.00868159  0.99          0.979167      0.973899      0.964886      1\n",
       "mean_per_class_error     0.0184096  0.00868159  0.01          0.0208333     0.0261006     0.035114      0\n",
       "mse                      0.0224844  0.00733792  0.0246353     0.01956       0.0261688     0.036958      0.00510014\n",
       "precision                0.97619    0.0153567   0.971429      1             0.966667      0.942857      1\n",
       "r2                       0.902398   0.0296369   0.897749      0.904156      0.886618      0.847177      0.976292\n",
       "recall                   0.979118   0.012377    1             0.958333      0.966667      0.970588      1\n",
       "rmse                     0.144448   0.0284531   0.156956      0.139857      0.161768      0.192245      0.0714152\n",
       "specificity              0.984063   0.0107334   0.98          1             0.981132      0.959184      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_auc</b></td>\n",
       "<td><b>training_lift</b></td>\n",
       "<td><b>training_classification_error</b></td>\n",
       "<td><b>validation_rmse</b></td>\n",
       "<td><b>validation_logloss</b></td>\n",
       "<td><b>validation_auc</b></td>\n",
       "<td><b>validation_lift</b></td>\n",
       "<td><b>validation_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-11-01 17:20:44</td>\n",
       "<td> 1 min 46.567 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4784879</td>\n",
       "<td>0.6504369</td>\n",
       "<td>0.5</td>\n",
       "<td>1.0</td>\n",
       "<td>0.6450839</td>\n",
       "<td>0.5025216</td>\n",
       "<td>0.6989862</td>\n",
       "<td>0.5</td>\n",
       "<td>1.0</td>\n",
       "<td>0.5638298</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-11-01 17:20:44</td>\n",
       "<td> 1 min 46.589 sec</td>\n",
       "<td>5.0</td>\n",
       "<td>0.3809366</td>\n",
       "<td>0.4699504</td>\n",
       "<td>0.9998995</td>\n",
       "<td>2.8175676</td>\n",
       "<td>0.0047962</td>\n",
       "<td>0.4187457</td>\n",
       "<td>0.5340051</td>\n",
       "<td>0.9880350</td>\n",
       "<td>2.2926829</td>\n",
       "<td>0.0638298</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-11-01 17:20:45</td>\n",
       "<td> 1 min 46.619 sec</td>\n",
       "<td>10.0</td>\n",
       "<td>0.3060686</td>\n",
       "<td>0.3539237</td>\n",
       "<td>0.9998493</td>\n",
       "<td>2.8175676</td>\n",
       "<td>0.0047962</td>\n",
       "<td>0.3566493</td>\n",
       "<td>0.4276028</td>\n",
       "<td>0.9894156</td>\n",
       "<td>2.2926829</td>\n",
       "<td>0.0531915</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-11-01 17:20:45</td>\n",
       "<td> 1 min 46.644 sec</td>\n",
       "<td>15.0</td>\n",
       "<td>0.2468476</td>\n",
       "<td>0.2715863</td>\n",
       "<td>0.9999498</td>\n",
       "<td>2.8175676</td>\n",
       "<td>0.0023981</td>\n",
       "<td>0.3114389</td>\n",
       "<td>0.3539051</td>\n",
       "<td>0.9903359</td>\n",
       "<td>2.2926829</td>\n",
       "<td>0.0531915</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-11-01 17:20:45</td>\n",
       "<td> 1 min 46.666 sec</td>\n",
       "<td>20.0</td>\n",
       "<td>0.2030022</td>\n",
       "<td>0.2142073</td>\n",
       "<td>0.9999498</td>\n",
       "<td>2.8175676</td>\n",
       "<td>0.0023981</td>\n",
       "<td>0.2827238</td>\n",
       "<td>0.3053763</td>\n",
       "<td>0.9894156</td>\n",
       "<td>2.2926829</td>\n",
       "<td>0.0531915</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-11-01 17:20:45</td>\n",
       "<td> 1 min 47.101 sec</td>\n",
       "<td>100.0</td>\n",
       "<td>0.0147156</td>\n",
       "<td>0.0082274</td>\n",
       "<td>1.0</td>\n",
       "<td>2.8175676</td>\n",
       "<td>0.0</td>\n",
       "<td>0.2128851</td>\n",
       "<td>0.1299639</td>\n",
       "<td>0.9949379</td>\n",
       "<td>2.2926829</td>\n",
       "<td>0.0319149</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-11-01 17:20:45</td>\n",
       "<td> 1 min 47.125 sec</td>\n",
       "<td>105.0</td>\n",
       "<td>0.0131909</td>\n",
       "<td>0.0068861</td>\n",
       "<td>1.0</td>\n",
       "<td>2.8175676</td>\n",
       "<td>0.0</td>\n",
       "<td>0.2093006</td>\n",
       "<td>0.1243006</td>\n",
       "<td>0.9958583</td>\n",
       "<td>2.2926829</td>\n",
       "<td>0.0212766</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-11-01 17:20:45</td>\n",
       "<td> 1 min 47.156 sec</td>\n",
       "<td>110.0</td>\n",
       "<td>0.0111373</td>\n",
       "<td>0.0057028</td>\n",
       "<td>1.0</td>\n",
       "<td>2.8175676</td>\n",
       "<td>0.0</td>\n",
       "<td>0.2124765</td>\n",
       "<td>0.1269457</td>\n",
       "<td>0.9953981</td>\n",
       "<td>2.2926829</td>\n",
       "<td>0.0212766</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-11-01 17:20:45</td>\n",
       "<td> 1 min 47.187 sec</td>\n",
       "<td>115.0</td>\n",
       "<td>0.0096529</td>\n",
       "<td>0.0047644</td>\n",
       "<td>1.0</td>\n",
       "<td>2.8175676</td>\n",
       "<td>0.0</td>\n",
       "<td>0.2106627</td>\n",
       "<td>0.1240695</td>\n",
       "<td>0.9958583</td>\n",
       "<td>2.2926829</td>\n",
       "<td>0.0212766</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-11-01 17:20:45</td>\n",
       "<td> 1 min 47.197 sec</td>\n",
       "<td>116.0</td>\n",
       "<td>0.0093409</td>\n",
       "<td>0.0045947</td>\n",
       "<td>1.0</td>\n",
       "<td>2.8175676</td>\n",
       "<td>0.0</td>\n",
       "<td>0.2104795</td>\n",
       "<td>0.1234770</td>\n",
       "<td>0.9953981</td>\n",
       "<td>2.2926829</td>\n",
       "<td>0.0212766</td></tr></table></div>"
      ],
      "text/plain": [
       "     timestamp            duration          number_of_trees    training_rmse         training_logloss      training_auc        training_lift       training_classification_error    validation_rmse      validation_logloss    validation_auc      validation_lift    validation_classification_error\n",
       "---  -------------------  ----------------  -----------------  --------------------  --------------------  ------------------  ------------------  -------------------------------  -------------------  --------------------  ------------------  -----------------  ---------------------------------\n",
       "     2018-11-01 17:20:44  1 min 46.567 sec  0.0                0.47848788117119334   0.6504368749643079    0.5                 1.0                 0.645083932853717                0.5025216357949578   0.6989861543176717    0.5                 1.0                0.5638297872340425\n",
       "     2018-11-01 17:20:44  1 min 46.589 sec  5.0                0.38093658396051      0.46995039586327675   0.9998995277805687  2.8175675675675675  0.004796163069544364             0.4187456726067143   0.5340051331965001    0.9880349746893695  2.292682926829268  0.06382978723404255\n",
       "     2018-11-01 17:20:45  1 min 46.619 sec  10.0               0.3060686462649166    0.3539236704549123    0.9998492916708531  2.8175675675675675  0.004796163069544364             0.3566492809664348   0.4276028234538272    0.9894155545329038  2.292682926829268  0.05319148936170213\n",
       "     2018-11-01 17:20:45  1 min 46.644 sec  15.0               0.24684757935623444   0.2715863016234861    0.9999497638902844  2.8175675675675675  0.002398081534772182             0.3114389178436729   0.3539051370085395    0.9903359410952599  2.292682926829268  0.05319148936170213\n",
       "     2018-11-01 17:20:45  1 min 46.666 sec  20.0               0.2030022119057993    0.2142073455713158    0.9999497638902844  2.8175675675675675  0.002398081534772182             0.28272383910694837  0.3053762920371252    0.9894155545329038  2.292682926829268  0.05319148936170213\n",
       "---  ---                  ---               ---                ---                   ---                   ---                 ---                 ---                              ---                  ---                   ---                 ---                ---\n",
       "     2018-11-01 17:20:45  1 min 47.101 sec  100.0              0.014715597607453593  0.008227385428282944  1.0                 2.8175675675675675  0.0                              0.21288514288482102  0.12996387177105076   0.994937873907041   2.292682926829268  0.031914893617021274\n",
       "     2018-11-01 17:20:45  1 min 47.125 sec  105.0              0.013190881966667817  0.006886146632986139  1.0                 2.8175675675675675  0.0                              0.20930057629809823  0.12430061869576108   0.9958582604693972  2.292682926829268  0.02127659574468085\n",
       "     2018-11-01 17:20:45  1 min 47.156 sec  110.0              0.011137321252181101  0.005702803962505842  1.0                 2.8175675675675675  0.0                              0.2124765318902852   0.12694567088923325   0.9953980671882191  2.292682926829268  0.02127659574468085\n",
       "     2018-11-01 17:20:45  1 min 47.187 sec  115.0              0.009652873458480071  0.004764359507816857  1.0                 2.8175675675675675  0.0                              0.21066270677997959  0.1240694903776788    0.9958582604693972  2.292682926829268  0.02127659574468085\n",
       "     2018-11-01 17:20:45  1 min 47.197 sec  116.0              0.009340946767879006  0.004594706366768465  1.0                 2.8175675675675675  0.0                              0.2104795448533576   0.12347704631577848   0.9953980671882191  2.292682926829268  0.02127659574468085"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>concave points_mean</td>\n",
       "<td>153.2989044</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1621791</td></tr>\n",
       "<tr><td>perimeter_worst</td>\n",
       "<td>139.4512787</td>\n",
       "<td>0.9096691</td>\n",
       "<td>0.1475293</td></tr>\n",
       "<tr><td>concave points_worst</td>\n",
       "<td>104.0784454</td>\n",
       "<td>0.6789249</td>\n",
       "<td>0.1101074</td></tr>\n",
       "<tr><td>area_mean</td>\n",
       "<td>74.8215332</td>\n",
       "<td>0.4880761</td>\n",
       "<td>0.0791557</td></tr>\n",
       "<tr><td>radius_worst</td>\n",
       "<td>61.0014915</td>\n",
       "<td>0.3979252</td>\n",
       "<td>0.0645351</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>symmetry_se</td>\n",
       "<td>1.8534694</td>\n",
       "<td>0.0120906</td>\n",
       "<td>0.0019608</td></tr>\n",
       "<tr><td>concave points_se</td>\n",
       "<td>1.7387568</td>\n",
       "<td>0.0113423</td>\n",
       "<td>0.0018395</td></tr>\n",
       "<tr><td>radius_se</td>\n",
       "<td>1.6000111</td>\n",
       "<td>0.0104372</td>\n",
       "<td>0.0016927</td></tr>\n",
       "<tr><td>symmetry_mean</td>\n",
       "<td>1.2100910</td>\n",
       "<td>0.0078937</td>\n",
       "<td>0.0012802</td></tr>\n",
       "<tr><td>id</td>\n",
       "<td>0.1023757</td>\n",
       "<td>0.0006678</td>\n",
       "<td>0.0001083</td></tr></table></div>"
      ],
      "text/plain": [
       "variable              relative_importance    scaled_importance      percentage\n",
       "--------------------  ---------------------  ---------------------  ----------------------\n",
       "concave points_mean   153.2989044189453      1.0                    0.16217908884973323\n",
       "perimeter_worst       139.45127868652344     0.9096691148256469     0.14752930819716678\n",
       "concave points_worst  104.07844543457031     0.6789249135801904     0.11010742388181914\n",
       "area_mean             74.821533203125        0.4880761117421153     0.07915573909165684\n",
       "radius_worst          61.00149154663086      0.39792516311742177    0.06453514038476493\n",
       "---                   ---                    ---                    ---\n",
       "symmetry_se           1.8534693717956543     0.012090558499559602   0.001960835761142974\n",
       "concave points_se     1.738756775856018      0.011342264854706524   0.0018394781796286558\n",
       "radius_se             1.6000111103057861     0.010437198598192005   0.0016926953587984921\n",
       "symmetry_mean         1.2100909948349        0.00789367020867862    0.0012801882421237822\n",
       "id                    0.10237573832273483    0.0006678178080317893  0.00010830608362422163"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n",
      "<bound method ModelBase.coef_norm of >\n"
     ]
    }
   ],
   "source": [
    "mods=mod_best.coef_norm\n",
    "print(mods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gain Lift Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_gain_lift = mod_best.gains_lift().as_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.011990</td>\n",
       "      <td>0.998106</td>\n",
       "      <td>2.817568</td>\n",
       "      <td>2.817568</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998115</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998115</td>\n",
       "      <td>0.033784</td>\n",
       "      <td>0.033784</td>\n",
       "      <td>181.756757</td>\n",
       "      <td>181.756757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0.021583</td>\n",
       "      <td>0.998065</td>\n",
       "      <td>2.817568</td>\n",
       "      <td>2.817568</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998081</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998100</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.060811</td>\n",
       "      <td>181.756757</td>\n",
       "      <td>181.756757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>0.031175</td>\n",
       "      <td>0.998031</td>\n",
       "      <td>2.817568</td>\n",
       "      <td>2.817568</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998046</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998084</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.087838</td>\n",
       "      <td>181.756757</td>\n",
       "      <td>181.756757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.040767</td>\n",
       "      <td>0.998002</td>\n",
       "      <td>2.817568</td>\n",
       "      <td>2.817568</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998010</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998066</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.114865</td>\n",
       "      <td>181.756757</td>\n",
       "      <td>181.756757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>0.050360</td>\n",
       "      <td>0.997979</td>\n",
       "      <td>2.817568</td>\n",
       "      <td>2.817568</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997991</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998052</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.141892</td>\n",
       "      <td>181.756757</td>\n",
       "      <td>181.756757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>0.100719</td>\n",
       "      <td>0.997802</td>\n",
       "      <td>2.817568</td>\n",
       "      <td>2.817568</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997885</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997968</td>\n",
       "      <td>0.141892</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>181.756757</td>\n",
       "      <td>181.756757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>0.151079</td>\n",
       "      <td>0.997449</td>\n",
       "      <td>2.817568</td>\n",
       "      <td>2.817568</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997683</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997873</td>\n",
       "      <td>0.141892</td>\n",
       "      <td>0.425676</td>\n",
       "      <td>181.756757</td>\n",
       "      <td>181.756757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "      <td>0.201439</td>\n",
       "      <td>0.996762</td>\n",
       "      <td>2.817568</td>\n",
       "      <td>2.817568</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997171</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997698</td>\n",
       "      <td>0.141892</td>\n",
       "      <td>0.567568</td>\n",
       "      <td>181.756757</td>\n",
       "      <td>181.756757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>0.299760</td>\n",
       "      <td>0.989562</td>\n",
       "      <td>2.817568</td>\n",
       "      <td>2.817568</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994390</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996613</td>\n",
       "      <td>0.277027</td>\n",
       "      <td>0.844595</td>\n",
       "      <td>181.756757</td>\n",
       "      <td>181.756757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>0.400480</td>\n",
       "      <td>0.011492</td>\n",
       "      <td>1.542954</td>\n",
       "      <td>2.497006</td>\n",
       "      <td>0.547619</td>\n",
       "      <td>0.542843</td>\n",
       "      <td>0.886228</td>\n",
       "      <td>0.882491</td>\n",
       "      <td>0.155405</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>54.295367</td>\n",
       "      <td>149.700599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>0.501199</td>\n",
       "      <td>0.003095</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.995215</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005514</td>\n",
       "      <td>0.708134</td>\n",
       "      <td>0.706257</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>99.521531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.599520</td>\n",
       "      <td>0.001910</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.668000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002346</td>\n",
       "      <td>0.592000</td>\n",
       "      <td>0.590815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>66.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.700240</td>\n",
       "      <td>0.001535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.428082</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001696</td>\n",
       "      <td>0.506849</td>\n",
       "      <td>0.506079</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>42.808219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0.798561</td>\n",
       "      <td>0.001297</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.252252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001390</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.443940</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>25.225225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>15</td>\n",
       "      <td>0.899281</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.112000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001228</td>\n",
       "      <td>0.394667</td>\n",
       "      <td>0.394356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>11.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>0.354916</td>\n",
       "      <td>0.354747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0         1                  0.011990         0.998106  2.817568   \n",
       "1         2                  0.021583         0.998065  2.817568   \n",
       "2         3                  0.031175         0.998031  2.817568   \n",
       "3         4                  0.040767         0.998002  2.817568   \n",
       "4         5                  0.050360         0.997979  2.817568   \n",
       "5         6                  0.100719         0.997802  2.817568   \n",
       "6         7                  0.151079         0.997449  2.817568   \n",
       "7         8                  0.201439         0.996762  2.817568   \n",
       "8         9                  0.299760         0.989562  2.817568   \n",
       "9        10                  0.400480         0.011492  1.542954   \n",
       "10       11                  0.501199         0.003095  0.000000   \n",
       "11       12                  0.599520         0.001910  0.000000   \n",
       "12       13                  0.700240         0.001535  0.000000   \n",
       "13       14                  0.798561         0.001297  0.000000   \n",
       "14       15                  0.899281         0.001163  0.000000   \n",
       "15       16                  1.000000         0.001043  0.000000   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0          2.817568       1.000000  0.998115                  1.000000   \n",
       "1          2.817568       1.000000  0.998081                  1.000000   \n",
       "2          2.817568       1.000000  0.998046                  1.000000   \n",
       "3          2.817568       1.000000  0.998010                  1.000000   \n",
       "4          2.817568       1.000000  0.997991                  1.000000   \n",
       "5          2.817568       1.000000  0.997885                  1.000000   \n",
       "6          2.817568       1.000000  0.997683                  1.000000   \n",
       "7          2.817568       1.000000  0.997171                  1.000000   \n",
       "8          2.817568       1.000000  0.994390                  1.000000   \n",
       "9          2.497006       0.547619  0.542843                  0.886228   \n",
       "10         1.995215       0.000000  0.005514                  0.708134   \n",
       "11         1.668000       0.000000  0.002346                  0.592000   \n",
       "12         1.428082       0.000000  0.001696                  0.506849   \n",
       "13         1.252252       0.000000  0.001390                  0.444444   \n",
       "14         1.112000       0.000000  0.001228                  0.394667   \n",
       "15         1.000000       0.000000  0.001097                  0.354916   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate        gain  \\\n",
       "0           0.998115      0.033784                 0.033784  181.756757   \n",
       "1           0.998100      0.027027                 0.060811  181.756757   \n",
       "2           0.998084      0.027027                 0.087838  181.756757   \n",
       "3           0.998066      0.027027                 0.114865  181.756757   \n",
       "4           0.998052      0.027027                 0.141892  181.756757   \n",
       "5           0.997968      0.141892                 0.283784  181.756757   \n",
       "6           0.997873      0.141892                 0.425676  181.756757   \n",
       "7           0.997698      0.141892                 0.567568  181.756757   \n",
       "8           0.996613      0.277027                 0.844595  181.756757   \n",
       "9           0.882491      0.155405                 1.000000   54.295367   \n",
       "10          0.706257      0.000000                 1.000000 -100.000000   \n",
       "11          0.590815      0.000000                 1.000000 -100.000000   \n",
       "12          0.506079      0.000000                 1.000000 -100.000000   \n",
       "13          0.443940      0.000000                 1.000000 -100.000000   \n",
       "14          0.394356      0.000000                 1.000000 -100.000000   \n",
       "15          0.354747      0.000000                 1.000000 -100.000000   \n",
       "\n",
       "    cumulative_gain  \n",
       "0        181.756757  \n",
       "1        181.756757  \n",
       "2        181.756757  \n",
       "3        181.756757  \n",
       "4        181.756757  \n",
       "5        181.756757  \n",
       "6        181.756757  \n",
       "7        181.756757  \n",
       "8        181.756757  \n",
       "9        149.700599  \n",
       "10        99.521531  \n",
       "11        66.800000  \n",
       "12        42.808219  \n",
       "13        25.225225  \n",
       "14        11.200000  \n",
       "15         0.000000  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_gain_lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "gbm_predictions_df=predictions_test(mod_best,test,run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>predict  </th><th style=\"text-align: right;\">         B</th><th style=\"text-align: right;\">        M</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>M        </td><td style=\"text-align: right;\">0.0254218 </td><td style=\"text-align: right;\">0.974578 </td></tr>\n",
       "<tr><td>M        </td><td style=\"text-align: right;\">0.00364481</td><td style=\"text-align: right;\">0.996355 </td></tr>\n",
       "<tr><td>M        </td><td style=\"text-align: right;\">0.0131194 </td><td style=\"text-align: right;\">0.986881 </td></tr>\n",
       "<tr><td>M        </td><td style=\"text-align: right;\">0.00207514</td><td style=\"text-align: right;\">0.997925 </td></tr>\n",
       "<tr><td>M        </td><td style=\"text-align: right;\">0.00273859</td><td style=\"text-align: right;\">0.997261 </td></tr>\n",
       "<tr><td>B        </td><td style=\"text-align: right;\">0.984861  </td><td style=\"text-align: right;\">0.0151394</td></tr>\n",
       "<tr><td>B        </td><td style=\"text-align: right;\">0.974138  </td><td style=\"text-align: right;\">0.0258624</td></tr>\n",
       "<tr><td>M        </td><td style=\"text-align: right;\">0.756796  </td><td style=\"text-align: right;\">0.243204 </td></tr>\n",
       "<tr><td>B        </td><td style=\"text-align: right;\">0.955198  </td><td style=\"text-align: right;\">0.0448021</td></tr>\n",
       "<tr><td>M        </td><td style=\"text-align: right;\">0.00592085</td><td style=\"text-align: right;\">0.994079 </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:58\n",
      "Cols:3\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th>predict  </th><th>B                   </th><th>M                    </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>type   </td><td>enum     </td><td>real                </td><td>real                 </td></tr>\n",
       "<tr><td>mins   </td><td>         </td><td>0.002075135266529693</td><td>0.0010468100665216112</td></tr>\n",
       "<tr><td>mean   </td><td>         </td><td>0.6217691021177613  </td><td>0.3782308978822388   </td></tr>\n",
       "<tr><td>maxs   </td><td>         </td><td>0.9989531899334784  </td><td>0.9979248647334703   </td></tr>\n",
       "<tr><td>sigma  </td><td>         </td><td>0.4633146893404552  </td><td>0.4633146893404552   </td></tr>\n",
       "<tr><td>zeros  </td><td>         </td><td>0                   </td><td>0                    </td></tr>\n",
       "<tr><td>missing</td><td>0        </td><td>0                   </td><td>0                    </td></tr>\n",
       "<tr><td>0      </td><td>M        </td><td>0.025421766189176354</td><td>0.9745782338108236   </td></tr>\n",
       "<tr><td>1      </td><td>M        </td><td>0.003644810067294002</td><td>0.996355189932706    </td></tr>\n",
       "<tr><td>2      </td><td>M        </td><td>0.013119387444179398</td><td>0.9868806125558206   </td></tr>\n",
       "<tr><td>3      </td><td>M        </td><td>0.002075135266529693</td><td>0.9979248647334703   </td></tr>\n",
       "<tr><td>4      </td><td>M        </td><td>0.00273858551707884 </td><td>0.9972614144829212   </td></tr>\n",
       "<tr><td>5      </td><td>B        </td><td>0.984860620822154   </td><td>0.015139379177846038 </td></tr>\n",
       "<tr><td>6      </td><td>B        </td><td>0.9741375533459156  </td><td>0.02586244665408444  </td></tr>\n",
       "<tr><td>7      </td><td>M        </td><td>0.7567958587559884  </td><td>0.24320414124401152  </td></tr>\n",
       "<tr><td>8      </td><td>B        </td><td>0.9551978574969431  </td><td>0.04480214250305695  </td></tr>\n",
       "<tr><td>9      </td><td>M        </td><td>0.005920848110712584</td><td>0.9940791518892874   </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gbm_predictions_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= gbm_predictions_df['predict'].as_data_frame()\n",
    "y_act= test['diagnosis'].as_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e8eb52df28>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAELCAYAAADawD2zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niISI/w9G97dAl2qpCgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e8eb52d2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "# plot training logloss and auc\n",
    "#gbm_predictions_df.plot(x='cumulative_data_fraction',y = ['cumulative_capture_rate', 'cumulative_lift'])\n",
    "gbm_gain_lift.plot(x='cumulative_data_fraction',y = ['cumulative_capture_rate', 'cumulative_lift'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "cm = confusion_matrix(y_act,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi4AAAGyCAYAAADDBk96AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl0VeUZ7/HfPiGESJjKZJgCCgZDjEIZrQIyGy9DkEJB\nQiGAVEWMFxlvGBQuEsZK0CIIigGMgJCggChhiEpERIUmDNUrpkVmUIYEk5Cc+0dv04sYDmjOPrzZ\n389aZy3OgbP3k3S5+lvP877vttxut1sAAAAGcPm6AAAAgBtFcAEAAMYguAAAAGMQXAAAgDEILgAA\nwBgEFwAAYIwyvi7Ak4iQdr4uAXCk3XtW+LoEwJECa9S19X4l+f+z+7N2lti1ikPHBQAAGOOW77gA\nAADvsSzL1yXcFDouAADAGHRcAABwMMsyq4dhVrUAAMDRCC4AAMAYjIoAAHAwl8xanEtwAQDAwdhV\nBAAA4CV0XAAAcDCXYbuKCC4AADgYoyIAAAAvIbgAAABjMCoCAMDBLMO2Q9NxAQAAxqDjAgCAg7Gr\nCAAAGMO0XUUEFwAAHMxlWHAxqz8EAAAcjeACAACMwagIAAAHswzrYRBcAACALQoKChQXF6cjR47I\nsiw9//zzCggI0Pjx42VZlho1aqQpU6bI5So+TBFcAABwMDt3FW3fvl2SlJSUpN27d2v+/Plyu92K\njY1Vq1atNHnyZKWmpqpz587FXsOs/hAAAChRLssqsZcnnTp10rRp0yRJx44dU8WKFZWZmamWLVtK\nktq2batdu3Zdv97f/iMDAADcmDJlymjcuHGaNm2aunfvLrfbXdT1KV++vC5evHj979tRJAAAuDX5\n4llF8fHxeu6559S3b1/l5uYWfZ6dna2KFSte97t0XAAAgC2Sk5P16quvSpICAwNlWZbCw8O1e/du\nSVJaWpqaN29+3WvQcQEAALbo0qWLJkyYoMcee0xXrlzRxIkTdeedd2rSpEmaN2+e7rjjDnXt2vW6\n1yC4AADgYHY+ZPG2227TSy+9dM3nK1asuOFrEFwAAHAw0x6yyBoXAABgDDouAAA4mGlPhya4AADg\nYL7YDv1bMCoCAADGILgAAABjMCoCAMDB7NwOXRLMqhYAADgaHRcAABzMtHNcCC4AADiYaduhGRUB\nAABj0HEBAMDBOMcFAADASwguAADAGIyKAABwMHYVAQAAY7CrCAAAwEvouAAA4GCm7SoiuAAA4GA8\nqwgAAMBLCC4AAMAYjIoAAHAw07ZD03EBAADGoOMCAICDmXaOC8EFAAAHM207NKMiAABgDDouAAA4\nmGmjIjouAADAGAQXAABgDEZFAAA4mGnnuBBcAABwMNa4AAAAeAkdFwAAHMy0c1wILgAAOBijIgAA\nAC8huAAAAGMwKgIAwMFM2w5NxwUAABiDjgsAAA5m2uJcggsAAA5m2nZoRkUAAMAYdFwAAHAw00ZF\ndFwAAIAx6LgAAOBgbIcGAADwEjouAAA4mGlrXAguAAA4GKMiAAAAL6HjAgCAg3EAHQAAgJcQXAAA\ngDEYFQEA4GAusyZFBBcAAJyMXUUAAABeQscFAAAH4wA6AABgDLtGRfn5+Zo4caK+//575eXl6Ykn\nnlBwcLBGjBih+vXrS5L69++vyMjI616H4AIAALxuw4YNqly5smbPnq0ff/xRvXr10lNPPaUhQ4Yo\nJibmhq9DcAEAAF7XrVs3de3aVZLkdrvl5+enjIwMHTlyRKmpqQoJCdHEiRMVFBR03euwOBcAAAdz\nySqx1/WUL19eQUFBunTpkkaNGqXY2FhFRERo7NixWrlyperWrauXX375BuoFAACwwfHjxzVo0CD1\n7NlT3bt3V+fOnRUeHi5J6ty5sw4cOODxGl4fFYWGhl71vnLlyurYseMNtYNgjj/9OUp9B/aU3G79\nK+uYnh8/W9mXcjRx+rMKj2gsy2Xp718d1Iy4+crNzfN1uUCplfROslYnvyvLslS3drAmj/2f+l2V\nKr4uC7cwuxbnnjlzRjExMZo8ebLatGkjSRo6dKgmTZqkiIgIpaenq0mTJh6vY0vH5a9//as+/vhj\npaWl6dVXX1VGRoZmzpxpx61hg7vD79Kfh/fToN5PqXeXIfrnd0f11OihGv50tMr4+alPtxj16Rqj\ncgEBGvrUQF+XC5RaBw7/Q8uT1mj5317SO2++pnp16ujl197wdVm4xbksq8Re17No0SJduHBBr7zy\niqKjoxUdHa3x48drxowZio6O1hdffKEnn3zSY722LM6tVKmSqlevLkmqWbOmRowYoUmTJmn69Ol2\n3B5edjDjH+re/jFduVKgsgFlVaNmdX3/r+Pau3ufjh09IbfbLbfbrUOZX+vOu+r7ulyg1AoLvUsb\n3lou/zJllJubp1Onz6hW8O2+LguQJMXFxSkuLu6az5OSkm7qOj5Z4xIYGOiL28KLrlwp0ENdHtCH\nn65Rs1YRSl6zSekffa6sI0clScG1a+qxoX30wcYdvi0UKOX8y5TRtrRP1PXRP2nvvv3qGdnV1yXh\nFmdZJfeyg+3B5dy5c0pMTFSPHj3svjW8bPsHH6td055aNP8NLUqcUzQ3vTv8Lr2xJkFJy9crbVu6\nj6sESr8Obf+gHe+t01+GDNKTo8ersLDQ1yUBJcaW4PKXv/xFTZs21X333ac2bdrowIEDio6OtuPW\nsEHdkNpq2vyeovfrV29ScO2aqlipgrp176DFK+fqpfjFeu3lFT6sEij9/nn0e325/+9F73s90k3H\nT57ShYsXfVgVULJsCS4vvPCCkpOTlZKSojVr1qhHjx7q16+fjhw5Ysft4WXVa1TVrIWTVblKJUnS\nI70665vDR9Ty/qYaP3WURgx8TptStvq4SqD0O3P2nMZN/d/64cfzkqRNH6aqYYP6qlypkm8Lwy3N\nrsW5JcWWxbk1atRQSEhI0fuIiAilpaVp9erVGjdunB0lwIu+2LNfSxau0LK3/6orVwp0+tRZxT7+\nv7Qoca5kWZoaP6bo3361N0MzJv3Vh9UCpVeze+/RsOgBGjZqtPz8/FS9WlXNn/G8r8vCLc7ycHDc\nrcanR/4XFBT48vYoQatXpGj1ipSrPuve/jEfVQM4V9+oHuobxRpClF62BJfz58/r9OnTkqSffvpJ\n77zzjrKystStWzc7bg8AAIph1wF0JcWW4BIbG1v054CAADVu3FgJCQlq1qyZHbcHAADFsGttSknx\nenA5fPiwt28BAAAcwqdrXAAAgG8Z1nDh6dAAAMAcBBcAAGAMRkUAADgYi3MBAIAxTDuAjlERAAAw\nBh0XAAAcjFERAAAwhmG5hVERAAAwB8EFAAAYg1ERAAAOZtpDFum4AAAAY9BxAQDAwdhVBAAAjGFY\nbmFUBAAAzEHHBQAABzNtVETHBQAAGIPgAgAAjMGoCAAABzPt6dAEFwAAHIwD6AAAALyEjgsAAA7m\nMqvhQnABAMDJGBUBAAB4CcEFAAAYg1ERAAAOZtqoiOACAICDmbY4l1ERAAAwBh0XAAAcjFERAAAw\nhmG5hVERAAAwB8EFAAAYg1ERAAAO5jJsVkTHBQAAGIOOCwAADmbJrI4LwQUAAAczbFLEqAgAAJiD\njgsAAA7G4lwAAAAvIbgAAABjMCoCAMDBeFYRAAAwhmG5hVERAAAwBx0XAAAcjFERAAAwhsus3MKo\nCAAAmIPgAgAAjMGoCAAAB7NrjUt+fr4mTpyo77//Xnl5eXriiSfUsGFDjR8/XpZlqVGjRpoyZYpc\nruv3VAguAADA6zZs2KDKlStr9uzZ+vHHH9WrVy81btxYsbGxatWqlSZPnqzU1FR17tz5utdhVAQA\ngINZVsm9rqdbt2565plnJElut1t+fn7KzMxUy5YtJUlt27bVrl27PNZLcAEAwMFcllVir+spX768\ngoKCdOnSJY0aNUqxsbFyu91Fo6ry5cvr4sWLnustkZ8aAADAg+PHj2vQoEHq2bOnunfvftV6luzs\nbFWsWNHjNQguAAA4mGVZJfa6njNnzigmJkZjxoxRnz59JElhYWHavXu3JCktLU3Nmzf3WC/BBQAA\neN2iRYt04cIFvfLKK4qOjlZ0dLRiY2OVkJCgfv36KT8/X127dvV4HcvtdrttqPdXiwhp5+sSAEfa\nvWeFr0sAHCmwRl1b75cYM7fErhW9bHSJXas4bIcGAMDBDHtUEcEFAAAnM+0hi6xxAQAAxqDjAgCA\ngxnWcCG4AADgZJ4OjrvVeBwV7d+/X6+//rry8vIUExOj1q1ba8uWLXbUBgAAcBWPwWX69OkKDw/X\nli1bVK5cOa1fv16LFy+2ozYAAICreAwuhYWFatGihXbs2KEuXbooODhYBQUFdtQGAAC8zK6HLJYU\nj8ElMDBQy5Yt06effqqHHnpIy5cvV/ny5e2oDQAA4Coeg8ucOXOUk5OjhQsXqlKlSjp16pTmzi25\nU/YAAIDv2PWsopLiMbjUrFlTrVu31qFDh5SXl6f27dvr9ttvt6M2AADgZaVuVLR8+XK99NJLeuON\nN5Sdna3Jkydr6dKldtQGAABwFY/BZf369Vq6dKkCAwNVpUoVrV27Vu+8844dtQEAAC8rdaMil8ul\nsmXLFr0PCAiQn5+fV4sCAAD4JR5Pzm3ZsqXi4+N1+fJlbd26VW+//bZat25tR20AAABX8dhxGTt2\nrEJCQhQaGqrk5GS1a9dO48aNs6M2AADgZaYtzvXYcTlx4oTatm2rtm3bFn126tQp1apVy6uFAQAA\n7zPtWUUeg8vAgQOLFtzk5+frzJkzuvvuu1mgCwAAbOcxuGzbtu2q9/v379fKlSu9VhAAALCPYQ0X\nz2tcfi4iIkKZmZneqAUAANjMtO3QHjsuCxcuvOr9N998o6pVq3qtIAAAgOJ4DC4/16JFCz3yyCPe\nqAUAAOC6PAaXkSNH2lEHAADwAdPWuBQbXBo3bvyL8yq32y3LsnTw4EGvFgYAAPBzxQaXQ4cO2VkH\nAADwAbsW1ZYUj6Ois2fP6t1331V2drbcbrcKCwt19OhRzZo1y476AACAFxmWWzxvhx45cqQOHjyo\nDRs26PLly9q2bZtcrpveRQ0AAG5Bpm2H9phAfvjhB8XHx6tDhw7q0qWLEhMT9fXXX9tRGwAAwFU8\nBpdKlSpJkho0aKBDhw6pQoUKunLlitcLAwAA+DmPa1xat26tUaNGady4cYqJiVFmZqYCAgLsqA0A\nAHiZaWtcPAaXZ599Vv/85z9Vu3ZtzZs3T3v27NFTTz1lR20AAABXKTa49O7dW3369FH37t1Vr149\nSVKTJk3UpEkT24oDAADeZdp26GLXuEyYMEGZmZnq1q2bRo8erfT0dDvrAgAANrCsknvZodiOS4sW\nLdSiRQvl5eVp69ateuONNzR16lT16NFDvXv3VnBwsD0VAgAA/D8e17iULVtWkZGRioyM1NmzZ/XS\nSy+pc+fOysjIsKM+ff73dbbcB8DVXv/LEl+XADjSiFXjbb2fy7BR0Q09Hfq7777Te++9p02bNik4\nOFjx8fHergsAANjAsNxSfHA5deqUNm3apA0bNujSpUuKiorS0qVLGREBAACfKTa4dOvWTV26dNH4\n8ePVsmVLO2sCAAD4RcUGl7S0NAUFBdlZCwAAsFmp2Q5NaAEAALeaG1qcCwAASifDGi6eH7IoSTk5\nOTp06JDcbrdycnK8XRMAALCJ5bJK7GUHj8ElPT1dPXv21JNPPqnTp0+rQ4cO+vjjj+2oDQAA4Coe\ng8u8efO0atUqVaxYUTVq1NCKFSs0a9YsO2oDAABeZtqR/x6DS2FhoapXr170vmHDhl4tCAAAoDge\nF+fefvvt2r59uyzL0oULF7Ry5UrVqlXLjtoAAACu4rHj8sILL+jdd9/V8ePH1alTJx08eFAvvPCC\nHbUBAAAvsyyrxF528NhxqVq1qubNm2dHLQAAwGambYf2GFw6dOjwiykqNTXVKwUBAAAUx2NwSUxM\nLPrzlStX9OGHHyovL8+rRQEAAHuUmiP//6N27dpFr5CQEA0bNkxbt261ozYAAOBlpm2H9thx2bNn\nT9Gf3W63vv76a+Xm5nq1KAAAgF/iMbgsWLCg6M+WZalKlSqaOXOmV4sCAAD4JR6Dy8MPP6wBAwbY\nUQsAALBbaVvjsmrVKjvqAAAA8OiGTs4dNGiQ7r33XgUEBBR9PnLkSK8WBgAAvM/uXUX79u3TnDlz\nlJiYqAMHDmjEiBGqX7++JKl///6KjIy87vc9Bpf77ruvRAoFAAC3Hjtzy5IlS7RhwwYFBgZKkjIz\nMzVkyBDFxMTc8DWKDS7r169XVFQUnRUAAFAi6tWrp4SEBI0dO1aSlJGRoSNHjig1NVUhISGaOHGi\ngoKCrnuNYte4vPnmmyVbLQAAuOVYLqvEXp507dpVZcr8t2cSERGhsWPHauXKlapbt65efvllj9fw\nuDgXAADAGzp37qzw8PCiPx84cMDjd4odFX399dfq2LHjNZ+73W5ZlsWzigAAwG8ydOhQTZo0SRER\nEUpPT1eTJk08fqfY4BISEqLFixeXaIEAAODW4stjXKZOnapp06bJ399f1apV07Rp0zx+p9jg4u/v\nr9q1a5dogQAA4NZi93boOnXqaPXq1ZKkJk2aKCkp6aa+X+wal2bNmv22ygAAAEpYsR2XyZMn21kH\nAADwAcNO/Pd8AB0AACi97B4V/VZshwYAAMYguAAAAGMwKgIAwMEMmxTRcQEAAOag4wIAgIOZtjiX\n4AIAgJMZNnsxrFwAAOBkdFwAAHAw00ZFdFwAAIAxCC4AAMAYjIoAAHAwwyZFBBcAAJyMNS4AAABe\nQscFAAAHM6zhQnABAMDRDEsujIoAAIAxCC4AAMAYjIoAAHAwy2XWqIjgAgCAgxm2xIVREQAAMAcd\nFwAAHMy0A+gILgAAOJhhuYVREQAAMAfBBQAAGINREQAATmbYrIiOCwAAMAYdFwAAHIwD6AAAgDEM\nmxQxKgIAAOag4wIAgJMZ1nKh4wIAAIxBcAEAAMZgVAQAgIMZNikiuAAA4GSmbYdmVAQAAIxBxwUA\nAAezDJsVEVwAAHAys3ILoyIAAGAOggsAADAGoyIAABzMtDUudFwAAIAx6LgAAOBgpnVcCC4AADiZ\nYbMXw8oFAABORscFAAAHM21URMcFAAAYg+ACAACMwagIAAAHM21URHABAMDJzMotjIoAAIA56LgA\nAOBglsuslgvBBQAAJzNsjQujIgAAYAyCCwAAsM2+ffsUHR0tScrKylL//v01YMAATZkyRYWFhR6/\nT3ABAMDBLKvkXp4sWbJEcXFxys3NlSS9+OKLio2N1apVq+R2u5WamurxGgQXAABgi3r16ikhIaHo\nfWZmplq2bClJatu2rXbt2uXxGgQXAAAczLKsEnt50rVrV5Up8999QW63u+h75cuX18WLFz1ew2vB\nJTQ0VKGhofrXv/51zd+99dZbCg0N1fz58711ewAAcCNcVsm9bvbWrv/GkOzsbFWsWNHzd276LjfB\n399f27Ztu+bzrVu3GnfEMG7Ou5ve16MDBqnPgD9rYMzjyjxw0NclAaVSoz80UZ8XY/TojCHqOXWg\nqjW4vejvyv+uggYufErlKgT6sEKgeGFhYdq9e7ckKS0tTc2bN/f4Ha8Gl+bNm18TXC5duqQvv/xS\nYWFh3rw1fOjId1mat+BlLVowT2tXLdfjQwcrduxEX5cFlDqVgn+nVgMe0qb4t/XOxNf1RfIudXk2\nSpLU6MFw9ZwyUOV/V8HHVeJWZ+eo6OfGjRunhIQE9evXT/n5+eratavH73j1ALqOHTsqPj5eFy9e\nVIUK//6PZ+fOnWrevLkuX77szVvDh8qWLavn48arerVqkqQmdzfWmbNnlZ+fL39/fx9XB5QeBfkF\nSluyWTk/ZkuSTn97QrdVDlJQ1Ypq8PtG2jRrtfrNHu7jKoGr1alTR6tXr5YkNWjQQCtWrLip73u1\n43LnnXeqdu3aSktLK/osNTVVnTp18uZt4WO1awWr7QN/kPTvhVez5y/QQ20fILQAJezSmfP651f/\np+j9/QM7KGvv17p09oI++Ot6/fj9WR9WB3iH13cVdejQoWhclJ+fr48//lgdO3b09m1xC8i5fFmj\nJ8TpX0e/19S4Cb4uByi1ygT4q9MzvVSxZhXtXLLZ1+XANFYJvmzg9eDSsWNHffTRR7py5Yo+/fRT\nNWzYUFWrVvX2beFjx0+cUPTQEfJzubT0bwtVsQJzdsAbgqpWVK+p0XIXFurd6W8pLyfX1yXBML5c\n4/JreP0hi82aNZOfn5/27t2r1NRUde7c2du3hI+dP39BQ0Y8pZ7/I1JPDB/q63KAUiugfDl1nzRA\n/0j7u/au+8TX5QC28Hpwcblcat++vbZt26bt27ff9CIcmOftd9bp+ImTSt2eptTt/13f9NorC1S5\nciUfVgaULmGdmiqoWkXVb36X6je/q+jz92a8pdxLP/mwMpjE+hXnr/iS14OL9O9x0dixY1W3bl3V\nrVvXjlvChx6PGazHYwb7ugyg1PsyJV1fpqRf99+8OmCmTdXAWIadq2bLkf9/+MMfVFBQwG4iAADw\nm3it43L48OGiPwcGBmrfvn1X/X1iYqK3bg0AAG6QaSfZ85BFAABgDFvWuAAAgFuUWQ0XOi4AAMAc\ndFwAAHAwtkMDAABzsDgXAADAO+i4AADgYGyHBgAA8BKCCwAAMAajIgAAnIxdRQAAwBSscQEAAPAS\nOi4AADiZWQ0XggsAAE7GqAgAAMBLCC4AAMAYjIoAAHAyw7ZD03EBAADGoOMCAICDmbY4l+ACAICT\nGRZcGBUBAABj0HEBAMDBTBsV0XEBAADGILgAAABjMCoCAMDJDDvHheACAICDscYFAADAS+i4AADg\nZIZ1XAguAAA4mGXYGhdGRQAAwBgEFwAAYAxGRQAAOJlha1zouAAAAGPQcQEAwMFMO8eF4AIAgJMZ\nFlwYFQEAAGPQcQEAwME4xwUAAMBLCC4AAMAYjIoAAHAywxbnElwAAHAyw4ILoyIAAGAMOi4AADgY\nB9ABAABzsB0aAADAOwguAADAGIyKAABwMMsyq4dBcAEAALaJiopSUFCQJKlOnTp68cUXb+r7BBcA\nAJzMxl1Fubm5crvdSkxM/NXXMKs/BAAASpRlWSX28uTQoUO6fPmyYmJiNGjQIH311Vc3XS8dFwAA\nYIty5cpp6NCh+uMf/6jvvvtOw4cP1/vvv68yZW48jhBcAABwMhvPcWnQoIFCQkJkWZYaNGigypUr\n6/Tp0woODr7hazAqAgAAtli7dq1mzpwpSTp58qQuXbqk6tWr39Q16LgAAABb9OnTRxMmTFD//v1l\nWZZmzJhxU2MiieACAICj2fmsorJly2ru3Lm/6RoEFwAAnIyHLAIAAGMYdnKuWdUCAABHo+MCAICD\nWTZuhy4JdFwAAIAxCC4AAMAYjIoAAHAydhUBAABT2HmOS0lgVAQAAIxBxwUAACcz7BwXggsAAA7G\ndmgAAAAvIbgAAABjMCoCAMDJ2FUEAADgHXRcAABwMNPOcSG4AADgZIZthzarWgAA4Gh0XAAAcDLO\ncQEAAPAOggsAADAGoyIAAByMXUUAAMAc7CoCAADwDjouAAA4GKMiAABgDkZFAAAA3kFwAQAAxmBU\nBACAg1mcnAsAAOAddFwAAHAydhUBAABTWOwqAgAA8A46LgAAOJlhoyLL7Xa7fV0EAADAjWBUBAAA\njEFwAQAAxiC4AAAAYxBcAACAMQguAADAGAQXAABgDIILAAAwBsEFAAxw7NgxX5cA3BIILrhh+/fv\n18GDB3Xo0KGizzi/EPC+xYsXa9SoUUpPT/d1KYDPceQ/bsicOXP0wQcfyLIs/fTTTxo4cKCGDx8u\ny7CjogHTXLx4UV988YUyMjK0bt065eXlqV27dr4uC/AZggs8mjFjhtatW6fXXntNfn5+OnTokGbO\nnKmGDRvqoYce8nV5QKlWoUIFRUZGaufOnTp69Kg2b94sy7LUtm1bX5cG+ATBBdc1a9YspaSkaNWq\nVbrrrrskSQ0aNNCOHTt07tw55ebmKiAgwMdVAqVTYWGhXC6XevTooT179igrK0vHjh3T2rVr5XK5\n9MADD/i6RMB2rHFBsY4dO6Zly5Zp2LBhuuuuu1RYWChJCgoK0sWLF7V8+XJFRkZq2LBhSkpK8nG1\nQOnjcrmUl5cnSerUqZPuvfdeDR48WOfPn9eqVav0ySef+LhCwH4EFxSrVq1aWrx4sV599VVt3Lix\naCHu4sWLtX//fvXq1UujR4+W2+1WUlKS/vGPf/i4YsB8Cxcu1MKFC7V//35JUtmyZSVJ99xzj/bu\n3avjx49r9uzZys7O1ltvvUV4geNYbraFwIO0tDQ9/fTTWrRokfbv369ly5Zp7ty5RW3qU6dOqV27\ndnr++efVt29fH1cLmOv48eNF68buv/9+1apVS5MmTZLL5ZK/v78yMzM1ceJEzZs3T5L0wgsvqEqV\nKurVq5fat2/vw8oB+/hNnTp1qq+LwK0tJCREYWFhGjZsmL788kvNnz9fDz74oNxutwoKCiRJe/bs\n0f33368777zTx9UC5qpQoYJatGih5ORkRURE6PDhw1q7dq1yc3NVoUIFNW7cWCdOnNDZs2fVvn17\nNWrUSMnJyTp79qweeOAB+fv7+/pHALyOURFuSLt27bR8+XLl5uYqLy9P+fn5sixLZcqU0RtvvKET\nJ04oPDzc12UCxmvVqpWWLl2q7du3a+TIkerUqZMOHDigYcOG6f3331e1atW0Zs0aHT9+XOHh4Zox\nY4aeeeYZBQYG+rp0wBZ0XHDD6tSpo3vuuUfPPvus7rjjDjVq1EgJCQlavHixli1bpjvuuMPXJQKl\nQr169dS4cWNNmDBB/fr1U69evVS1alUtWrRI1apV065du3ThwgW1adNGt99+uypWrOjrkgHbsMYF\nNy0tLU2jR49Ws2bN9NlnnykxMZFuC+AFO3fuVGxsrGbMmKGHH35Yhw4d0ueff65FixapSpUqSkpK\nUvny5X1dJmArggt+lZ07d2rEiBFat26dwsLCfF0OUGrt3LlTI0eOVHx8vCIjIyVJ2dnZ+uGHH1Sn\nTh0fVweXtEnYAAAGcklEQVTYj+CCX+3y5cvM1QEbpKWlKTY2VlOmTNHDDz9ctEUacCKCCwAYIDU1\nVVOmTNH777+voKAgX5cD+AzBBQAMkZ2dzZoWOB7BBQAAGINzXAAAgDEILgAAwBgEFwAAYAyCCwAA\nMAbBBbDZ0aNHFR4erp49e6pXr1565JFHNGTIEJ04ceJXX3PdunUaP368JGn48OE6efJksf92wYIF\n+vzzz2/q+qGhoVe9v3Tpkpo2bXrNfT777DNFRUXd1LUA4GYQXAAfqFGjhlJSUpScnKyNGzcqPDxc\n06ZNK5FrL1myRDVr1iz27/fs2VP0VO9fKygoSJ07d9bGjRuv+jw5OVmPPvrob7o2AFxPGV8XAEBq\n3ry5tm3bJknq0KGDIiIidPDgQa1atUofffSRli9frsLCQjVp0kRTpkxRQECAkpOT9be//U1BQUGq\nXbu2brvttqLvv/nmm6pevbqef/557d27V/7+/nryySeVl5enjIwMxcXFaeHChSpXrpymTp2qH3/8\nUeXKldOkSZMUFhamo0ePasyYMcrJydG99977izU/+uijio+PV0xMjCQpNzdXO3bs0Lhx4yRJ8+fP\nV3p6us6fP68qVaooISFB1atXL/p+QkKCJOnpp5++qu7g4GDNmjVLn332mQoKCtS7d28NHjxYJ06c\n0HPPPaecnBy5XC7FxcXpvvvu887/IABuWXRcAB/Lz8/X5s2b1axZs6LP2rZtqy1btujcuXNavXq1\nkpKSlJKSoqpVq2rp0qU6efKk5syZo5UrV+rtt99Wdnb2NddNTExUTk6ONm/erNdff10vv/yyIiMj\nFR4erunTpys0NFTjxo3TmDFjtH79ek2bNk3PPvusJGnatGnq3bu3UlJSrqrr/9eyZUtduHBB3377\nrSRp69atat26tSpVqqSsrCx9++23SkpK0pYtW1SvXj29++67N/T7WL16tSRp/fr1Wrt2rVJTU/X5\n559r7dq1at++vdatW6cxY8Zo7969N/V7BlA60HEBfODUqVPq2bOnJCkvL08REREaPXp00d//p8ux\ne/duZWVlqW/fvpL+HXLCwsL05ZdfqmnTpqpWrZokqXv37vr000+vuseePXvUt29fuVwuVa9e/Zqx\nTnZ2tjIyMjRhwoSiz3JycvTDDz/os88+09y5cyVJPXr0UFxc3DU/g2VZioqK0nvvvadRo0YpJSVF\ngwcPliSFhIRo3LhxWrNmjY4cOaKvvvpK9erVu6HfTXp6ug4ePFj08+Tk5Ojw4cNq06aNnn76aR08\neFDt2rXTwIEDb+h6AEoXggvgA/9Z41KcgIAASVJBQYEefvjhouCQnZ2tgoICpaenq7CwsOjflylz\n7X/KP/8sKytLwcHBRe8LCwtVtmzZq+o4ceKEKleuLEn6z6HalmXJsqxfrDMqKkoxMTEaMGCAjhw5\nojZt2kiSMjIyNHr0aA0ePFhdu3aVy+XSzw/ptizrqp8hPz+/6GceM2aMunTpIkk6d+6cbrvtNpUr\nV04bN27Ujh07tGnTJq1fv16vv/56sb9DAKUToyLgFtaqVSt9+OGHOnv2rNxut6ZOnarly5fr97//\nvfbt26eTJ0+qsLBQmzZtuua7LVq00ObNm+V2u3X27FkNHDhQeXl58vPzU0FBgSpUqKD69esXBZdP\nPvlEjz32mCTp/vvv14YNGyRJH3zwgfLy8n6xvlq1aqlWrVpasGCBevbsWRRw9uzZo5YtW6p///5q\n2LChPvnkk2sWBFepUkXffPONJGn//v06ffq0JKl169ZavXq18vPzlZ2drQEDBmjfvn2aNWuWUlJS\nFBUVpcmTJ+vAgQMl8BsGYBo6LsAtrHHjxho5cqT+/Oc/q7CwUHfffbcef/xxBQQEKC4uToMHD1Zg\nYKAaNmx4zXcHDBig6dOnq0ePHpKkSZMmKSgoSA8++KCmTJmi+Ph4zZ49W1OnTtVrr70mf39/zZ8/\nX5ZlafLkyRozZoySkpJ0zz33XPfBfr1799bYsWP14YcfFn0WGRmpkSNHqnv37vL391doaKiOHj16\n1fciIyO1ZcsWRUZGqkmTJgoLC5Mk/elPf1JWVpaioqJ05coV9e7dW61atVK9evU0evRorV+/Xn5+\nfpoyZUpJ/IoBGIaHLAIAAGMwKgIAAMYguAAAAGMQXAAAgDEILgAAwBgEFwAAYAyCCwAAMAbBBQAA\nGIPgAgAAjPF/AVlUC5rQLp3OAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e8edf3b6d8>"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi4AAAGyCAYAAADDBk96AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGIPgAgAAjPF/AVlUC5rQLp3OAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e8edf3b6d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_name = ['B','M']\n",
    "print_confusion_matrix(cm,class_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>concave points_mean</td>\n",
       "      <td>153.298904</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.162179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>perimeter_worst</td>\n",
       "      <td>139.451279</td>\n",
       "      <td>0.909669</td>\n",
       "      <td>0.147529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>concave points_worst</td>\n",
       "      <td>104.078445</td>\n",
       "      <td>0.678925</td>\n",
       "      <td>0.110107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>area_mean</td>\n",
       "      <td>74.821533</td>\n",
       "      <td>0.488076</td>\n",
       "      <td>0.079156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>radius_worst</td>\n",
       "      <td>61.001492</td>\n",
       "      <td>0.397925</td>\n",
       "      <td>0.064535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0           1         2         3\n",
       "0   concave points_mean  153.298904  1.000000  0.162179\n",
       "1       perimeter_worst  139.451279  0.909669  0.147529\n",
       "2  concave points_worst  104.078445  0.678925  0.110107\n",
       "3             area_mean   74.821533  0.488076  0.079156\n",
       "4          radius_worst   61.001492  0.397925  0.064535"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_varimp=pd.DataFrame(mod_best.varimp())\n",
    "gbm_varimp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>relative_importance</th>\n",
       "      <th>scaled_importance</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>concave points_mean</td>\n",
       "      <td>153.298904</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.162179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>perimeter_worst</td>\n",
       "      <td>139.451279</td>\n",
       "      <td>0.909669</td>\n",
       "      <td>0.147529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>concave points_worst</td>\n",
       "      <td>104.078445</td>\n",
       "      <td>0.678925</td>\n",
       "      <td>0.110107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>area_mean</td>\n",
       "      <td>74.821533</td>\n",
       "      <td>0.488076</td>\n",
       "      <td>0.079156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>radius_worst</td>\n",
       "      <td>61.001492</td>\n",
       "      <td>0.397925</td>\n",
       "      <td>0.064535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               variable  relative_importance  scaled_importance  percentage\n",
       "0   concave points_mean           153.298904           1.000000    0.162179\n",
       "1       perimeter_worst           139.451279           0.909669    0.147529\n",
       "2  concave points_worst           104.078445           0.678925    0.110107\n",
       "3             area_mean            74.821533           0.488076    0.079156\n",
       "4          radius_worst            61.001492           0.397925    0.064535"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#variable\trelative_importance\tscaled_importance\tpercentage\n",
    "gbm_varimp.rename(columns={0:\"variable\",1:\"relative_importance\",2:\"scaled_importance\",3:\"percentage\"}).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1e8ede9ca20>"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAAG+CAYAAABoC4bHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3Xtcz/f/P/7bSylEDlOb82kYNmbM4eM05jRzbBQlh7Fp\nJiv7LqRyWkKENTSMtnKKMMN7yGHN2RxyeDPkLCqJDtLx8fvDr9e7Rr0er+erVy/P3K6Xi8tFr7q/\n7vdePV/P+/PweD0eGiGEABEREalSKVMXQERERMqxkRMREakYGzkREZGKsZETERGpGBs5ERGRirGR\nExERqZhRG3lUVBScnZ0BAAkJCfjqq6/g5OSEoUOH4vbt2wCAsLAw2NnZwd7eHgcOHDBmOURERCWO\nubGeeOXKldi+fTvKli0LAPD390e/fv3Qp08fHDt2DNevX0fZsmUREhKC8PBwpKenw9HRER06dICF\nhYWxyiIiIipRjNbIa9eujcDAQHh4eAAATp8+jcaNG2PUqFGoUaMGpk2bhqNHj6Jly5awsLCAhYUF\nateujcuXL6N58+aFPnd8fHKB36tcuRwSE58qqllprJpyqqlWU+RUU62myKmmWk2RU021miKnmmo1\nRU5dcTY2FV76uNEurffq1Qvm5v87Trh37x6sra0RHByMatWqYeXKlUhJSUGFCv8rzMrKCikpKQbl\nNTc3K/ZYNeVUU62myKmmWk2RU021miKnmmo1RU411WqKnIrjFEUpUKlSJXTr1g0A0K1bNyxatAjv\nvvsuUlNTtT+Tmpqar7EXpHLlcoX+wgUdtchQGqumnGqq1RQ51VSrKXKqqVZT5FRTrabIqaZaTZFT\nSVyxNfJWrVrhzz//xMCBA3Hy5Em8/fbbaN68ORYvXoz09HRkZGQgOjoajRo10vlcui49FHbpvTBK\nY9WUU021miKnmmo1RU411WqKnGqq1RQ51VSrKXLqiiuoyRdbI588eTK8vLywYcMGlC9fHgsXLkTF\nihXh7OwMR0dHCCHg7u4OS0vL4iqJiIhI9YzayGvWrImwsDAAQI0aNbBmzZoXfsbe3h729vbGLIOI\niKjE4oQwREREKsZGTkREpGJs5ERERCpWbIPdiIiIXjWfz91fpM+3eko3qZ+7ePECli//AT/+uMLg\nnGzkRERExWjt2l+we/culClTtkiej5fWiYiIilGNGjXh6+tfZM/HRk5ERFSMPvro43xTmBuKjZyI\niEjFSsQ98sIGK8gOPCAiIlIjnpETERGpWIk4IyciIlKisKu2hiy4oku1atWxYkVwkTwXz8iJiIhU\njI2ciIhIxdjIiYiIVIyNnIiISMXYyImIiFSMjZyIiEjF2MiJiIhUjI2ciIhIxdjIiYiIVIyNnIiI\nSMXYyImIiFSMjZyIiEjF2MiJiIhUjI2ciIhIxdjIiYiIVIyNnIiISMXYyImIiFSMjZyIiEjFjNrI\no6Ki4OzsnO+x33//HQ4ODtqvw8LCYGdnB3t7exw4cMCY5RAREZU45sZ64pUrV2L79u0oW7as9rH/\n/ve/2Lx5M4QQAID4+HiEhIQgPDwc6enpcHR0RIcOHWBhYWGssoiIiEoUo52R165dG4GBgdqvExMT\nERAQAE9PT+1j586dQ8uWLWFhYYEKFSqgdu3auHz5srFKIiIiKnGM1sh79eoFc/PnJ/zZ2dmYNm0a\npk6dCisrK+3PpKSkoEKFCtqvrayskJKSYqySiIiIShyjXVrP6+LFi7h16xZmzJiB9PR0XLt2Db6+\nvmjXrh1SU1O1P5eampqvsRekcuVyMDc3k8ptY6P7+Qz5eUPjTJFTTbWaIqeaajVFTjXVaoqcaqrV\nFDnVVKspciqJK5ZG3rx5c+zcuRMAcPfuXUyaNAnTpk1DfHw8Fi9ejPT0dGRkZCA6OhqNGjXS+XyJ\niU+lc8fHJxf4vc/n7i/we6undJPOYWNTodA8xogt7rjXJaeaajVFTjXVaoqcaqrVFDnVVKspcuqK\nK6jJF0sjL4iNjQ2cnZ3h6OgIIQTc3d1haWlpypKIiIhUxaiNvGbNmggLCyv0MXt7e9jb2xuzDCIi\nohKLE8IQERGpGBs5ERGRirGRExERqRgbORERkYqxkRMREakYGzkREZGKsZETERGpGBs5ERGRirGR\nExERqRgbORERkYqxkRMREakYGzkREZGKsZETERGpGBs5ERGRirGRExERqRgbORERkYqxkRMREakY\nGzkREZGKsZETERGpGBs5ERGRirGRExERqRgbORERkYqxkRMREakYGzkREZGKsZETERGpGBs5ERGR\nirGRExERqRgbORERkYqxkRMREamYURt5VFQUnJ2dAQCXLl2Co6MjnJ2dMWbMGDx8+BAAEBYWBjs7\nO9jb2+PAgQPGLIeIiKjEMTfWE69cuRLbt29H2bJlAQC+vr7w9vZGkyZNsGHDBqxcuRJjx45FSEgI\nwsPDkZ6eDkdHR3To0AEWFhbGKouIiKhEMdoZee3atREYGKj9OiAgAE2aNAEAZGdnw9LSEufOnUPL\nli1hYWGBChUqoHbt2rh8+bKxSiIiIipxjNbIe/XqBXPz/53w29raAgBOnz6N0NBQjBo1CikpKahQ\noYL2Z6ysrJCSkmKskoiIiEoco11af5ldu3Zh+fLlWLFiBapUqYLy5csjNTVV+/3U1NR8jb0glSuX\ng7m5mVROGxvdz1cUcUrzGBJb3HGvS0411WqKnGqq1RQ51VSrKXKqqVZT5FQSV2yN/LfffsPGjRsR\nEhKCSpUqAQCaN2+OxYsXIz09HRkZGYiOjkajRo10Pldi4lPpvPHxyYrq1SfOxqaC4jxKY4s77nXJ\nqaZaTZFTTbWaIqeaajVFTjXVaoqcuuIKavLF0sizs7Ph6+uLatWqwdXVFQDw4YcfYuLEiXB2doaj\noyOEEHB3d4elpWVxlERERFQiGLWR16xZE2FhYQCAEydOvPRn7O3tYW9vb8wyiIiISixOCENERKRi\nbOREREQqxkZORESkYmzkREREKsZGTkREpGJs5ERERCrGRk5ERKRibOREREQqxkZORESkYmzkRERE\nKsZGTkREpGJs5ERERCrGRk5ERKRibOREREQqxkZORESkYmzkREREKsZGTkREpGJs5ERERCrGRk5E\nRKRibOREREQqxkZORESkYlKN/MmTJ/Dy8sKIESOQmJiIqVOn4smTJ8aujYiIiHSQauTe3t547733\n8PjxY1hZWcHW1hbfffedsWsjIiIiHaQa+d27d+Hg4IBSpUrBwsIC7u7uePDggbFrIyIiIh2kGrmZ\nmRmSk5Oh0WgAADdv3kSpUry9TkREZGrmMj/k6uoKZ2dn3L9/H+PHj8fZs2cxZ84cY9f2Svt87v4C\nv7d6SrdirISIiF5nUo28c+fOePfdd3Hu3DlkZ2dj1qxZqFq1qrFrIyIiIh2kro8fO3YM48ePx0cf\nfYR69erBwcEBp0+fNnZtREREpINUI583bx5mzZoFAKhfvz5WrFgBX19foxZGREREukk18vT0dDRq\n1Ej7dYMGDZCVlWW0ooiIiEiOVCOvX78+/P39ceXKFVy5cgWLFi1C3bp1dcZFRUXB2dkZAHDr1i0M\nGzYMjo6OmD59OnJycgAAYWFhsLOzg729PQ4cOKD8NyEiInoNSTVyX19fPH36FN9++y0mT56Mp0+f\n4vvvvy80ZuXKlfDy8kJ6ejoAwM/PD25ubli3bh2EENi3bx/i4+MREhKCDRs24Oeff0ZAQAAyMjIM\n/62IiIheE1Kj1itWrIjp06fr9cS1a9dGYGAgPDw8AAAXL15EmzZtADwfBX/48GGUKlUKLVu2hIWF\nBSwsLFC7dm1cvnwZzZs31/PXICIiej1JNfItW7Zg3rx5SEpKAgAIIaDRaHDp0qUCY3r16oW7d+9q\nv86NAQArKyskJycjJSUFFSpU0P6MlZUVUlJSdNZTuXI5mJubyZQOG5sKun+oCOOUxBZ3jcX5u6kx\np5pqNUVONdVqipxqqtUUOdVUqylyKomTauRLly5FSEhIvgFv+so7E1xqaiqsra1Rvnx5pKam5ns8\nb2MvSGLiU+m88fHJ+hVqYJy+sTY2FRTlKu641yWnmmo1RU411WqKnGqq1RQ51VSrKXLqiiuoyUvd\nI3/zzTcNauIA0LRpUxw/fhwAEBkZidatW6N58+Y4deoU0tPTkZycjOjoaIPzEBERvU6kzsibNWuG\niRMnokOHDrC0tNQ+PnDgQOlEkydPhre3NwICAlC/fn306tULZmZmcHZ2hqOjI4QQcHd3z/f8RERE\nVDipRp6SkgIrKyucPXs23+O6GnnNmjURFhYGAKhXrx5CQ0Nf+Bl7e3vY29vL1ktERER5SDVyPz+/\nFx579uxZkRdDRERE+pFq5Lt378bSpUvx9OlTCCGQk5ODZ8+e4ejRo8auj4iIiAoh1cj9/f3x/fff\nY82aNXBxccGhQ4eQmJho7NqIiIhIB6lR69bW1mjXrh1atGiB5ORkuLq6vnC/nIiIiIqfVCMvU6YM\nbty4gQYNGuDEiRPIyMhAcrLyz1kTERFR0ZBq5G5ubli8eDG6du2Ko0ePokOHDujevbuxayMiIiId\npO6RV65cGUuWLAEAhIeH48mTJ7hx44ZRCyMiIiLdCm3kp06dQk5ODry8vODr6wshBAAgKysLM2bM\nwO7du4ulSCIiInq5Qhv5kSNHcOLECcTFxWnPyAHA3NwcDg4ORi+OiIiICldoI3d1dQUAbNu2Ta/p\nWImIiKh4SA12W7lypbHrICIiIgWkBrvVqlULU6dORYsWLVCmTBnt4zxLJyIiMi3pUesAEBUVle9x\nNnIiIiLTkl40JTMzEzdu3EB2djYaNmwIc3OpUCIiIjIiqW584cIFTJw4EZUqVUJOTg4ePnyIpUuX\nokWLFsauj4iIiAoh1ci///57LFq0SNu4z549i9mzZ2Pz5s1GLY6IiIgKJzVq/enTp/nOvt9//32k\np6cbrSgiIiKSI9XIK1asiIiICO3XERERqFSpktGKIiIiIjlSl9Znz56N7777DtOmTYMQArVr18b8\n+fONXRsRERHpINXI69ati02bNiE2NhY5OTmoVq2asesiIiIiCVKN/PLly/Dw8EBsbCyEEKhfvz7m\nzZuHOnXqGLs+IiIiKoTUPXJPT0+4u7vj+PHjOHHiBMaMGYOpU6cauzYiIiLSQaqRCyHQtWtX7dc9\nevTA06dPjVYUERERyZFq5K1bt8ayZcvw8OFDJCYmYu3atWjQoAFiYmIQExNj7BqJiIioAFL3yPft\n2wcAL0wAM3z4cGg0Gu33iYiIqHhJNfL9+/cbuw4iIiJSQKqRX79+HWFhYXjy5Em+x/38/IxSFBER\nEcmRauQTJkxAnz590LhxY2PXQ0RERHqQauTW1taYMGGCsWshIiIiPUk18kGDBmHRokVo165dvnXI\nP/zwQ72SZWZmYsqUKbh37x5KlSqF2bNnw9zcHFOmTIFGo0HDhg0xffp0lColNZieiIjotSfVyE+c\nOIHz58/j9OnT2sc0Gg1+/fVXvZL9+eefyMrKwoYNG3D48GEsXrwYmZmZcHNzQ9u2beHj44N9+/ah\nR48e+v0WRERErympRn7hwgXs2bPH4GT16tVDdnY2cnJykJKSAnNzc5w9exZt2rQBAHTu3BmHDx9m\nIyciIpIk1cgbNWqEy5cv45133jEoWbly5XDv3j188sknSExMRFBQEE6ePAmNRgMAsLKyQnJyss7n\nqVy5HMzNzaRy2thUUFSr0jglscVdY3H+bmrMqaZaTZFTTbWaIqeaajVFTjXVaoqcSuKkGvmdO3cw\naNAg2NjYoHTp0hBCKJoIJjg4GB07dsS3336L+/fvY+TIkcjMzNR+PzU1FdbW1jqfJzFRfnrY+Hjd\nBwZFGadvrI1NBUW5ijvudcmpplpNkVNNtZoip5pqNUVONdVqipy64gpq8lKNfOnSpXoX9DLW1tYo\nXbo0AKBixYrIyspC06ZNcfz4cbRt2xaRkZFo165dkeQiIiJ6HRTayHPnUc+99G2oUaNGwdPTE46O\njsjMzIS7uzveffddeHt7IyAgAPXr10evXr2KJBcREdHroNBGnjuXuhDihe8pubRuZWWFJUuWvPB4\naGioXs9DREREzxXayGXmWL948SKaNWtWZAURERGRPINnXvHy8iqKOoiIiEgBgxv5yy67ExERUfEw\nuJEX1UA4IiIi0h8nNSciIlIxqc+RU9H5fG7BAwhXT+lWjJUQEVFJwHvkREREKibdyE+dOoX169cj\nIyMDJ0+e1D4eGBholMKIiIhIN6lG/ssvv2Dx4sUIDg5GamoqfHx88PPPPwMAatWqZdQCiYiIqGBS\njXzr1q34+eefUbZsWVSuXBmbN29GeHi4sWsjIiIiHaQaealSpWBhYaH92tLSEmZmcsuIEhERkfFI\njVpv06YN5s2bh7S0NERERGDjxo1cpYyIiOgVIHVG7uHhgTp16qBx48bYtm0bunTpgsmTJxu7NiIi\nItJB6ozcz88P/fv3x9ChQ41dDxEREelBqpHXrVsXc+bMwZMnT9C3b1/0798fNWvWNHZtREREpIPU\npXUnJyesX78eq1atgqWlJb7++msMGzbM2LURERGRDtITwiQnJ+PIkSM4fPgwsrOz0bFjR2PWRURE\nRBKkLq27uLjgv//9L3r27IlvvvkGLVq0MHZdREREJEGqkdvb26Nz584wN+caK0RERK+SQjtzYGAg\nXF1dsXfvXuzdu/eF7/v5+RmtMCIiItKt0EberFkzAM8nhPk3jUZjnIqIiIhIWqGNvFu35+tjx8XF\nYdy4cfm+FxAQYLyqiIiISEqhjXzBggVISEjA/v37cfPmTe3j2dnZiIqKwqRJk4xdHxERERWi0Ebe\ns2dPREdH49ixY/kur5uZmWH8+PFGL46IiIgKV2gjb968OZo3b47u3bujQoUK2seFELh7967RiyMi\nIqLCSX2e7LfffkNAQADS0tK0j9WoUQMRERFGK4yIiIh0k5rZbfXq1fjtt9/Qp08f7N27F76+vpwU\nhoiI6BUg1cjfeOMN1KpVC40bN8aVK1dgZ2eHGzduGLs2IiIi0kGqkZctWxbHjh1D48aNceDAAcTH\nxyMpKcnYtREREZEOUo3cy8sL+/fvR6dOnfD48WP07t0bw4cPV5Twp59+goODA+zs7LBp0ybcunUL\nw4YNg6OjI6ZPn46cnBxFz0tERPQ6khrs1qhRI3h6egJ4Pm2rUsePH8eZM2ewfv16pKWlYfXq1fDz\n84Obmxvatm0LHx8f7Nu3Dz169FCco6T6fO7+Qr+/ekq3YqqEiIheJTpnditsKtZ9+/bplezQoUNo\n1KgRvv76a6SkpMDDwwNhYWHaz6h37twZhw8fZiMnIiKSVGgjDwkJKdJkiYmJiImJQVBQEO7evYuv\nvvoKQgjtwYKVlRWSk5N1Pk/lyuVgbm4mldPGpoLuHyrCuFcxZ79vfyvwe78vHFBkeYwRZ4qcaqrV\nFDnVVKspcqqpVlPkVFOtpsipJK7QRl6jRg3t/3///Xdcu3YNLi4u2L17NwYOHKh3skqVKqF+/fqw\nsLBA/fr1YWlpiQcPHmi/n5qaCmtra53Pk5j4VDpnfLzuA4OijCvJOW1sKijKozTOFDnVVKspcqqp\nVlPkVFOtpsipplpNkVNXXEFNXmqw24IFC/Dnn39iz549yM7ORnh4OObOnat3ka1atcJff/0FIQRi\nY2ORlpaG9u3b4/jx4wCAyMhItG7dWu/nJSIiel1JNfJDhw7B398flpaWKF++PNasWYPIyEi9k3Xt\n2hVNmjTB4MGD8dVXX8HHxweTJ09GYGAgHBwckJmZiV69eun9vERERK8rqVHrpUo97/e597IzMjK0\nj+nLw8PjhcdCQ0MVPRcREdHrTqqR9+7dG25ubnjy5AmCg4Px22+/oW/fvsaujYiIiHTQ2civX7+O\nAQMGoEmTJqhevToePHiAUaNG4e+//y6O+oiIiKgQhV4fDwwMxGeffYbevXujVKlS+H//7/+hSpUq\nmDlzJmJiYoqrRiIiIipAoWfk27Ztw+7duxEXF4cffvgBq1atwsOHD7FkyRJ06tSpuGokIiKiAhTa\nyK2srGBrawtbW1ucO3cOAwcOxKpVq2BmJjcZCxERERlXoY0878j0ypUrY8qUKUYviF4dhc3vzrnd\niYheDYXeI887z3qZMmWMXgwRERHpp9Az8qtXr+Ljjz8GAMTGxmr/nzs/ur6LphAREVHRKrSR7969\nu7jqICIiIgWkF00hIiKiV4+yeVaJiIjolSA1RSuRvjjinYioePCMnIiISMXYyImIiFSMjZyIiEjF\n2MiJiIhUjI2ciIhIxdjIiYiIVIyNnIiISMXYyImIiFSMjZyIiEjF2MiJiIhUjI2ciIhIxdjIiYiI\nVIyNnIiISMW4+hm9UrhqGhGRfnhGTkREpGI8I6cSobAzeYBn80RUcvGMnIiISMVM0sgTEhLQpUsX\nREdH49atWxg2bBgcHR0xffp05OTkmKIkIiIiVSr2Rp6ZmQkfHx+UKVMGAODn5wc3NzesW7cOQgjs\n27evuEsiIiJSrWJv5PPmzcPQoUNha2sLALh48SLatGkDAOjcuTOOHDlS3CURERGpVrE28i1btqBK\nlSro1KmT9jEhBDQaDQDAysoKycnJxVkSERGRqhXrqPXw8HBoNBocPXoUly5dwuTJk/Ho0SPt91NT\nU2Ftba3zeSpXLgdzczOpnDY2FRTVqjTudcmpplr1jS3Jv5sp416XnGqq1RQ51VSrKXIqiSvWRr52\n7Vrt/52dnTFjxgz4+/vj+PHjaNu2LSIjI9GuXTudz5OY+FQ6Z3y8sjN8pXGvS0411apPrI1NBcV5\nlMaqKaeaajVFTjXVaoqcaqrVFDl1xRXU5E3+8bPJkycjMDAQDg4OyMzMRK9evUxdEhERkWqYbEKY\nkJAQ7f9DQ0NNVQYREZGqmfyMnIiIiJRjIyciIlIxNnIiIiIVYyMnIiJSMTZyIiIiFWMjJyIiUjE2\nciIiIhVjIyciIlIxNnIiIiIVYyMnIiJSMTZyIiIiFWMjJyIiUjE2ciIiIhUz2epnRK+Kz+fuL/B7\nq6d0K8ZKiIj0xzNyIiIiFWMjJyIiUjE2ciIiIhVjIyciIlIxNnIiIiIVYyMnIiJSMTZyIiIiFWMj\nJyIiUjE2ciIiIhVjIyciIlIxNnIiIiIVYyMnIiJSMTZyIiIiFWMjJyIiUjEuY0qkEJc/JaJXQbE2\n8szMTHh6euLevXvIyMjAV199hbfffhtTpkyBRqNBw4YNMX36dJQqxQsFREREMoq1kW/fvh2VKlWC\nv78/Hj9+jIEDB+Kdd96Bm5sb2rZtCx8fH+zbtw89evQozrKIiIhUq1hPfXv37o1vvvkGACCEgJmZ\nGS5evIg2bdoAADp37owjR44UZ0lERESqVqyN3MrKCuXLl0dKSgomTpwINzc3CCGg0Wi0309OTi7O\nkoiIiFSt2Ae73b9/H19//TUcHR3Rr18/+Pv7a7+XmpoKa2trnc9RuXI5mJubSeWzsamgqE6lca9L\nTjXVaoqc+saV5N/tdcupplpNkVNNtZoip5K4Ym3kDx8+xOeffw4fHx+0b98eANC0aVMcP34cbdu2\nRWRkJNq1a6fzeRITn0rnjI9XdoavNO51yammWk2RU584G5sKivMojS3uuNclp5pqNUVONdVqipy6\n4gpq8sV6aT0oKAhJSUlYtmwZnJ2d4ezsDDc3NwQGBsLBwQGZmZno1atXcZZERESkasV6Ru7l5QUv\nL68XHg8NDS3OMoiIiEoMfmCbiIhIxdjIiYiIVIyNnIiISMXYyImIiFSMjZyIiEjFuPoZkQlw5TQi\nKio8IyciIlIxNnIiIiIV46V1IhXhJXki+jeekRMREakYz8iJXgOFnckDPJsnUjOekRMREakYGzkR\nEZGK8dI6ERWKA+yIXm08IyciIlIxNnIiIiIVYyMnIiJSMTZyIiIiFeNgNyIyCg6SIyoebORE9Mrh\nQQCRPF5aJyIiUjE2ciIiIhXjpXUiKjF4SZ5eR2zkRPTaM2RRGR48kKnx0joREZGK8YyciMgEeCZP\nRYWNnIhIZXgQQHmxkRMRvSaUHgAYMoaAjI/3yImIiFTslTgjz8nJwYwZM/DPP//AwsIC33//PerU\nqWPqsoiIyEDGuArAKwD5vRKNPCIiAhkZGdi4cSPOnj2LuXPnYvny5aYui4iIVOh1O3h4JRr5qVOn\n0KlTJwDA+++/jwsXLpi4IiIiIjmmHkPwStwjT0lJQfny5bVfm5mZISsry4QVERERqYNGCCFMXYSf\nnx9atGiBPn36AAA6d+6MyMhIE1dFRET06nslzsg/+OADbeM+e/YsGjVqZOKKiIiI1OGVOCPPHbV+\n5coVCCEwZ84cNGjQwNRlERERvfJeiUZOREREyrwSl9aJiIhIGTZyIiIiFWMjJyIiUjE2ciIiIhUr\nMY08ISEBMTEx2n/GNmvWrHxfe3h4GD3n+fPn83194sQJo+csbv+eCCgpKanYcj9+/LjYcpnCgwcP\n8n19/fp1E1VSsrwO78u81PA+uXLlChwdHdG3b1+sWLECBw4cMHVJRvVKTNFqqBkzZiAyMhK2trYQ\nQkCj0WDDhg2FxmRnZyM7OxuTJk3CokWLIISAEAJffPEFfv311wLj1q5di+XLl+Px48fYs2cPAEAI\ngbffflu63oSEBKSnp2u/rl69eqE///fff+PatWsIDg7G6NGjtfWvW7cOO3bs0JnvypUrmDFjBpKS\nktC/f380bNgQXbt2lap12bJlGD9+vPbrhQsX4ttvv9UZd+nSJWzcuDHf7+nn51fgz8fHxyMlJQWT\nJ0/G/PnzIYRATk4OJk+ejM2bN0vVOmvWLPj4+Gi/9vDwwPz583XGnThxArNmzUJ2djZ69+6N6tWr\nY8iQIVI5hRA4f/58vt/zww8/1Bl34MCBfH+DXbt2aSdE0iUlJQV3795F7dq1Ua5cOZ0/f+XKFcTG\nxmLBggX47rvvADzffgICAvDbb79J5VTi8OHDWLNmDTIyMrSPFfbeyislJQWRkZH5YgcOHKgzLjY2\nFv7+/nioCkPHAAAgAElEQVT06BF69+6Nxo0bo0WLFlI579+/jx07duT7W06YMKHAnzf0fZmdnY0t\nW7YgJiYG7dq1Q8OGDVGlShWdMUr2W7mUbq+AYe+Tmzdv4tatW2jcuDHefPNNaDQaqTgAOHr0KG7f\nvo0WLVqgXr16sLS01Bnj6+sLPz8/eHl5YfDgwRg7dqz0Pk9pTn33eYWdcOrqCf9WIhr5uXPnEBER\ngVKl5C8whIeHIygoCA8fPkTv3r0hhECpUqXQunXrQuOcnJzg5OSEoKAguLi46F2rkoMOa2trPHz4\nEBkZGYiPjwcAaDQa7U5ZFyUb9aZNm7B582ZER0drJ+vJzs5GVlaWVCOfMmUKhg8fjrfeekuqxqio\nKPzyyy+4ceMGfHx8tH+Pjh076ow19OBqyZIlCA0NhaurK1xcXDBs2DDpHZSrqysSEhJQrVo1AM//\nLoXtGA8cOIDTp09j586dOHPmDIDnr+v+/fulGvkff/yBoKAg7c5Uo9HkO9B6maSkJOzatQsJCQnY\nuXOntk5HR0ep3zEoKAirVq1CmTJltI8dOnRIZ5yfnx88PT2lt4G8xo8fD1tb23yvqwxvb2+MHj0a\ny5YtQ+vWrTFlyhSEhYVJxX7zzTdo3769Nqcuhr4vfXx8YGtriyNHjuC9997D5MmTsXLlykJjlO63\ncum7veal9H0SGhqKvXv34smTJxg4cCBu376d74C7MAEBAXjw4AGio6NhYWGBFStWICAgQCq2Tp06\n0Gg0qFKlCqysrKRiDMmp7z7P3d0dwPMrHKmpqWjYsCGuXbuGqlWrYuvWrdL1AgBECeDm5iaePn2q\nKHbTpk2K4h48eCCuXr0qrl+/LqZOnSouXbokFTdo0CCRnZ2tOGeumJgY6bgRI0YIIYRwdnYWQggx\nfPhwnTHp6enizp07wsvLS9y9e1fcvXtXxMTEiPT0dKmcn3/+uXR9eR08eFBRnBBCLF++XFFc7uuh\nz+uTy8HBQa9cMTExYsuWLaJ3795iy5YtYsuWLWLr1q3iv//9r3S+9PR0MXz4cJGTkyMGDRoknfvC\nhQva/+uzDfbr10/R+2vs2LF6x+TS52+QV+7fUMnfctSoUYpyKn1f/nu702dbUrrf0nd7zUvp+2To\n0KEiOztb+/N2dnbSOR0dHfPlGjJkiFScq6urWL9+vRg8eLDYsWOHGD9+vNFzKt3njR8/XiQnJwsh\nhEhNTRXjxo3T+zlKxBn5/fv30bVrV+0a5jJnubneffddnDlzBqVKlUJAQABcXFzQvn17nXHffvst\nJkyYgHXr1qFXr17w9fVFSEiIzrg6deogPT0dZcuWlaovr99//x3W1tZISkrCli1b0KlTJ0ydOlVn\nXMWKFbFhwwakpaVh586dsLa21hljYWGBmjVrYurUqUhKSoK5uTk2btyIgQMHokaNGjrja9SogRUr\nVqBJkybasymZs+vSpUsjMjISQgjMnj0b33zzDfr166czDgAGDRqEa9euwczMDCtXrsSIESPwzjvv\n6IyrXbs2Fi5ciMePH2PFihV6XdaqV68eYmNj8eabb0r9fLVq1TBo0CAMGDAAwPNZDc+ePSs9k6GZ\nmRksLCyg0Wig0Wj02o6io6Nx8+ZNZGRkwN/fH2PGjMGYMWN0xtWsWTPf2bisN954Az4+PmjatKl2\nG3BwcJCKbdy4MaKiotCkSRPtYxYWFjrjLC0t8ddff2lfV5mYXA0bNsTOnTvzbbP16tXTGaf0fZmd\nnY1Hjx4BeH4rQZ8rikr3W/pur3kpfZ+I///KY+5rqs/fJDs7G+np6dBoNMjOzpZ+jebMmYOgoCBU\nrlwZFy5cgK+vr9FzKt3n3b9/X7toWNmyZREXFydda64S0cgXLlyoOHbGjBnw9vZGYGAg3N3d4e/v\nL/WGyL0kFRQUhE8//VT68p0hBx179uxBaGgoxo4di127dmHEiBFScYZs1BMnTsTQoUOxZ88evP32\n2/Dx8cHPP/+sMy4zMxM3btzAjRs3tI/JbNSLFi3CwoULMXPmTKxfvx5ubm7SjVzpwdXMmTOxadMm\ntGrVCuXKlcPs2bOl8gHA6dOn0bVr13z3NmUvOzdo0AAxMTG4ePEiqlatinnz5umMa9WqFb799lvE\nxsbCx8cH7733nnStv/76K1auXIlJkybh4MGD+Pzzz6UaeWZmJvr166ddA0Gj0Ui952rWrAkAePjw\noXSNuU6cOIH9+/+3NKRGo8G+fft0xs2ePRvz5s1DYmIiVq9ejRkzZkjnvHTpEi5dupQvp8x9Z6Xv\nSzc3NwwbNgzx8fFwcHCAp6endK1K91tKt1dA+fukb9++cHJyQkxMDL744gt0795dKg4ARo4cCTs7\nOzx69AhDhgzBqFGjpOLKly+PcePGQaPRICIiQq978kpzKt3nderUCcOHD8e7776Lc+fOoWfPntK1\n5ioRjTwrKwt//PEHMjMzAQBxcXEvjCoviIWFBRo2bIjMzEy8//770kdfWVlZ8Pf3R+vWrXHs2DFt\nbl0MOegoVaoUHj58iKpVqwIAnj17JhVnyEb97NkzfPzxx/j1118xf/58HDlyRCru34M8ZI8yy5Qp\ngzfeeAPm5uawsbHRq1alB1cZGRno2rUrunfvjrCwMMTHx0tddQCA3bt3S9eX1/nz5zFt2jQ4Ozsj\nJCQEI0eOlIqbNGkSIiMj0aRJEzRo0ECvATy5A3asrKxgYWEhvVTwF198IZ0jrwkTJiAuLg5ZWVkQ\nQuh1prF9+3ZFOd966y0sWLAAQgicPXtWrzPPfx/05R1oVxil78s2bdpg9+7dePToEaytrWFuLr87\nVrrfUrq9AsrfJ8OHD0f79u1x5coV1K9fH40bN5bO+cknn+D//u//cOvWLdSqVQuVK1eWinN3d8dH\nH32EM2fOICcnB3v37sXSpUuNmlPffd6mTZswZMgQ5OTkoHTp0jhw4ABq1aqFp0+fSuXLq0Q08m+/\n/RY9evTA6dOnYWtrq9cLodFo4OHhgc6dO2PXrl0oXbq0VNycOXNw5MgRDBkyBBEREVJnU4BhBx1t\n27aFs7Mz/P39MWfOHHTp0kUqzpCNOjMzE7/88guaNWuGa9euIS0tTSpuyZIlWL9+PTIzM/Hs2TPU\nrVtXO9CqMOXLl8fYsWPh4OCAtWvX6hzFm5fSg6uJEydi2LBh2L17t15XHYDnq/Vt2bIl399TJjYn\nJwcXLlxAzZo1kZGRgdTUVKl8sbGxqF69OmrWrIlVq1bhrbfeynf5uTC1a9eGg4MDpk6dih9//FF6\nh9qoUSMcOnQoX0Nu06aNzjhPT0+cPXsWaWlpePbsGWrVqiV9cLVv3z6sW7cOmZmZEELg8ePH+P33\n33XG+fr6KrrSAQAbNmzAmjVrtL9n6dKlpRqf0vfl9u3bYWZmpvetDkD5fkvp9goof59cvnwZaWlp\nqFatGubMmSN9GwAAjhw5gqysLOTk5GDSpEnSt9ri4uIwYMAAbN68GSEhIdJn1Ybk1Heflzsorn79\n+qhfv750fS+l6O78KyZ38MWUKVOEEEIMGzZMOjYhIUEcPHhQ5OTkiKNHj4rExESpuNGjR+tfqBDi\ns88+E0FBQWL06NFi8uTJwtXVVTr2t99+0/5fdtCZEC8O3hg5cqR07KlTp8S8efPEkydPREhIiIiK\nipKK69+/v0hPTxfTp08XN2/elH69rl27Jq5evSqEEOKff/7R6/e8fv26CA0NFenp6WLnzp3i9u3b\nUnFOTk4iJydHux3p8/oMGDBA/P7772LChAnihx9+EJMmTZKKW7t2rRg8eLC4cuWK+P7770VYWJh0\nrUePHhWurq5ix44deg3mOnr0qEhJSRFCCBEXFycd5+TkJLy9vYWDg4MYMWKE9GCcQYMGiZycHOHl\n5SUSEhL0qrVv377i9OnTwsPDQ4SHh0u/rrmDuXJz5Q70lM0ZGxsrZsyYIY4dOya++uorqTil78vP\nPvtMPHr0SIwaNUqkp6cLJycn6Vil+y2l26sQyt8nDg4O4sKFC2LcuHHizJkz2v2RjMGDB4tbt26J\nzz//XMTFxUnHDhkyROzevVvMmDFDJCQkiMGDBxs9p9J9XlEoERPCaDQaxMfHIzU1FU+fPtXrjPzr\nr79Gly5doNFo0K5dO1SqVEkqztraGvv27UN0dPQL90UKU65cOYwbNw5vvvkm5s6dq9f9w7xnM/oM\nGMnMzNTe43706JH02R/w/KNdHh4esLa2xvDhw9G8eXOpOBsbG1hYWCA1NRV16tSRPjv28vLSfmys\nUaNGev2es2fPhpOTEywsLNCnTx/UqlVLKk7pVQcAqFy5Mvr27Yvy5cvD1dUVsbGxUnFpaWnYtGkT\nGjZsiGnTpkl/3C339kFSUhI+/fRTvQZIBQYGaj+GY2NjIx0nhMCsWbNQr149rFmzRnpCkMqVK0Oj\n0eDp06d6XVkBAFtbW7Rs2RIAYGdnJ31ZXumVjtyctra2SE1NRdu2bZGcnCwVp/R9mTuAUN9bHYDy\n/ZbS7RVQ/j5RehsAUH6rLXe8wrhx4xASEqLzI5pFkVPpPq8olIhL6xMmTMDevXsxYMAAdO/eXTsi\nWEbFihXxyy+/oF69etoNTGaAQkJCAoKDg7Vfyw6MMeSgIyMjAwMHDkS9evW0o0Bl7rnnbtRTpkzR\ne6POyMjA5cuXtTkBuZ3VW2+9hc2bN6Ns2bJYuHCh9Axt5cqVw5w5c/L9PWRHOuceXNWtW1cbKzPq\nePLkyYiIiMBXX32F7du3Y9q0aVL5gOf3R69evYq0tDRcv34dT548kYr7888/MWrUKJiZmUnnApTf\nPgCeb3tff/11vtd20qRJOuPMzMyQnp6OtLQ07UheGc2aNcPPP/8MW1tbuLu7S987Bp5/euHkyZPI\nysrCX3/9hcTERKm4AQMGYObMmZgzZw78/f2ltx0AqFChgnYMyYYNG6QPWJS+L2vVqqXoVgegfL+l\ndHsFlL9PlN4GAJTfauvZs6d20Ng333yjfXz69OmYOXOmUXIq3ecVhRKzHnnubFe1atXS68P/L/uY\nSGGz8eSVmJiIO3fuoGbNmtJ/7JMnT+Lq1at488034e3tjQEDBmDy5MlSsS+b+lHmXmVBZDbqfv36\n5TurkR09nJOTgwcPHsDa2hpbt25F+/btpSZo+fHHH194rLDZtfJydnbO97XswVVBvv76a51jCa5e\nvar9e/r6+qJ///5S9+P69euHhIQE1KxZU7vzl/n0ws2bN3H48GHt2Iz33nsPtWrVQkZGhs4DrJdN\nMjFo0CCdOXfv3o2bN2+iSpUqCAwMRKtWrbBo0SKdcQCQmpoKS0tLREZGonnz5toBYbrExsbi+vXr\nsLGxwZIlS9C7d298+umnUrEv8+OPP+rcjlJSUnDnzh1UqVIFa9asQdeuXdG2bVudz23I+zI1NRVW\nVlaIj4/XXiWJiIjQObJb6X5L6fZaGF3vk0ePHuH8+fPo3Lkzjh8/jnfeeQeVKlXCvXv3dA6Wy8jI\nwO3bt/H222/jypUrqFu3LiwsLBAVFSU9Y19eI0aM0LlPUJpT6T6vKJSIRr57924sX75cr9mu8rpy\n5QquXbuGevXqSQ8c+s9//oPFixejQYMGuHr1KiZMmCB9JUDpQUdKSgqWLl2K6Oho1K1bF+PHj5e+\npPYyMht1roSEBFSqVEn6DDIlJQUrV65EXFwcunbtisaNG2s/cqfLwYMHcfXqVdSrV0+vj6oAyg6u\nCpI7olyX3OknGzVqhLfeekvqUty9e/deeEx2pPzLyPwts7KysHHjRly7dg1169bFsGHD9LoU/Pjx\nY5ibm2s/86qLIdOlAsqmySyIzOujZMpUwHTvSyX7LUDZ9loY2ffJv+mz/ymqWGPmNGSfZ6gScY98\nzZo1CAsLQ6VKlTB+/HhERERIx4aEhMDb2xtnzpyBt7e39AjO4OBgbNmyBcuWLcPWrVulN47du3dj\n+PDh+O677xAcHIxly5ZJ1+rp6Ynq1avD3d0dNWrUwJQpU6RjlTp+/Dg+/vhjjBkzBj169MDhw4el\n4jw9PVGrVi3cunULVatWlb4Mt3DhQmzZsgWlS5fGtm3bpEccA88ProYOHYqgoCA4ODgYPI+4zA4u\nNDQU06dPx6JFi7Bnzx7pz9aamZlh3rx5+PLLLzFnzhwYejwtE+/j44M7d+6gQ4cOuHfvHry8vKSe\n++TJk+jbty+GDRuGn3/+GZs2bZKK8/b2xmeffYbMzEy0bt1ar/kLAgICsHXrVoSFheHSpUtSE6wU\nRvb1iYmJwZEjR5Camip9payo35cytSrdbyndXguj9EDAkG3eFOefunIq3ecVhRLRyA2Z7WrHjh1Y\nu3Ytpk2bhvXr12PXrl1ScRqNRns2Xb58eemzBUMOOhITE+Hs7IwmTZpg5MiRxXIPZvHixVi3bh22\nbduG9evXY/HixVJxjx8/xuDBg2Fubo4PPvgAOTk5UnEnT57EDz/8gFGjRiEwMBB///23dK1KD64M\nsXPnTqxZswYVKlTAyJEjERUVJRXn5eWFAQMGYP369Rg0aJDBb3qZnemtW7cwZcoUdO/eHZ6enrh9\n+7bUcy9evBihoaGoWrUqXFxcsH79eqm4Z8+eoX379tBoNKhfv75eZ9SnTp3C/PnzUa5cOQwaNAh3\n796Vjn0Zmdfn9u3b+Oabb2BpaYlu3bpJD3Yr6velTK1K91tKt1djMORKgKFXEYyRU+k+ryiUiEbe\nqlUrTJo0SdFsV0II7UQMpUuXlh6IUatWLcydOxcRERGYO3cuateuLRVnyEFHenq6dnGGhw8fFsuG\nYmZmpp1U480339RrZxwdHQ3g+fKZspfkcz+/CfxvakdZSg+uDCEUTj+Znp6Ojz/+GNbW1ujevbte\nI5aVyh2wBjxvsrKD1kqVKoVKlSpBo9HA0tJS+naQIdOlKp0m0xBKp0w1xftS6X5L6fZaUhj7TF7J\nPq8olIhR67mzXTVt2lTv2a4++OADTJw4Ea1atcKpU6e0H3nRxc/PDxs3bsSRI0fQoEEDqRXBAMMO\nOtzc3DB06FCUL18eqampBl8Wk9moy5cvj5CQEHz44Yc4efIkKlasKPXcXl5e8PT0RHR0NCZOnIjp\n06dLxfXp0wfDhg1DixYtcO7cOemlPYH/HVy1bt0af//9t/TB1fXr1186IYPM76p0+sns7Gz8888/\naNy4Mf755x+DzzBk/pYjRozAgAEDtKssTZw4Ueq5lc6xbch0qUqnySyIzOujdMpUU7wvle63DJku\ntSCy+4R/M+al9djYWCQnJ2vXXci9YrJ69Wqj5VS6zysKJWKw2507d3DgwIF868DqM63kwYMHER0d\njQYNGuCjjz6SihkzZgx69uyJHj166D2oKjIyEleuXNH7oOPs2bN4//338ejRI71yPn78+IWZucaN\nG4fMzEydR/LJyclYtmyZttm5uLgofuPKyJ2vODdf7vzeMnIHc+X+Le3t7aXOVIYNGyZ9ufhloqOj\n9Z5+8tKlS/Dy8kJcXBzefPNNzJ49W68BS/82c+ZMnTuOuLg4WFhYaAcDyk49mZWVhU2bNmm3WQcH\nB+kzwJSUlHzvyzfeeEMqDgCePHmi9zSZ48aNw5AhQ9C1a9d8Z0T379+XXp5U3/eX0vcl8PJ1uvfv\n349u3brpjFWy3wKUba+A/uu1v0xOTo72SsfSpUvx9ddfF/rzf/zxB7p37/7C9LVhYWGwt7cvMG74\n8OH51l3YsGGDogF5ebcbXTlNqUQ08n79+qFnz575VvWSnbvazs4OHTt2RM+ePfHuu+9K54yNjcW+\nffsQGRmJjIwMfPTRR1KLJRhy0OHt7Y2LFy+iZcuW6NmzJz788EOpy3/Dhw9H/fr1ceXKFVhaWqJs\n2bIICgqSyunj44OePXuiffv2el0qWrRoEcLDw/M9JrM4g52dHerVq4eePXuiS5cueq26pfTgasyY\nMWjQoIGiz66fO3cOO3fuzPf3lDnz3LlzJz766CO9PrUA/G/6SKFgdbgxY8Zo58vu0aOH9IQ5ycnJ\nOHHiRL7fUeZKiYeHB06fPo0KFSpoL+nKrrO8f/9+bNmyJV9OXWt1A8+bVHh4OA4fPoyOHTtiyJAh\nqFu3rlTODRs2YOPGjflyytx7Vvq+NGSdbqX7LaXbKwDY29u/sF770KFDdcblnYp2/vz5GDt2rPRU\ntAsWLEBkZCQ6dOiAwYMHS68S6OzsjODgYIwZMwbBwcEYOXIkfvnlF6nYVatWKVrNTuk+r0gYf/I4\n4/viiy8Ux6anp4uDBw+K6dOnCwcHB+Hr6ysde+7cObF8+XLx2WefSa/z27dvX/HDDz+I4OBg7T99\nnTx5Utjb24t27dpJ/XzuFINTpkwR2dnZeq1JfOrUKTF//nzh4OAgPDw8REREhFRc7nSFSly7dk38\n9NNPwsHBQa91hB88eCDWrl0rxo0bJ0aPHi1++eUXqbjAwMAX/snq3bu3CA8PF3v37tX+k7F8+XLh\n6Ogoxo0bJ8LDw6Wn2FQ6fWSu5ORksXPnTuHg4CAGDBggnXPKlCnC19dX+Pr6ijlz5kjHKdWzZ09x\n7NgxcenSJe0/fSQkJIhJkyaJZs2aiVGjRokzZ87ojPnkk0/EnTt3RFJSkvafPvR9XxqyTrfS/ZbS\n7VUI5eu1GzIVrRBCZGdniwMHDogJEyYIBwcHER4eLjIyMgqNGTp0qPDz8xOBgYHi6NGjek3bPWTI\nEJGenv7C2va6GLLPM1SJuEfetWtXLFiwIN+H7wcOHCgVm5aWhrS0NGRnZyMjIwMJCQlScW3atEH1\n6tXx5ZdfakeByqhWrRpcXV2lfvbfgoODcezYMTx69AgffPCB9PMonZkLeH4vrk6dOnjnnXcQGhqK\nmTNn4uOPP9YZ17RpU6Snp+s9mObSpUs4cuQIjh8/DgDSR+DA88F47733HpKSkhARESG9pOSECRNw\n5MgR3LlzR/uZZVl16tSBnZ2d9M/ncnFxgYuLC86fP4/vv/8ePj4+uHDhgs44Q1aHi4iIwJEjRxAV\nFYXq1atLzQQGPJ/xTHaSpLyaN29e4PgDXRo2bCg1Gcu//fnnn9i6dSuio6MxYMAAeHp6IisrC198\n8YXOFdUaN26MatWq6T1ISen7Uhgw8Ezpfkvp9gooX6/dkKlohRA4dOgQtm3bhnv37qF///5ITEyE\ni4tLoR+58/Pzyzdxkj4fY1W6mp3SfV5RKBGNfNeuXahfv752xKA+O7f27dujUaNGcHd312uQyooV\nK/DXX39h8+bN+OOPP/B///d/UpeZDDnoOHToEJKSktCzZ0907NgR77zzjlSck5MTgoOD0aFDB3Tp\n0gWtWrWSigOA/v37w8zMDP369cPs2bOl71k3bNgQHTt2RNWqVbU7LJkZ4YYPH45atWrB3d1dehWp\nXEoPrgICAvDgwQNER0fDwsICK1asQEBAgFRsr1694O7unu+AQ+a+oa+vL86dO6ed+3ru3LlS+QxZ\nHW7hwoWwsLDAl19+iU6dOuW7FVWYjh07Yv369fm22Q8//FCq1sGDB6NcuXLax2QvNX788cdwcHDI\ndxAgczCxfft2DBs27IWDAJnm2q5dO3Tv3h21atXSbrMyH2FU+r40ZOCZ0v2W0u0VUL5euyFT0fbs\n2ROtW7eGs7Nzvv3WtWvXCo379ddftbcp+vTpAw8PD8yfP18qp9LV7JTu84pCibhHPmbMGOkJEf4t\nLi4Ohw4dwuHDh5GYmIhmzZpJj0CPjY3FwYMHsWPHDmRkZGDjxo06Y5ydnVG/fn3tTlSj0UjNd50r\nPT0dx44dw6pVq3Djxg297sHoOzMX8Pxe7l9//YX79+/jnXfeQceOHdGpUyedcYMHD0ZQUFC+ZiFz\npJqVlYVTp07h0KFDOHfuHN544w3ppnr27Fn89ddfOHPmDMqXLy99cOXk5IS1a9dqZ6iyt7eXXm5z\n8ODBL4zPkMk5ffp03LhxAw0aNEDHjh3Rrl07qfvleaePvHr1KurUqaPXGcDdu3dx6NAh7Nq1C8+e\nPZP6PcePH4+MjIx826zMXOJDhw5FaGioXuts57Kzs8PYsWPzHYzJbHezZs3Kd59Znx24nZ0dpk+f\nni+n7NUEJe/L69evQwiBK1euoF69etIHAIDy/ZbS7TWX0pkTc6eizXumK0Nmat281q5di+XLl+Px\n48f5Ztdr0KCB9D3yvGQGBOdSus8rCiXijLx69er46aef0LRpU+3ZuOxlw6pVq6JOnTq4efMm7t27\n99KpM19m4MCBqFy5Mrp3744FCxZoP2uti4WFhc75zQuyZ88eREZG4uLFi3j33XelB8mdPHkSM2fO\n1E5hW716denVtj799FP07NkTx44dw4oVK7Br1y789ddfOuOqV6+OsmXL6r0hJyUlITY2FjExMUhL\nS5P+qBMAvP/++6hWrRpsbW2xY8cObN26VWonZchnlitVqoQvv/xS+udz5W4D586dg7+/P7755hup\nS+vXr19HWloaoqKiEBAQoNfazhcvXkRkZCQOHz6MMmXK4JNPPpGKe/r0ab4FgmTVrVsXCQkJ0u+N\nvKpWrarXRw9zd+BPnjzBnj17ADy/LKvPXNe5t2b0/cy60vdl7mQu+tw+yqV0v6V0ewWUT0ttyADN\nEydOIDs7W/p2h5OTE5ycnBAUFAQXFxepmH9zdnZ+4aquzJUHpfu8olAizsgNWfgkd5Rp7shs2T/C\nv4/4culaiMTb2xs1a9ZUdNDh5+eHHj16oFWrVvk2NF2T+Ts5OWHp0qVwdXXFqlWrMGzYMGzZskUq\np4uLC2JiYtCxY0d0794dLVu2lLp1YW9vr51PHoD0oiB2dnbo3r07evTogYYNG2ofl1kUJO/BVffu\n3aUbyH/+8x/8+OOPePToEapVq4bRo0dL72i+++47lC1bNt/fU2bE++rVq3Ho0CGkpaWhS5cu6NGj\nh9QOfejQofD29kZgYCBcXFzg7++PtWvXStU6YcIE9OjRA127ds131qBr8QpfX1+8//77et8b7dmz\nJ/Rkig0AACAASURBVO7du5fvo2OyV5AmTpyI1NTUfK+rzJUrQ3bgY8aMQVxcHBo2bKjNKXPlQen7\n0pBPSyjdbyndXnN/bvXq1bCyskJKSgpGjhz5wijtlxkyZAgWLlyImTNnYu7cuXBzc5PeZpUuLpSS\nkqL9RFEu2VuY169fB/D8QPDixYu4dOmS1HS9Svd5RaFEnJEX1LRlVvf6448/XnoErmtFn4IWRdC1\nLnlWVhZu3ryJmzdvah+TbeQFfQRi4cKFhR4xKp2ZC3g+2cXLLvnpuuRV0OpYunZuBR1gjB07VudR\ncXBwsKKDq5YtW2LdunW4desWatasKb18JQDtogj6rCsPAObm5vD19X3hs826Vr4yZG3nl60sBzzf\nrgp7bS9fvozLly9rv5a9N5p7ZvxvMqt7FTS/QkEHdAcOHEDXrl1RqVKlF25xyTaqcePGvfRxXQc6\nSt+XuZO4yA5Uy0vpfkvp9goonznRkAGagYGB+S5tyy67On78eNja2mrfX/rkzHs7pUGDBti8ebNU\nnNJ9XlEoEY28ILqaKoACd4TGmsfckIOOgui6qKJ0Zi4ABd63e9nSjXkVtOPTtXMriMyFI30Prq5c\nuYLY2FgsWLAA3333HQDgwoULWLhwofSCKwUdzOjaoRY0mv7XX38ttMkZsrZzQXS9tgVNpKHv/ctc\nun5HoODlVQs6oMs9+FLSoHIVtPSorgOdguh6XZWOHgeU77eUbq+A8pkTlQzQjI+PR0pKCiZPnoz5\n8+dDCIGcnBz4+PhINVYhBBYsWCBV37/lPRCMj4/H06dPpeKKep+njxLdyA1R3JPyyxx0FERXrdOn\nT0d4eDhatWqFsmXLFsmKR0rvyCiNM8bfIykpCbt27UJCQgJ27typzePo6Fgkz62Ertdn0aJFOH/+\nPLp06YJjx45JDwQsjNLXVtfBXEEMuZtXUGxu43/y5AkcHByKdB1oY22z7u7u0Gg0yMnJwd27d1Gn\nTh2DZhiUyVkQme1V6bTUS5Ysybe+t8z4nKioKPzyyy+4ceMGvL29ATw/eJG9etm4cWNERUXlmy1R\n9vZD7rz5uTGyC0UVpDjuXrORvwZcXFwMmmP4ZZTuMEyxalFBWrdujdatW+PixYto1qwZHj9+jIoV\nKxZJjcZ6fSwsLHD69Gn88ccf6Nq1K548eWLQ2teGMMVBma7Y1q1bw9/fH6mpqbCzs0OfPn30mh1Q\nSU6l8p75JSUlaRuWKRT2O54/fx7vvfcejh07hjp16mgvzx8/flyqsSYmJiIoKEi7Ln1aWprOS825\n41z+/PNPvT+GCjw/yNy/f7/2a5mPgj148ABvvfUWPv3003yPZ2Zm6p0/r+LY57GRFzFTjB3UldPa\n2hoRERH5BtXoM+nJq8CYr2tqair69u2raFR/cfP09ETnzp1x8uRJ7ZrHoaGhBj3nq3SVxFC9evVC\nr169EBcXBz8/P8yZM0evpXCLkj6va4UKFXDnzh0jVqPc0aNH8d5772mvWuUl08i9vb0xevRoLFu2\nDK1bt8aUKVOkP95ZrVo1ODo6IikpCf3790fDhg2l1qfQNfnPy6xevRqenp4vTJMrOybElEp0I5d5\nIyld+coYq+voI+9k/rpGWCckJOTbEDMyMgweTVncl9YNuVSqK+eSJUsQGhoKV1dXuLi4YNiwYSZr\n5LpqzV3zePv27QateZx38Yp27dopeg6ljHFpPVdMTAy2bduG3bt3o2nTplLzsxuas6CFPXS9Lx0c\nHKDRaCCEwKNHj6Q/RlgYYyxolPtxNT8/P2RnZ0MIgbNnz6J58+ZS8bnr0i9fvlzvdel9fX3h5+cH\nLy8vDB48GGPHji20kefOI5D72uala5+Xu9qdksVVCsNL65IMaaq5n+X8t8DAwELjvv3223yr68yZ\nMwchISGKBx/J/LELmsxf14o8ffr0QXBwsPYSkT4TdBS0mpTsJBuAfgcdBX3mVGZJwIJWedO1HRgy\nqt+QJVBftvLV6NGjdcYpXfO4oMUrdK1AVRCZbVbp71gQXQd0rq6uGDJkCNauXavXxEf/ps+BzoUL\nF7Bs2bIXFvbQ9b6cN2+edn9haWmp1+ePC1qJTNd+qyAy26uvry8aNGiAmJgYXLx4ETY2NlIzEhqy\nLj3wfKS9RqNBlSpVdL43x48fDwCKxo5069YtX/M3NzdHVlYWLC0tpRbPUXpAVySMMH97sXNychJH\njx4Vrq6uYseOHdpFCGR8/vnnwtfXV6xbt05s2LBBbNiwQSpu+PDhIisrS4wcOVIIIcSIESOk4hIT\nE8Xvv/8utm7dKrZs2SKCgoKEEELnIgBCKJ/Mv2/fviI2NlbMmDFDHDt2TK+FSK5duybmzZsn+vfv\nL+bPny9u3LghFbdy5UqxceNGsXLlSvHJJ5/otdCG0kVBnJychLe3t3BwcBAjRowQ48aNk4rz9PQU\nCxYsEP369RM//fST8PDwkM45dOhQ6Z/NKyQkRIwYMUIMGDBArFmzRsycOVMq7p9//hH29vaiVatW\nYsiQIeLChQvSOZUuXvHll1+KvXv3iqysrHyPx8TEFBqn9HcUQojDhw+LP//8Uxw8eFB8/PHHYvv2\n7dKxsbGx4t69e+Lu3bvi9OnT0nG//fab2LFjh9iyZYto166dWLVqlXSsPgt7xMXFievXr4shQ4aI\nGzduiOvXr4tr166Jzz77TDrfkCFDREBAgFi/fr32n4yYmBixYsUKRQsE5S62lLt/ld3n3b9/X7i5\nuYk+ffoIV1dXcfv2bemcrq6uYv369WLw4MFix44d0vuu+/fvC1dXV9GnTx8xfvx4cefOHZ0x6enp\n4tmzZ2Lq1KkiKipKCCHExYsXxbRp06Ry+vv7i379+om5c+eKa9euScUUFf2mMHpFaTQafPjhh0hK\nSsKnn36q12drW7ZsCWtrayQkJCA+Pj7fiMXCZGVlwd/fH61bt8axY8ekB0RMmDABJ06cwIYNG7Bt\n2zacOXMGAKTO5JVO5m9rawtbW1ukpqaibdu2eo2obtCgATw8PLBmzRo8ePAAffv2xejRo3H27NlC\n4/bs2YOBAwciMjISu3btyjdHc2EM+cypEAKzZs1CvXr1sGbNGunPg8+cORPVq1dHq1atUK5cOXz/\n/ffSOcuVK4c5c+Zg/fr12Lhxo9Q0vcDzqW9z54MfNWoUoqKipOIaNfr/2jv3qJzy/Y+/c42JZlwa\nDE4j5FZYtBiX9VtkFo5G1OqCXBKN26DMHBFNLhWHQ9OgGDFYlXRkUMeEXGZoTHLc4oxbuTQuMWko\niXh+f7T2nqLL3p/v8zxfz+77Wsta08Nu7/1MPZ/3/l4+r46Ij49HRkYGdu3aha5duyq+Vqq8QtKR\nuri4YNWqVXIPhOr83tR7BEpX51tbW2P79u2Ii4tTPBW0cOFCTJo0CePGjYOrq6sq2cv27dvRr18/\n7Nu3D8ePH8fRo0cVHad7Q+wxbNgwWexREefPn0dQUBCys7MRFBSEoKAgLF26VPGKbKD0/6Gfnx88\nPT3lP0qYM2cOCgoK0KxZM/mPUl6/fo3MzEy0bt0aL168QGFhoaLjWrRogbVr1yI5ORkRERGK9bkA\nEBoaipycHHzwwQfIzMxESEiIouMWLVoEZ2dnxMXFYfTo0QgMDKz2mHr16qF+/fq4c+eOPG3QpUsX\nxTuKvvzyS/zwww/o06cPwsPD4enpicTERObFckrQxNA6tagCdPMV1a4jFZsFCxYgJCRE1VYnajP/\nRo0a4fDhw3KnITUNT6g2KWroYJGCUC1vRUVFsLKykocXDx06pLg9KLWph45ovvrhhx+wadOmckOq\nSsUMVHmFFOby8vIQEhICJycnODg4YM6cOejRo0elx1HvEaAHut9++w3JyckICgqCn58f5syZo+qc\ngPqgo1bsIa3ITk1NLWcSLCgoUHytVBOZFAAoODs7Y8mSJQgNDcWqVasUN9qJiorC5s2by+0eUNrh\nr0GDBnBycpI7tN2+fVvRLo3i4mL5vR0yZAi2bt2q6HxA6edleHg47O3tcfbsWTRv3lzRcW8GOqWm\nNn2giULOoqyjmq+odh0Wpaifn5/8S2hnZ6d4Pn758uW4ffs2/P39sXXrVixatEjxOak2KWroKLvn\n9Nq1a6oWnVEtb5MnT0b79u1lWYaZmZniQk4NglTz1XfffYfIyMhqn4YrIiwsTJZX2NnZKX4ao4Y5\nFrsXNdB98MEHMDMzw7Nnz1SFQIAedJydnStstFLdaMDWrVthZ2cHKysrnD9/HoGBgUhKSlJ0TqqJ\njBoAgL/6mANQ9IQrIfkZGjRooPgYCV9fX7x48QKWlpZyMKysQ2FZXr16hStXrsDW1hZXrlxRNbK3\nevVq7Ny5E8eOHUP79u0Va2mppjZ9oIle6yzGI7XmK1a7TkpKCm7evIkmTZrg22+/Ra9evSpt7fcm\n1Gb+LLC8txJqDEK//fYbioqKUKtWLdVSEAm1lrfJkyeTdxuUDYJeXl74+eefFQVBqvlq2rRpiIqK\nIl0rVV4xb948uLu7vxXmDh06hE8//bTS41jsXlTL25o1a2BpaYlHjx7h/v37yMnJQUJCguLzUixd\nEyZMwNatW1V7zH/55ResXLkSDg4OyMzMxPLly1UJVCgmsvHjx5f7Ws3WKupo0IwZM7B+/XrSdkUv\nLy/S9srLly9j8eLFePjwIaysrLBs2bJyzWGqoqSkBBcvXiy3aNbJyana46idDvWBST+Rly2qZfs6\nq/llUGu+YrXrDB06FEBpsRk+fLiqlbVSC1ddmWb+hoLVJkUNHcHBwbIUxM/PD6tWrVJcyKmWN6pv\nGwDOnDkjB8HRo0cr7sxFNV+Zm5tjypQp5Z6olGpw165dK8sr4uLiMHfuXEWF3NLSslwRl8JcVUUc\nYLN7US1v/v7+KCgogLm5OY4fP66qxzU16Dx+/BgDBw5ULfbo0KEDmjZtirS0NAwYMEBxy1OAbiLb\nsWMHWUVKHQ16+fIlPvvsM3Ts2BGAcg0uUNrg5+effy73M6SkxbS09fD27duwtrZW1TRp1qxZePny\nJXJzc/Hq1StYWVkpKuRqTW36xKQLuT6UdRMnToSLiwvy8vLg5uameGuMl5cX/vOf/6i267AoRanN\n/CmwvrfU0MEiBQkPDyftB8/IyMCLFy9w+vRpAH8tnlQCVYEqLZJTa756c4pCzVOO2nln1jBHvUeA\nHuh27dqF7OxszJ8/HzExMXj69Kli6xU16FDFHuPGjcNXX32FIUOGIDo6Gh4eHoqthN9//z0SExPL\nmciUFHJqAABKpx6krm5qUKp1rYg//vgDoaGhsq1PaUiKiYnB9u3b0aFDB1y7dg0zZsxQfJ+PHz9G\nfHw8AgMD5WY2So+jBDp9YNKFXIJaVAG6+Ypq16EWG4DezJ8Cq02KGjpYpCDU/eBU3zZAD4LURXIX\nL158a6pD6c+62nln1jDHYveiBrq4uDh5KH3jxo3w8vJS/P6oDTqsYo9t27ahRYsWAEqVpm9OXVQF\n1URGDQAAfTSoVatWSElJQVFRkfxaZYKaN8nKysKBAwcU/duyJCQkYN++fahfvz6Kiorg5eWl6j6B\n0kWw5ubmij/bqYFOH2iikFOKKqv5Ske067A0H9F3M/+qYLVJUUMHixSEanljWQBEDYJqzVcVTSOp\neToG1MsrWMMci92LGuhq1aolN+SoW7euqhELtUGHVezx9OlT+Pv7l2s/qhSqiYwaAIC3R4OUMm/e\nPAwcOFDVVjcJW1tbnDt3Dl26dJFfU7JWomnTpvIQt7m5uaqhdUdHR6xbtw6dOnWCu7s7GjZsWOW/\nZw10+kAThZxSVFnNV1S7DqXYGKqZf1Ww2qSooYNFCkK1vFF826xBUK35Sh/TSGrlFaxhjsXuRQ10\njo6OGDt2LOzt7XHp0iUMHjxY8fWqDTqsYo/ly5eraj9aFqqJjBoAgNIOZXv27MHdu3fRt29fxcHD\n3NycvAjs9OnTOHbsmPy1EvkJUFoTRo0ahZ49e+Ly5csoKSmR36Pq5udTUlIQExMDoDS8WFtbV/nv\nWQOdPtBEIacUVVbzFcWuA9CKDc9m/mptUqyhg0UKQrW8UXorswZBqvmqQ4cOiIiIwOzZs+Hj4wNv\nb2/FHxhq5RWsYY7F7kUNdDNmzMCgQYOQnZ2NUaNGqVopT7F0AXSxB6Cu/SjAbiKjBgCg9LPLysoK\naWlpsLOzw/z586vsZS81UmnWrBmSkpLQpUsX1SNe+/fvV3x9ZSkbdtW2SDUzM8PMmTPLre2oagqB\nNdDpA00UcmpRBejmK4pdB6AVG0M181eCWpsUa+hgkYKotbzNnj0bERERFX4AVtewQp8KVDXmq3Xr\n1snvY3h4OKZOnaq4kFPlFfpQg6q1e1ED3b1793DixAkUFxcjKysLhw8fVvw0SLV0qRV7SFhaWmLn\nzp0oKipCcnKyon7nVBMZawAASpuxhISEICMjA4MHD8amTZuq/PdlPwPKhjo1DyA7d+5EfHx8uS1v\nSvqeK52DrwhXV1fScSyBjhVNFHJqUQXUm69Y7DoATSnK2syfBbU2KX2EDqoURK3lLSIiAgBUbXF7\nE2oQpJqv6tSpIzeuadSokapV/VR5BVUNymL3oga6OXPm4JNPPiE1zGGxdKl9sgZK2+3+/vvvaNKk\nCTIzMxVtBaOayFhVpEDpDo28vDyYmZmhoKCg2p896TNAWmshoeYza/v27di0aZNBrG6VIY1EqYUa\n6PSBSRdy1qIKqF98xmLXAWhK0R9//BE6nQ5LliyBp6cn7O3tcfnyZcTGxpKuQQ1qbVKsoWPRokVY\nuHAhbty4gdmzZyuynklQLW/r1q0jF3KqApVqvrK3t8e8efPQo0cPXLhwodwioOpYtmwZVq5ciceP\nH2PLli0IDg5WdBxVDcpi9wJogY6lBSk16Lz5ZC1tlaqMhIQE/Pvf/8aNGzfk/dEZGRmKW8IC6k1k\nrCpSAJg7dy7GjBmDhw8fwsPDQw7tlXH06FGcPXsWSUlJslPi9evXSE1NVdw50dbWFi1btuSyN5sC\nJdDpA5Mu5KxFFVC/+ExaeVm7dm2Ehobixo0bsLa2xoIFCxSdj1JspA8UajN/Fnbv3o3c3Fw8efIE\nf/75J3Jzc+VtRRXBGjokKQiF2NhY7NixA5GRkRg2bJji4Tu1c2JlURsEK1rh+vz5c8yfP1/RCtfF\nixfj8OHDyMrKwrBhw8r16q4OSV6hFrVhjvUeAXqgY9mBQA06oaGhiIqKUiz2cHZ2xieffIKNGzfK\nc7m1atVC06ZNFZ0PKB0qDwwMlDtSTpw4UdFxVBUpUDpcnZKSgry8PEWjB506dUJ+fj7q168v/z8w\nMzN7a/1MVfTt2xdDhgxBmzZt5BatSn6vr169iuDgYKMOc6sNdPrEpAs5a1EFShuXJCQkqDZfLVq0\nCGPGjIGDgwPS09MRGBioqEUrtdgA9Gb+LCxcuBDnzp1DUVERioqK0LZt2yrnDVlDB4sU5E3Lm5Ke\nzAB9TgxQHwTLrnANCgqCTqdTtcI1Pz8fz58/h5WVFZ48eYKNGzfi888/V3QsVV6hNsyx3iNAD3TU\nHuQAPeioFXvUq1cPrVu3VryroiKoJjJqAADUz1e3bNkSo0ePhrOzM27cuIHr16/D2tpacatUoHRu\nPTw8XJ5OUgqPYW61gU6fmHQhl6AWVYBuvqLadajFBqA382eBapOihg4WKQjV8kbdVgOoD4Ks5qtZ\ns2ahXbt2uHr1KurXr69KREGVV6gNc/qwe1EDHUsLUmrQoYo9WKCayKgBAKDPV8fExGD//v3o3r07\noqOjMXz4cPj4+Cg69sMPP4SdnZ2qtSASxh7mppra9IEmCjmLso5qvqLadViUovXq1UPPnj1hZ2cH\nnU6HgwcPKuoBzALVJkUNHdQ2kADd8qZ2W01ZqEGQar5i0eC2bt1a9WpzgB7mWOxe1EDH0oKUGnSK\ni4tJYg8WqCYyagAA6PPVSUlJiI2NRZ06dfDy5Ut4enoqLuQvXryAs7MzOnToIH/GKunTzmOYm0eg\nk9BEIWdR1jVq1Kha3WBFSHN4Ze06SmBRilKb+bPQtWtXREdHw8rKCn5+foq94tTQwSIFsbCwkBd/\nBQQEKDoGUL+tpizUIDhz5kz4+vrK5qtvvvlG0flYNLhUeQU1zFHvEaAHOpYWpNSgQxV7sEAdsaAG\nAIA+X63T6cp121PTdlnptNGb8Bjm5hHoJDRRyKlFFaCbr6h2HWqxAejN/Fmg2qSooYNFCkJF7baa\nslCDINV8RXWuA3R5BTXMsdi9qIGOpQUpNehQxR4sUEcsWNagUOere/XqhdmzZ6NXr144c+ZMlesr\n3mTFihUYOXIkRo0apWqYOiIiAu7u7qqbGLHAI9BJaKKQsyjrqOYrFrsOFWozfxaoNilq6GCRglDx\n8/ODh4cH7t27B09Pz2q31ZSFGgSp5quhQ4fi9evXyMvLU63BpcorqGGOxe5FDXRlW5CeOXNGVXig\nBh2q2IMF6ogFyxoU6nz1/PnzcezYMWRlZcHV1VVV97Pvv/8e+/fvx7Rp09CyZUu4ubmhX79+1R7X\nq1cv5iZGauER6CQ0UchZiirVfMVi16Gitpm/PqDapNSGDn1IQag8fvwYr169wt/+9jc8f/5cVTc5\nahCkmq8OHjyIFStWoHHjxigsLERwcDD69++v6FiqvIIa5ljsXtRA5+HhgdOnTyMtLQ3JycnYvHmz\n4nNSgw5V7MECdcSCZQ0Kdb66oKAAv/76K65fv4779++je/fuih+2GjdujHHjxqFv377YsGED5s2b\nh9atW8PX1xeffvpppcdRmxixwCPQSWiikLMUVeq+Uxa7DhW1zfz1AdUmpTZ06EMKQmXDhg1ISEhA\n06ZN8ejRI0ybNk3xVilqEKSaryq6VqWFnCqvoIY5yj2yBrqwsDCsXbsWbdu2hbe3NwICAuTfmeqg\nBh2q2IMFak9vljUo1PnqhQsXwsHBASNHjkR6ejoCAgIQFRWl6NiYmBjs3bsXFhYWcHNzw4oVK1BS\nUgJ3d/cqCzm1iRELPAKdhCYKOUtRpZivADa7DhWWxiVUqDYpauhgkYJQef/99+VmHM2aNVM1XE0N\nglTzFeVaWeUV1DBHuUfWQFe3bl15OL1NmzaqhoGpQYcq9mCBumWSEgCkFqsV9YJQMmLx+PFjjB8/\nHgDQuXNnpKSkKD73pUuXsGzZMtStWxebN2/Gxx9/jE6dOmHp0qVVHqe2iZE+4BHoJDRRyFmKKrUn\nOItdhwpL4xIqVJsUNXSwSEGovPfee/Dx8YGDgwMuXbqE58+fy90Cq7tmahAEaPtcy15rZmamomtl\nlVewqEGpe3mpga5Vq1ZYs2aN3MLWysqq2mNYgw5V7MECdcskJQBIW2TLqonVUFxcjIcPH6J58+Z4\n9OiRqqmr27dvIz8/HzExMRg6dChCQkKwY8eOahfMqW1ipA94BDoJTRRySlFlMV8BbHYdKtRm/ixQ\nbVLU0MEiBaEyZMgQ+b8//PBDVcdSgyDFfAXQrpVVXkENc9R7BOiBLiwsDHFxcTh+/DhsbGzkNs5V\nwRp0eIg9qFsmKQGgT58+uHv3LlxcXEjXOmfOHHh6esLCwgKFhYWqdhWZmZmhd+/eiIyMxIgRIxTZ\n6AD1TYz0AY9AJ6GJQk4pqvowX9UEqDYpauhgkYJQoVwraxCkmK+A0kKenp5e7sOiun3rrPIKapij\n3iNAD3T169fHpEmTFJ8HYA86PMQe1C2TlAAgSWjy8/NRWFiIjh074tq1a2jevLmiXQj9+/dHamqq\n4h7tZSkpKcGqVavQu3dvnDp1SnZUVAe1iRELPAKdhCYKOQss5quaAItNigKLFMSYUIMgq/mK0oCG\nVV6hNszpw+5lzEDHGnSojVJYUGsik6AEAGmUYubMmVi5ciUsLCzw7NkzxetzWJ5Uw8LCcPLkSbi5\nueHw4cNYuXKlouOoTYxY4GlqM9PpdDqjn/UdwsvLC5aWlqrncnnYdXgQGhqK7t27k2xSFPLz83Hi\nxAmUlJRAp9MhNzeXvFrWGIwbN07xqmigdAtPbm5uheYrJStcJ0+ejC1btpCu9fXr1yR5hbe3t6q2\nx6z3KCEFOhsbG4MGunv37uHUqVPYtGmTrPs0MzODra2tovfIxcUFX3/9dblGKe3atTPY9ZZF7VNu\neno6Fi9ejIcPH6Jly5ZYuHCh4l0Prq6u2L17d6VfV8bf//73t55U1TaVUcuaNWtgaWmJR48e4f79\n+8jJyZF3XhiK+Ph4REVFGTXQSWiikLMU1T179rz1mpKh1okTJ2Lp0qVYtGgRvvnmG0yZMkVxswtT\nQlptKmHoH04vL6+3pCBKt6rwgBoEqWzZsgUNGjRQ3YAGKB1CluQVZ8+eVSyvMHaYA/gEOmrQmT59\nOtavX2+U9RwSrPOxlGHutWvX4syZM+jWrRsuXLiAgQMHYvr06dUe5+fnh9WrVxv9SfXNJkZqtxWq\nhWeg08TQOouyjsV8xUsib0xYbFIUWKQgPDD2TgJqAxqALq9gUYNSYbG8UaFauqiNUligzseyBAA/\nPz9kZmbi5s2b5RY9nj9/vspufzymHqhNjFhgMbWxoolCDtCLKnUbB0+JvDFhsUlRYJGC8IAlCFKg\nNqAB6PIKY4c5gE+gowYdHlM/1PlY1gVZ3bp1Q7du3cq99q9//avKwkzt0c4CtYkRCzwCnYQmCjlL\nUaVu4+ApkTcmLDYpCixSEB6wKFApUBvQAHR5hbHDHMAn0FGDDlXswQL1KdcQC7Kqm53l8aRKbWLE\nAs+1PJoo5CxFlbqNg4ddhwcsNikKLFIQHrAoUCmwNKChyiuMHeYAPoGOGnSoYg8WqE+5hhjmrq5I\n8nhSZWliRIVHoJPQRCFnKapU8xUPuw4PWGxSFFikIDxgUaBSYBnmpsorjB3mAD6Bjhp0qGIPFqhP\nuTyGuUeOHImCggLUrl0b33333VsLaA0BtYkRCzwCnYQmCjlLUaWar3jYdXjAYpOiwCIF4QGL4Q+h\nSwAADc9JREFUApUCyzA3VV5h7DAH8Al01KBDFXuwQH3KNcQwd3VD6wkJCZg1axZiY2Ph7++PnTt3\nqm7aoxZqEyMWeAQ6CU0UcpaiSjVf8bDr8IDFJkWBRWDCAxYFKgWWYW6qvMLYYQ7gE+ioQYcq9mCB\nOh9riGHu6tpiSzsroqKiVLVZZYHakZIFHoFOQhOFnKWoUgsHD7sOD1hsUhQoUhCesChQKbAMc1Pl\nFcYOcwCfQEcNOlSxBwVWExklAFT183zixAm4u7tXeTy1zSoLxu5ICfAJdBKaKOQsRZVqvuJh1+EB\nxSbFAovAhAfGLjgsw9xUeYWxwxzAJ9BRgw5V7EGBaiJjCQBK3AFVQW2zygLL7g4qxgx0b6KJQs5S\nVKmFg4ddhwcUmxQLFCkIT1gUqBRYhrmp8gpjhzmAT6CjBh1jPnFSTWSsKlIAOHfuHBITE+X7y83N\nRXR0dLXHWVtbw9raGoDxfpd5NDEyZqB769xaaNHKo6i6uLhg9+7d5ew6VKWl4C/c3NzekoIsWLCA\n81VVTkUtfiUMoZ11dXWVh7nv3Lmjapib2tWruLgYcXFxyM7Oho2NDTw9PVX1TKfw9OlTboFObdC5\nefNmuSdOOzs7tGnTxiDX5uHhAUC9iezu3buV/l2rVq0UnXvUqFGYMmUKUlJS0LFjR9y8edNoDU8o\nGLuJ0ZgxY9C9e3dYWFigd+/eiIiIQGxsrMHPC2jkiZyHso6HXacm0KhRI4SFhfG+DMUY2xHPMsxN\n7epFUYOyQrG8sUINOsZ84qSayFhVpEDpZ56TkxNOnjyJL774Al5eXmw3Y0B4NDHiMYUgoYlCzqOo\ndu3aFdHR0bCysoKfnx+eP39ulPNqnQEDBiAuLo4kBakJsAxz89QsqoVHoOPpk1bL/fv35fUYDRs2\nrHbInFVFCpR2S7t27RqKioqQlZWFP//8k34DBoZHEyMeUwgSmijkPIqqv7//W3YdATssUpCaAMua\nBR7yCio8Ap0pBZ0BAwbAy8tLNpGVXVNQFWoDQFkCAgJw7do1jB8/Hl9++aXRhUFq4NHEiCeaKOQ8\niioPu05NgEUKUhNgGebm0dWLCo9AZ0pBh2oiowYAoHSxm5ubGwAgMTHxnX1vgPK7OzIyMozSxIgn\nmljsVraoTp48We53a0hGjx6NhIQE2ZTk5eUlD18J6ISEhKBHjx5G3TZSU+DhzaYyadIkowc6nj5p\nfTFhwoRqC6wUANq3b68oACQlJeHIkSP49ddf0bdvXwCl7varV68iOTlZvzegJ0pKShAfH48bN27A\nxsYG7u7uiiU4pogmnsh5KOt42HVqAixSEEHV8NQsqoXHPmCePml9oeS5TK2KdODAgWjevDny8/Ph\n6ekJnU6HWrVqGWxlvj64dOkSXr16haCgIMybNw89e/ZEly5deF+WwdBEIedRVHnYdWoCPNzXNQUe\n8goqPAKdKQWdyqB+9lUVACwtLdGnTx+0aNECFy9ehJOTE1avXg1PT0/qZRqcpUuXYu3atQCAuXPn\nGqUbIU80Uch5FFUedp2aAI9tIzUFHvIKKjwCnSkFHX2jJADMnz8fAQEBAID/+7//Q2BgILZt22bo\nSyPBoxshTzRxdzNmzMDixYthb2+PwMBA+Pr6Gvyckl1HMuusW7fO4OesCUjbRjZs2IA9e/aIYXU9\nIi0Ye/LkCUaMGPFOf7gdOHAAnp6eiIqKgoeHB/bu3WvwcyYkJMDGxgZpaWnw9/dHamqqwc+pbwy9\n5KlHjx4ASncQGFoQxIK0TfPIkSMIDw83SjdCnry7v8kq4FFU58yZg4KCAjRr1kz+I2Cnpm0bMSY8\n5BVUeAQ6Uwo6lVGdiawylASAxo0bIz4+HleuXEFCQoL8e/ouEhYWhiZNmuD48eNo0qSJSTWZoqCJ\noXUeyjoedp2aAA/3dU2BZ+cptfAIdKYQdFhNZJWhJACsWLECkZGROHToENq3b4/Q0FDSuYwBj26E\nPNHE9jNvb29s3brVqOcMDQ1F9+7dxTYpPZORkYHTp0/j4cOHshTEzs6O92UJjMxXX32Fpk2byoHu\n8ePHWLFihUHPacye6camugCglNzcXJSUlECn02nW+GiKaKKQ8yiqby6EEduk9AOLFESgHUSgqxqq\niYyFsnKq58+fo02bNpo0Ppoimhha56GsE9ukDENNW20qqJiwsDA50Hl7e4tA9wbBwcHlTGQvXrxQ\ndBxLAOAhpxIoQxOFnEdRFdukDAMP97Xg3UMEuqqhmsioAUA6pzA+vpto4reDx1YVsU3KMNS01aaC\niqlp24fUQjWRSQHAwsICX3zxBR48eKD4nML4+O6iiSdyHso6sU3KMNS01aaCimGxvNUEqCYyFhXp\nqFGjYGVlBXNzc/z000+wt7enXr5Az2iikPMoqjXNriMQGBMR6KqGaiJjUZEGBgYiLi4OAERL6ncM\nTaxaL7tVJSMjA/n5+QbfqlLT7DoCgYA/rCayhIQEOQAAwPbt2zFhwoQqj3n69CkaNWoEHx8f2NjY\n4OOPP5bXLHh4eDDcjUBfaOKJPCwsDPHx8UhLS4ONjQ3mzZtn8HPWNLuOQCDgD9VEVjYAnDp1CsBf\nAaC6Qu7r64u4uDh89NFHaNy4Mf744w+93Y9AP2iikPMoqjXNriMQCPhDNZGxqEjr1KkDV1dX3Lp1\nCzY2NvLrZmZmmDVrFvM9CfSATgO4uLjobt26pdPpdLrbt2/rxo4da/Bzenh4lPvay8vL4OcUCAQC\nna708+fs2bM6nU6nS09P102YMEHRcTdv3tTt379fp9PpdKtWrdLduXOn2mNKSkp0v//+u27q1Km6\nnJyccn8E7waaeCLnsedU7HcWCAQ8oZjIKCrS2rVro1WrVti0aRPbBQsMhiYKOY+iKrbHCAQCXkgm\nMukzT42JzFRUpALlaGLVenFxMeLi4pCdnQ0bGxt4enqiXr16vC9LIBAIDEJeXh4iIyORnZ2N9u3b\nw9fXV1G3NV9fXzg6OsoBIDU1FVFRUUa4YoEh0UQhFwgEgpoGxURGDQCCdxtRyAUCgcDEYDGRCRWp\n9tDEHLlAIBDUJKgmMqEi1SaakKYIBAJBTYJqIpMCwIABA5CcnCwcERpBFHKBQCAwMagmMqEi1SZi\njlwgEAhMjKysrLdMZM2aNav2uDVr1sDS0hKPHj3C/fv3kZOTg4SEBCNcscCQiEIuEAgEJsaYMWNk\nE5kaqAFA8G4jCrlAIBCYCKwmMmoAELzbiFXrAoFAYCJQTWRSAGjYsCFCQ0OFilRjiEIuEAgEJgLV\nRCZUpNpGDK0LBAKBifDq1Ss8ePAAwcHB+Prrr8v93UcffVTpcePHj8ezZ88qDAA7d+402PUKjIMo\n5AKBQKBxqAFAYBqIQi4QCAQCgQkjGsIIBAKBQGDCiEIuEAgEAoEJIwq5QKAxxo4di6SkpHKvPXv2\nDH369EFeXp6i7+Hs7Fzl3ycmJiIgIOCt13NycjB48GDlFysQCJgRhVwg0BguLi5vFfKDBw+iT58+\nivtr79271xCXJhAIDIAo5AKBxhg+fDj++9//Ij8/X35t3759cHV1xYEDB+Du7o6RI0di6NChOH36\nNIDS7UmzZs3C0KFD8b///Q+2trYAgAcPHsDHxwfu7u4YNGgQVq9eLX/PW7duYdy4cRgxYgRWr16N\nN9fNPnr0CDNmzICLiwtcXV2RlpYGAPjll1/g4uICFxcXeHt7Kx4lEAgEFSMKuUCgMd577z04Ojri\nxx9/BFBajLOzszFw4EDs3LkTUVFR2LdvH6ZOnYro6Gj5OFtbW6SkpKBz587ya0lJSXBycsKuXbuw\nb98+xMbGyoU3JycH3377Lfbs2YMzZ84gNTW13HWEhITA1dUViYmJiIyMRFBQEAoKCrBhwwYEBwcj\nMTERgwYNwuXLl43wrggE2kV0dhMINIirqyvCw8Ph6emJ/fv3Y+TIkahVqxbWr1+PI0eOIDs7G+np\n6XKbTgCwt7d/6/v4+Pjg1KlTiI6OxrVr1/Dy5UsUFRUBAAYPHiwP1Q8fPhzp6eno1KmTfGxaWhqy\nsrIQEREBACgpKcGdO3fg6OiIWbNmYciQIXB0dET//v0N+VYIBJpHFHKBQIP07t0bDx8+xL1797Bv\n3z6sW7cOhYWFcHV1hbOzMxwcHGBra4uYmBj5GHNz87e+z4oVK3Dnzh04OTlhyJAhSEtLk4fQ69T5\n6+NDp9OV+xoAXr9+jW3btuH9998HUDoy0KxZM3Tu3BmDBg3C0aNHsWrVKly4cAHTp083xNsgENQI\nxNC6QKBRRo8ejcjISFhaWqJt27a4efMmatWqhWnTpqFv37746aef8OrVqyq/x8mTJ+Hj44Phw4fj\n3r17ePDgAV6/fg0AOH78OJ48eYLi4mIkJyejX79+5Y7t27cvYmNjAQDXr1/HyJEjUVRUBDc3NxQW\nFmLSpEmYNGmSGFoXCBgRT+QCgUYZNWoUHB0dERISAgDo1KkTOnfujOHDh8Pc3BwODg64e/duld/j\n888/xz/+8Q80btwYTZs2Rbdu3ZCTkwMAaNeuHXx9ffHkyRM4OTlhwIAB8t8BwKJFixAUFITPPvsM\nAPDPf/4TFhYW8Pf3R0BAAOrUqYP69etjyZIlBnoHBIKagWjRKhAIBAKBCSOG1gUCgUAgMGFEIRcI\nBAKBwIQRhVwgEAgEAhNGFHKBQCAQCEwYUcgFAoFAIDBhRCEXCAQCgcCEEYVcIBAIBAITRhRygUAg\nEAhMmP8HI3jggehBjcIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e8ede4feb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gbm_varimp.plot.bar(x=0,y=[1])\n",
    "plt.xlabel('Variables')\n",
    "plt.ylabel('Relative_Importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'StackedEnsemble_BestOfFamily_0_AutoML_20181101_171828'"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_set=aml_leaderboard_df['model_id']\n",
    "mod_best=h2o.get_model(model_set[8])\n",
    "se = mod_best._id\n",
    "se"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.1697925826679713: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>B</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>B</td>\n",
       "<td>267.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0074</td>\n",
       "<td> (2.0/269.0)</td></tr>\n",
       "<tr><td>M</td>\n",
       "<td>0.0</td>\n",
       "<td>148.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/148.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>267.0</td>\n",
       "<td>150.0</td>\n",
       "<td>0.0048</td>\n",
       "<td> (2.0/417.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       B    M    Error    Rate\n",
       "-----  ---  ---  -------  -----------\n",
       "B      267  2    0.0074   (2.0/269.0)\n",
       "M      0    148  0        (0.0/148.0)\n",
       "Total  267  150  0.0048   (2.0/417.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_best.confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.1697925826679713: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>B</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>B</td>\n",
       "<td>267.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0074</td>\n",
       "<td> (2.0/269.0)</td></tr>\n",
       "<tr><td>M</td>\n",
       "<td>0.0</td>\n",
       "<td>148.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/148.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>267.0</td>\n",
       "<td>150.0</td>\n",
       "<td>0.0048</td>\n",
       "<td> (2.0/417.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       B    M    Error    Rate\n",
       "-----  ---  ---  -------  -----------\n",
       "B      267  2    0.0074   (2.0/269.0)\n",
       "M      0    148  0        (0.0/148.0)\n",
       "Total  267  150  0.0048   (2.0/417.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.1697925826679713: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>B</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>B</td>\n",
       "<td>267.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0074</td>\n",
       "<td> (2.0/269.0)</td></tr>\n",
       "<tr><td>M</td>\n",
       "<td>0.0</td>\n",
       "<td>148.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/148.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>267.0</td>\n",
       "<td>150.0</td>\n",
       "<td>0.0048</td>\n",
       "<td> (2.0/417.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       B    M    Error    Rate\n",
       "-----  ---  ---  -------  -----------\n",
       "B      267  2    0.0074   (2.0/269.0)\n",
       "M      0    148  0        (0.0/148.0)\n",
       "Total  267  150  0.0048   (2.0/417.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Act/Pred) for max f0point5 @ threshold = 0.3427932686432317: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>B</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>B</td>\n",
       "<td>269.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/269.0)</td></tr>\n",
       "<tr><td>M</td>\n",
       "<td>2.0</td>\n",
       "<td>146.0</td>\n",
       "<td>0.0135</td>\n",
       "<td> (2.0/148.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>271.0</td>\n",
       "<td>146.0</td>\n",
       "<td>0.0048</td>\n",
       "<td> (2.0/417.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       B    M    Error    Rate\n",
       "-----  ---  ---  -------  -----------\n",
       "B      269  0    0        (0.0/269.0)\n",
       "M      2    146  0.0135   (2.0/148.0)\n",
       "Total  271  146  0.0048   (2.0/417.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Act/Pred) for max f0point5 @ threshold = 0.3427932686432317: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>B</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>B</td>\n",
       "<td>269.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/269.0)</td></tr>\n",
       "<tr><td>M</td>\n",
       "<td>2.0</td>\n",
       "<td>146.0</td>\n",
       "<td>0.0135</td>\n",
       "<td> (2.0/148.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>271.0</td>\n",
       "<td>146.0</td>\n",
       "<td>0.0048</td>\n",
       "<td> (2.0/417.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       B    M    Error    Rate\n",
       "-----  ---  ---  -------  -----------\n",
       "B      269  0    0        (0.0/269.0)\n",
       "M      2    146  0.0135   (2.0/148.0)\n",
       "Total  271  146  0.0048   (2.0/417.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Act/Pred) for max precision @ threshold = 0.9959664395085774: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>B</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>B</td>\n",
       "<td>269.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/269.0)</td></tr>\n",
       "<tr><td>M</td>\n",
       "<td>147.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9932</td>\n",
       "<td> (147.0/148.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>416.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.3525</td>\n",
       "<td> (147.0/417.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       B    M    Error    Rate\n",
       "-----  ---  ---  -------  -------------\n",
       "B      269  0    0        (0.0/269.0)\n",
       "M      147  1    0.9932   (147.0/148.0)\n",
       "Total  416  1    0.3525   (147.0/417.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.1697925826679713: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>B</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>B</td>\n",
       "<td>267.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0074</td>\n",
       "<td> (2.0/269.0)</td></tr>\n",
       "<tr><td>M</td>\n",
       "<td>0.0</td>\n",
       "<td>148.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/148.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>267.0</td>\n",
       "<td>150.0</td>\n",
       "<td>0.0048</td>\n",
       "<td> (2.0/417.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       B    M    Error    Rate\n",
       "-----  ---  ---  -------  -----------\n",
       "B      267  2    0.0074   (2.0/269.0)\n",
       "M      0    148  0        (0.0/148.0)\n",
       "Total  267  150  0.0048   (2.0/417.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Act/Pred) for max precision @ threshold = 0.9959664395085774: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>B</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>B</td>\n",
       "<td>269.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/269.0)</td></tr>\n",
       "<tr><td>M</td>\n",
       "<td>147.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9932</td>\n",
       "<td> (147.0/148.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>416.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.3525</td>\n",
       "<td> (147.0/417.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       B    M    Error    Rate\n",
       "-----  ---  ---  -------  -------------\n",
       "B      269  0    0        (0.0/269.0)\n",
       "M      147  1    0.9932   (147.0/148.0)\n",
       "Total  416  1    0.3525   (147.0/417.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.1697925826679713: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>B</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>B</td>\n",
       "<td>267.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0074</td>\n",
       "<td> (2.0/269.0)</td></tr>\n",
       "<tr><td>M</td>\n",
       "<td>0.0</td>\n",
       "<td>148.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/148.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>267.0</td>\n",
       "<td>150.0</td>\n",
       "<td>0.0048</td>\n",
       "<td> (2.0/417.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       B    M    Error    Rate\n",
       "-----  ---  ---  -------  -----------\n",
       "B      267  2    0.0074   (2.0/269.0)\n",
       "M      0    148  0        (0.0/148.0)\n",
       "Total  267  150  0.0048   (2.0/417.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Act/Pred) for max min_per_class_accuracy @ threshold = 0.26666735197557184: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>B</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>B</td>\n",
       "<td>268.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0037</td>\n",
       "<td> (1.0/269.0)</td></tr>\n",
       "<tr><td>M</td>\n",
       "<td>1.0</td>\n",
       "<td>147.0</td>\n",
       "<td>0.0068</td>\n",
       "<td> (1.0/148.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>269.0</td>\n",
       "<td>148.0</td>\n",
       "<td>0.0048</td>\n",
       "<td> (2.0/417.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       B    M    Error    Rate\n",
       "-----  ---  ---  -------  -----------\n",
       "B      268  1    0.0037   (1.0/269.0)\n",
       "M      1    147  0.0068   (1.0/148.0)\n",
       "Total  269  148  0.0048   (2.0/417.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.1697925826679713: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>B</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>B</td>\n",
       "<td>267.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0074</td>\n",
       "<td> (2.0/269.0)</td></tr>\n",
       "<tr><td>M</td>\n",
       "<td>0.0</td>\n",
       "<td>148.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/148.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>267.0</td>\n",
       "<td>150.0</td>\n",
       "<td>0.0048</td>\n",
       "<td> (2.0/417.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       B    M    Error    Rate\n",
       "-----  ---  ---  -------  -----------\n",
       "B      267  2    0.0074   (2.0/269.0)\n",
       "M      0    148  0        (0.0/148.0)\n",
       "Total  267  150  0.0048   (2.0/417.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[, , , , , , , , , ]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_best.confusion_matrix(metrics=[\"f1\",\"f2\",\"f0point5\",\"accuracy\",\"precision\",\"recall\",\"specificity\",\"absolute_mcc\",\"min_per_class_accuracy\",\"mean_per_class_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function h2o.model.model_base.ModelBase._get_metrics>"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_best._get_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "h2o.estimators.stackedensemble.H2OStackedEnsembleEstimator"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mod_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OStackedEnsembleEstimator :  Stacked Ensemble\n",
      "Model Key:  StackedEnsemble_BestOfFamily_0_AutoML_20181101_171828\n",
      "No model summary for this model\n",
      "\n",
      "\n",
      "ModelMetricsBinomialGLM: stackedensemble\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.0045468790162855235\n",
      "RMSE: 0.06743054957721703\n",
      "LogLoss: 0.02243213656828987\n",
      "Null degrees of freedom: 416\n",
      "Residual degrees of freedom: 412\n",
      "Null deviance: 542.4643537202328\n",
      "Residual deviance: 18.708401897953742\n",
      "AIC: 28.708401897953742\n",
      "AUC: 0.9999246458354265\n",
      "Gini: 0.999849291670853\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.1697925826679713: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>B</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>B</td>\n",
       "<td>267.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0074</td>\n",
       "<td> (2.0/269.0)</td></tr>\n",
       "<tr><td>M</td>\n",
       "<td>0.0</td>\n",
       "<td>148.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/148.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>267.0</td>\n",
       "<td>150.0</td>\n",
       "<td>0.0048</td>\n",
       "<td> (2.0/417.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       B    M    Error    Rate\n",
       "-----  ---  ---  -------  -----------\n",
       "B      267  2    0.0074   (2.0/269.0)\n",
       "M      0    148  0        (0.0/148.0)\n",
       "Total  267  150  0.0048   (2.0/417.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.1697926</td>\n",
       "<td>0.9932886</td>\n",
       "<td>137.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1697926</td>\n",
       "<td>0.9973046</td>\n",
       "<td>137.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.3427933</td>\n",
       "<td>0.9972678</td>\n",
       "<td>133.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.3427933</td>\n",
       "<td>0.9952038</td>\n",
       "<td>133.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9959664</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.1697926</td>\n",
       "<td>1.0</td>\n",
       "<td>137.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9959664</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.1697926</td>\n",
       "<td>0.9896115</td>\n",
       "<td>137.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.2666674</td>\n",
       "<td>0.9932432</td>\n",
       "<td>135.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.1697926</td>\n",
       "<td>0.9962825</td>\n",
       "<td>137.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.169793     0.993289  137\n",
       "max f2                       0.169793     0.997305  137\n",
       "max f0point5                 0.342793     0.997268  133\n",
       "max accuracy                 0.342793     0.995204  133\n",
       "max precision                0.995966     1         0\n",
       "max recall                   0.169793     1         137\n",
       "max specificity              0.995966     1         0\n",
       "max absolute_mcc             0.169793     0.989611  137\n",
       "max min_per_class_accuracy   0.266667     0.993243  135\n",
       "max mean_per_class_accuracy  0.169793     0.996283  137"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 35.49 %, avg score: 35.59 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0119904</td>\n",
       "<td>0.9959662</td>\n",
       "<td>2.8175676</td>\n",
       "<td>2.8175676</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9959663</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9959663</td>\n",
       "<td>0.0337838</td>\n",
       "<td>0.0337838</td>\n",
       "<td>181.7567568</td>\n",
       "<td>181.7567568</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0215827</td>\n",
       "<td>0.9959659</td>\n",
       "<td>2.8175676</td>\n",
       "<td>2.8175676</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9959660</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9959662</td>\n",
       "<td>0.0270270</td>\n",
       "<td>0.0608108</td>\n",
       "<td>181.7567568</td>\n",
       "<td>181.7567568</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0311751</td>\n",
       "<td>0.9959655</td>\n",
       "<td>2.8175676</td>\n",
       "<td>2.8175676</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9959657</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9959661</td>\n",
       "<td>0.0270270</td>\n",
       "<td>0.0878378</td>\n",
       "<td>181.7567568</td>\n",
       "<td>181.7567568</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0407674</td>\n",
       "<td>0.9959651</td>\n",
       "<td>2.8175676</td>\n",
       "<td>2.8175676</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9959654</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9959659</td>\n",
       "<td>0.0270270</td>\n",
       "<td>0.1148649</td>\n",
       "<td>181.7567568</td>\n",
       "<td>181.7567568</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0503597</td>\n",
       "<td>0.9959648</td>\n",
       "<td>2.8175676</td>\n",
       "<td>2.8175676</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9959650</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9959657</td>\n",
       "<td>0.0270270</td>\n",
       "<td>0.1418919</td>\n",
       "<td>181.7567568</td>\n",
       "<td>181.7567568</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1007194</td>\n",
       "<td>0.9959625</td>\n",
       "<td>2.8175676</td>\n",
       "<td>2.8175676</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9959636</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9959647</td>\n",
       "<td>0.1418919</td>\n",
       "<td>0.2837838</td>\n",
       "<td>181.7567568</td>\n",
       "<td>181.7567568</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1510791</td>\n",
       "<td>0.9959535</td>\n",
       "<td>2.8175676</td>\n",
       "<td>2.8175676</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9959594</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9959629</td>\n",
       "<td>0.1418919</td>\n",
       "<td>0.4256757</td>\n",
       "<td>181.7567568</td>\n",
       "<td>181.7567568</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2014388</td>\n",
       "<td>0.9959028</td>\n",
       "<td>2.8175676</td>\n",
       "<td>2.8175676</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9959362</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9959562</td>\n",
       "<td>0.1418919</td>\n",
       "<td>0.5675676</td>\n",
       "<td>181.7567568</td>\n",
       "<td>181.7567568</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.2997602</td>\n",
       "<td>0.9916477</td>\n",
       "<td>2.8175676</td>\n",
       "<td>2.8175676</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9951180</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9956813</td>\n",
       "<td>0.2770270</td>\n",
       "<td>0.8445946</td>\n",
       "<td>181.7567568</td>\n",
       "<td>181.7567568</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4004796</td>\n",
       "<td>0.0262233</td>\n",
       "<td>1.5429537</td>\n",
       "<td>2.4970060</td>\n",
       "<td>0.5476190</td>\n",
       "<td>0.5080315</td>\n",
       "<td>0.8862275</td>\n",
       "<td>0.8730388</td>\n",
       "<td>0.1554054</td>\n",
       "<td>1.0</td>\n",
       "<td>54.2953668</td>\n",
       "<td>149.7005988</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5011990</td>\n",
       "<td>0.0109150</td>\n",
       "<td>0.0</td>\n",
       "<td>1.9952153</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0153918</td>\n",
       "<td>0.7081340</td>\n",
       "<td>0.7006887</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>99.5215311</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.5995204</td>\n",
       "<td>0.0096788</td>\n",
       "<td>0.0</td>\n",
       "<td>1.668</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0102497</td>\n",
       "<td>0.592</td>\n",
       "<td>0.5874567</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.8</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7002398</td>\n",
       "<td>0.0092254</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4280822</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0093741</td>\n",
       "<td>0.5068493</td>\n",
       "<td>0.5043078</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.8082192</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7985612</td>\n",
       "<td>0.0090868</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2522523</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0091455</td>\n",
       "<td>0.4444444</td>\n",
       "<td>0.4433419</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.2252252</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8992806</td>\n",
       "<td>0.0090171</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1120000</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0090416</td>\n",
       "<td>0.3946667</td>\n",
       "<td>0.3947003</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.2000000</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0089888</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0090035</td>\n",
       "<td>0.3549161</td>\n",
       "<td>0.3558531</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain\n",
       "--  -------  --------------------------  -----------------  -------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------\n",
       "    1        0.0119904                   0.995966           2.81757  2.81757            1                0.995966    1                           0.995966            0.0337838       0.0337838                  181.757  181.757\n",
       "    2        0.0215827                   0.995966           2.81757  2.81757            1                0.995966    1                           0.995966            0.027027        0.0608108                  181.757  181.757\n",
       "    3        0.0311751                   0.995965           2.81757  2.81757            1                0.995966    1                           0.995966            0.027027        0.0878378                  181.757  181.757\n",
       "    4        0.0407674                   0.995965           2.81757  2.81757            1                0.995965    1                           0.995966            0.027027        0.114865                   181.757  181.757\n",
       "    5        0.0503597                   0.995965           2.81757  2.81757            1                0.995965    1                           0.995966            0.027027        0.141892                   181.757  181.757\n",
       "    6        0.100719                    0.995962           2.81757  2.81757            1                0.995964    1                           0.995965            0.141892        0.283784                   181.757  181.757\n",
       "    7        0.151079                    0.995953           2.81757  2.81757            1                0.995959    1                           0.995963            0.141892        0.425676                   181.757  181.757\n",
       "    8        0.201439                    0.995903           2.81757  2.81757            1                0.995936    1                           0.995956            0.141892        0.567568                   181.757  181.757\n",
       "    9        0.29976                     0.991648           2.81757  2.81757            1                0.995118    1                           0.995681            0.277027        0.844595                   181.757  181.757\n",
       "    10       0.40048                     0.0262233          1.54295  2.49701            0.547619         0.508031    0.886228                    0.873039            0.155405        1                          54.2954  149.701\n",
       "    11       0.501199                    0.010915           0        1.99522            0                0.0153918   0.708134                    0.700689            0               1                          -100     99.5215\n",
       "    12       0.59952                     0.00967882         0        1.668              0                0.0102497   0.592                       0.587457            0               1                          -100     66.8\n",
       "    13       0.70024                     0.00922543         0        1.42808            0                0.00937405  0.506849                    0.504308            0               1                          -100     42.8082\n",
       "    14       0.798561                    0.00908676         0        1.25225            0                0.00914548  0.444444                    0.443342            0               1                          -100     25.2252\n",
       "    15       0.899281                    0.00901711         0        1.112              0                0.00904165  0.394667                    0.3947              0               1                          -100     11.2\n",
       "    16       1                           0.00898878         0        1                  0                0.00900347  0.354916                    0.355853            0               1                          -100     0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomialGLM: stackedensemble\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 0.009288004065626182\n",
      "RMSE: 0.09637429151815427\n",
      "LogLoss: 0.040418142997807535\n",
      "Null degrees of freedom: 93\n",
      "Residual degrees of freedom: 89\n",
      "Null deviance: 131.4093970117223\n",
      "Residual deviance: 7.598610883587815\n",
      "AIC: 17.598610883587817\n",
      "AUC: 1.0\n",
      "Gini: 1.0\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4350264114407421: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>B</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>B</td>\n",
       "<td>53.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/53.0)</td></tr>\n",
       "<tr><td>M</td>\n",
       "<td>0.0</td>\n",
       "<td>41.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/41.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>53.0</td>\n",
       "<td>41.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/94.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       B    M    Error    Rate\n",
       "-----  ---  ---  -------  ----------\n",
       "B      53   0    0        (0.0/53.0)\n",
       "M      0    41   0        (0.0/41.0)\n",
       "Total  53   41   0        (0.0/94.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.4350264</td>\n",
       "<td>1.0</td>\n",
       "<td>39.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.4350264</td>\n",
       "<td>1.0</td>\n",
       "<td>39.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.4350264</td>\n",
       "<td>1.0</td>\n",
       "<td>39.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4350264</td>\n",
       "<td>1.0</td>\n",
       "<td>39.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9959664</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.4350264</td>\n",
       "<td>1.0</td>\n",
       "<td>39.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9959664</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4350264</td>\n",
       "<td>1.0</td>\n",
       "<td>39.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.4350264</td>\n",
       "<td>1.0</td>\n",
       "<td>39.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.4350264</td>\n",
       "<td>1.0</td>\n",
       "<td>39.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value    idx\n",
       "---------------------------  -----------  -------  -----\n",
       "max f1                       0.435026     1        39\n",
       "max f2                       0.435026     1        39\n",
       "max f0point5                 0.435026     1        39\n",
       "max accuracy                 0.435026     1        39\n",
       "max precision                0.995966     1        0\n",
       "max recall                   0.435026     1        39\n",
       "max specificity              0.995966     1        0\n",
       "max absolute_mcc             0.435026     1        39\n",
       "max min_per_class_accuracy   0.435026     1        39\n",
       "max mean_per_class_accuracy  0.435026     1        39"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 43.62 %, avg score: 42.18 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0106383</td>\n",
       "<td>0.9959663</td>\n",
       "<td>2.2926829</td>\n",
       "<td>2.2926829</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9959664</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9959664</td>\n",
       "<td>0.0243902</td>\n",
       "<td>0.0243902</td>\n",
       "<td>129.2682927</td>\n",
       "<td>129.2682927</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0212766</td>\n",
       "<td>0.9959662</td>\n",
       "<td>2.2926829</td>\n",
       "<td>2.2926829</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9959663</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9959663</td>\n",
       "<td>0.0243902</td>\n",
       "<td>0.0487805</td>\n",
       "<td>129.2682927</td>\n",
       "<td>129.2682927</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0319149</td>\n",
       "<td>0.9959658</td>\n",
       "<td>2.2926829</td>\n",
       "<td>2.2926829</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9959662</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9959663</td>\n",
       "<td>0.0243902</td>\n",
       "<td>0.0731707</td>\n",
       "<td>129.2682927</td>\n",
       "<td>129.2682927</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0425532</td>\n",
       "<td>0.9959653</td>\n",
       "<td>2.2926829</td>\n",
       "<td>2.2926829</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9959657</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9959661</td>\n",
       "<td>0.0243902</td>\n",
       "<td>0.0975610</td>\n",
       "<td>129.2682927</td>\n",
       "<td>129.2682927</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0531915</td>\n",
       "<td>0.9959645</td>\n",
       "<td>2.2926829</td>\n",
       "<td>2.2926829</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9959652</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9959659</td>\n",
       "<td>0.0243902</td>\n",
       "<td>0.1219512</td>\n",
       "<td>129.2682927</td>\n",
       "<td>129.2682927</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1063830</td>\n",
       "<td>0.9959602</td>\n",
       "<td>2.2926829</td>\n",
       "<td>2.2926829</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9959627</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9959643</td>\n",
       "<td>0.1219512</td>\n",
       "<td>0.2439024</td>\n",
       "<td>129.2682927</td>\n",
       "<td>129.2682927</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1489362</td>\n",
       "<td>0.9959432</td>\n",
       "<td>2.2926829</td>\n",
       "<td>2.2926829</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9959554</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9959618</td>\n",
       "<td>0.0975610</td>\n",
       "<td>0.3414634</td>\n",
       "<td>129.2682927</td>\n",
       "<td>129.2682927</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2021277</td>\n",
       "<td>0.9958242</td>\n",
       "<td>2.2926829</td>\n",
       "<td>2.2926829</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9959052</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9959469</td>\n",
       "<td>0.1219512</td>\n",
       "<td>0.4634146</td>\n",
       "<td>129.2682927</td>\n",
       "<td>129.2682927</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.2978723</td>\n",
       "<td>0.9925317</td>\n",
       "<td>2.2926829</td>\n",
       "<td>2.2926829</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9951311</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9956846</td>\n",
       "<td>0.2195122</td>\n",
       "<td>0.6829268</td>\n",
       "<td>129.2682927</td>\n",
       "<td>129.2682927</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4042553</td>\n",
       "<td>0.7904326</td>\n",
       "<td>2.2926829</td>\n",
       "<td>2.2926829</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9336110</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9793495</td>\n",
       "<td>0.2439024</td>\n",
       "<td>0.9268293</td>\n",
       "<td>129.2682927</td>\n",
       "<td>129.2682927</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0225294</td>\n",
       "<td>0.7642276</td>\n",
       "<td>2.0</td>\n",
       "<td>0.3333333</td>\n",
       "<td>0.2146241</td>\n",
       "<td>0.8723404</td>\n",
       "<td>0.8329127</td>\n",
       "<td>0.0731707</td>\n",
       "<td>1.0</td>\n",
       "<td>-23.5772358</td>\n",
       "<td>100.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.5957447</td>\n",
       "<td>0.0126116</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6785714</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0143817</td>\n",
       "<td>0.7321429</td>\n",
       "<td>0.7013631</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>67.8571429</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7021277</td>\n",
       "<td>0.0104598</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4242424</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0112379</td>\n",
       "<td>0.6212121</td>\n",
       "<td>0.5967987</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.4242424</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7978723</td>\n",
       "<td>0.0092106</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2533333</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0095661</td>\n",
       "<td>0.5466667</td>\n",
       "<td>0.5263308</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.3333333</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8936170</td>\n",
       "<td>0.0090138</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1190476</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0091066</td>\n",
       "<td>0.4880952</td>\n",
       "<td>0.4709139</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.9047619</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0089930</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0090008</td>\n",
       "<td>0.4361702</td>\n",
       "<td>0.4217742</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  --------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0106383                   0.995966           2.29268   2.29268            1                0.995966    1                           0.995966            0.0243902       0.0243902                  129.268   129.268\n",
       "    2        0.0212766                   0.995966           2.29268   2.29268            1                0.995966    1                           0.995966            0.0243902       0.0487805                  129.268   129.268\n",
       "    3        0.0319149                   0.995966           2.29268   2.29268            1                0.995966    1                           0.995966            0.0243902       0.0731707                  129.268   129.268\n",
       "    4        0.0425532                   0.995965           2.29268   2.29268            1                0.995966    1                           0.995966            0.0243902       0.097561                   129.268   129.268\n",
       "    5        0.0531915                   0.995964           2.29268   2.29268            1                0.995965    1                           0.995966            0.0243902       0.121951                   129.268   129.268\n",
       "    6        0.106383                    0.99596            2.29268   2.29268            1                0.995963    1                           0.995964            0.121951        0.243902                   129.268   129.268\n",
       "    7        0.148936                    0.995943           2.29268   2.29268            1                0.995955    1                           0.995962            0.097561        0.341463                   129.268   129.268\n",
       "    8        0.202128                    0.995824           2.29268   2.29268            1                0.995905    1                           0.995947            0.121951        0.463415                   129.268   129.268\n",
       "    9        0.297872                    0.992532           2.29268   2.29268            1                0.995131    1                           0.995685            0.219512        0.682927                   129.268   129.268\n",
       "    10       0.404255                    0.790433           2.29268   2.29268            1                0.933611    1                           0.979349            0.243902        0.926829                   129.268   129.268\n",
       "    11       0.5                         0.0225294          0.764228  2                  0.333333         0.214624    0.87234                     0.832913            0.0731707       1                          -23.5772  100\n",
       "    12       0.595745                    0.0126116          0         1.67857            0                0.0143817   0.732143                    0.701363            0               1                          -100      67.8571\n",
       "    13       0.702128                    0.0104598          0         1.42424            0                0.0112379   0.621212                    0.596799            0               1                          -100      42.4242\n",
       "    14       0.797872                    0.00921064         0         1.25333            0                0.00956609  0.546667                    0.526331            0               1                          -100      25.3333\n",
       "    15       0.893617                    0.0090138          0         1.11905            0                0.00910658  0.488095                    0.470914            0               1                          -100      11.9048\n",
       "    16       1                           0.00899301         0         1                  0                0.00900078  0.43617                     0.421774            0               1                          -100      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomialGLM: stackedensemble\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.01965918392410031\n",
      "RMSE: 0.14021121183450455\n",
      "LogLoss: 0.07812424882474653\n",
      "Null degrees of freedom: 416\n",
      "Residual degrees of freedom: 412\n",
      "Null deviance: 543.9771262603819\n",
      "Residual deviance: 65.15562351983861\n",
      "AIC: 75.15562351983861\n",
      "AUC: 0.992087812719783\n",
      "Gini: 0.9841756254395659\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.19224675478735598: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>B</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>B</td>\n",
       "<td>263.0</td>\n",
       "<td>6.0</td>\n",
       "<td>0.0223</td>\n",
       "<td> (6.0/269.0)</td></tr>\n",
       "<tr><td>M</td>\n",
       "<td>3.0</td>\n",
       "<td>145.0</td>\n",
       "<td>0.0203</td>\n",
       "<td> (3.0/148.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>266.0</td>\n",
       "<td>151.0</td>\n",
       "<td>0.0216</td>\n",
       "<td> (9.0/417.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       B    M    Error    Rate\n",
       "-----  ---  ---  -------  -----------\n",
       "B      263  6    0.0223   (6.0/269.0)\n",
       "M      3    145  0.0203   (3.0/148.0)\n",
       "Total  266  151  0.0216   (9.0/417.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.1922468</td>\n",
       "<td>0.9698997</td>\n",
       "<td>138.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1922468</td>\n",
       "<td>0.9757739</td>\n",
       "<td>138.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.9537067</td>\n",
       "<td>0.9811047</td>\n",
       "<td>122.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.3288586</td>\n",
       "<td>0.9784173</td>\n",
       "<td>134.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9966978</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0087557</td>\n",
       "<td>1.0</td>\n",
       "<td>332.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9966978</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.1922468</td>\n",
       "<td>0.9531965</td>\n",
       "<td>138.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.1922468</td>\n",
       "<td>0.9776952</td>\n",
       "<td>138.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.1922468</td>\n",
       "<td>0.9787124</td>\n",
       "<td>138.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.192247     0.9699    138\n",
       "max f2                       0.192247     0.975774  138\n",
       "max f0point5                 0.953707     0.981105  122\n",
       "max accuracy                 0.328859     0.978417  134\n",
       "max precision                0.996698     1         0\n",
       "max recall                   0.00875574   1         332\n",
       "max specificity              0.996698     1         0\n",
       "max absolute_mcc             0.192247     0.953196  138\n",
       "max min_per_class_accuracy   0.192247     0.977695  138\n",
       "max mean_per_class_accuracy  0.192247     0.978712  138"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 35.49 %, avg score: 35.36 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0119904</td>\n",
       "<td>0.9966970</td>\n",
       "<td>2.8175676</td>\n",
       "<td>2.8175676</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9966977</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9966977</td>\n",
       "<td>0.0337838</td>\n",
       "<td>0.0337838</td>\n",
       "<td>181.7567568</td>\n",
       "<td>181.7567568</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0215827</td>\n",
       "<td>0.9966928</td>\n",
       "<td>2.8175676</td>\n",
       "<td>2.8175676</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9966940</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9966960</td>\n",
       "<td>0.0270270</td>\n",
       "<td>0.0608108</td>\n",
       "<td>181.7567568</td>\n",
       "<td>181.7567568</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0311751</td>\n",
       "<td>0.9966706</td>\n",
       "<td>2.8175676</td>\n",
       "<td>2.8175676</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9966833</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9966921</td>\n",
       "<td>0.0270270</td>\n",
       "<td>0.0878378</td>\n",
       "<td>181.7567568</td>\n",
       "<td>181.7567568</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0407674</td>\n",
       "<td>0.9966486</td>\n",
       "<td>2.8175676</td>\n",
       "<td>2.8175676</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9966589</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9966843</td>\n",
       "<td>0.0270270</td>\n",
       "<td>0.1148649</td>\n",
       "<td>181.7567568</td>\n",
       "<td>181.7567568</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0503597</td>\n",
       "<td>0.9966400</td>\n",
       "<td>2.8175676</td>\n",
       "<td>2.8175676</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9966459</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9966770</td>\n",
       "<td>0.0270270</td>\n",
       "<td>0.1418919</td>\n",
       "<td>181.7567568</td>\n",
       "<td>181.7567568</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1007194</td>\n",
       "<td>0.9959022</td>\n",
       "<td>2.8175676</td>\n",
       "<td>2.8175676</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9962873</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9964821</td>\n",
       "<td>0.1418919</td>\n",
       "<td>0.2837838</td>\n",
       "<td>181.7567568</td>\n",
       "<td>181.7567568</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1510791</td>\n",
       "<td>0.9945282</td>\n",
       "<td>2.8175676</td>\n",
       "<td>2.8175676</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9954347</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9961330</td>\n",
       "<td>0.1418919</td>\n",
       "<td>0.4256757</td>\n",
       "<td>181.7567568</td>\n",
       "<td>181.7567568</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2014388</td>\n",
       "<td>0.9937242</td>\n",
       "<td>2.8175676</td>\n",
       "<td>2.8175676</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9943743</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9956933</td>\n",
       "<td>0.1418919</td>\n",
       "<td>0.5675676</td>\n",
       "<td>181.7567568</td>\n",
       "<td>181.7567568</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.2997602</td>\n",
       "<td>0.9845325</td>\n",
       "<td>2.8175676</td>\n",
       "<td>2.8175676</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9919507</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9944657</td>\n",
       "<td>0.2770270</td>\n",
       "<td>0.8445946</td>\n",
       "<td>181.7567568</td>\n",
       "<td>181.7567568</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4004796</td>\n",
       "<td>0.0390917</td>\n",
       "<td>1.3416988</td>\n",
       "<td>2.4463910</td>\n",
       "<td>0.4761905</td>\n",
       "<td>0.4853264</td>\n",
       "<td>0.8682635</td>\n",
       "<td>0.8664187</td>\n",
       "<td>0.1351351</td>\n",
       "<td>0.9797297</td>\n",
       "<td>34.1698842</td>\n",
       "<td>144.6391002</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5011990</td>\n",
       "<td>0.0124766</td>\n",
       "<td>0.1341699</td>\n",
       "<td>1.9817341</td>\n",
       "<td>0.0476190</td>\n",
       "<td>0.0185561</td>\n",
       "<td>0.7033493</td>\n",
       "<td>0.6960348</td>\n",
       "<td>0.0135135</td>\n",
       "<td>0.9932432</td>\n",
       "<td>-86.5830116</td>\n",
       "<td>98.1734126</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.5995204</td>\n",
       "<td>0.0110428</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6567297</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0114694</td>\n",
       "<td>0.588</td>\n",
       "<td>0.5837661</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9932432</td>\n",
       "<td>-100.0</td>\n",
       "<td>65.6729730</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7002398</td>\n",
       "<td>0.0101740</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4184330</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0104892</td>\n",
       "<td>0.5034247</td>\n",
       "<td>0.5013085</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9932432</td>\n",
       "<td>-100.0</td>\n",
       "<td>41.8432988</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7985612</td>\n",
       "<td>0.0088688</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2437911</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0093830</td>\n",
       "<td>0.4414414</td>\n",
       "<td>0.4407411</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9932432</td>\n",
       "<td>-100.0</td>\n",
       "<td>24.3791088</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8992806</td>\n",
       "<td>0.0084976</td>\n",
       "<td>0.0670849</td>\n",
       "<td>1.1120000</td>\n",
       "<td>0.0238095</td>\n",
       "<td>0.0086929</td>\n",
       "<td>0.3946667</td>\n",
       "<td>0.3923517</td>\n",
       "<td>0.0067568</td>\n",
       "<td>1.0</td>\n",
       "<td>-93.2915058</td>\n",
       "<td>11.2000000</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0070754</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0075773</td>\n",
       "<td>0.3549161</td>\n",
       "<td>0.3535974</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0119904                   0.996697           2.81757    2.81757            1                0.996698    1                           0.996698            0.0337838       0.0337838                  181.757   181.757\n",
       "    2        0.0215827                   0.996693           2.81757    2.81757            1                0.996694    1                           0.996696            0.027027        0.0608108                  181.757   181.757\n",
       "    3        0.0311751                   0.996671           2.81757    2.81757            1                0.996683    1                           0.996692            0.027027        0.0878378                  181.757   181.757\n",
       "    4        0.0407674                   0.996649           2.81757    2.81757            1                0.996659    1                           0.996684            0.027027        0.114865                   181.757   181.757\n",
       "    5        0.0503597                   0.99664            2.81757    2.81757            1                0.996646    1                           0.996677            0.027027        0.141892                   181.757   181.757\n",
       "    6        0.100719                    0.995902           2.81757    2.81757            1                0.996287    1                           0.996482            0.141892        0.283784                   181.757   181.757\n",
       "    7        0.151079                    0.994528           2.81757    2.81757            1                0.995435    1                           0.996133            0.141892        0.425676                   181.757   181.757\n",
       "    8        0.201439                    0.993724           2.81757    2.81757            1                0.994374    1                           0.995693            0.141892        0.567568                   181.757   181.757\n",
       "    9        0.29976                     0.984533           2.81757    2.81757            1                0.991951    1                           0.994466            0.277027        0.844595                   181.757   181.757\n",
       "    10       0.40048                     0.0390917          1.3417     2.44639            0.47619          0.485326    0.868263                    0.866419            0.135135        0.97973                    34.1699   144.639\n",
       "    11       0.501199                    0.0124766          0.13417    1.98173            0.047619         0.0185561   0.703349                    0.696035            0.0135135       0.993243                   -86.583   98.1734\n",
       "    12       0.59952                     0.0110428          0          1.65673            0                0.0114694   0.588                       0.583766            0               0.993243                   -100      65.673\n",
       "    13       0.70024                     0.010174           0          1.41843            0                0.0104892   0.503425                    0.501308            0               0.993243                   -100      41.8433\n",
       "    14       0.798561                    0.00886877         0          1.24379            0                0.00938302  0.441441                    0.440741            0               0.993243                   -100      24.3791\n",
       "    15       0.899281                    0.00849765         0.0670849  1.112              0.0238095        0.0086929   0.394667                    0.392352            0.00675676      1                          -93.2915  11.2\n",
       "    16       1                           0.00707537         0          1                  0                0.00757729  0.354916                    0.353597            0               1                          -100      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<bound method ModelBase.coef_norm of >\n"
     ]
    }
   ],
   "source": [
    "mods=mod_best.coef_norm\n",
    "print(mods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gain Lift Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.011990</td>\n",
       "      <td>0.995966</td>\n",
       "      <td>2.817568</td>\n",
       "      <td>2.817568</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995966</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995966</td>\n",
       "      <td>0.033784</td>\n",
       "      <td>0.033784</td>\n",
       "      <td>181.756757</td>\n",
       "      <td>181.756757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0.021583</td>\n",
       "      <td>0.995966</td>\n",
       "      <td>2.817568</td>\n",
       "      <td>2.817568</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995966</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995966</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.060811</td>\n",
       "      <td>181.756757</td>\n",
       "      <td>181.756757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>0.031175</td>\n",
       "      <td>0.995965</td>\n",
       "      <td>2.817568</td>\n",
       "      <td>2.817568</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995966</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995966</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.087838</td>\n",
       "      <td>181.756757</td>\n",
       "      <td>181.756757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.040767</td>\n",
       "      <td>0.995965</td>\n",
       "      <td>2.817568</td>\n",
       "      <td>2.817568</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995965</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995966</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.114865</td>\n",
       "      <td>181.756757</td>\n",
       "      <td>181.756757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>0.050360</td>\n",
       "      <td>0.995965</td>\n",
       "      <td>2.817568</td>\n",
       "      <td>2.817568</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995965</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995966</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.141892</td>\n",
       "      <td>181.756757</td>\n",
       "      <td>181.756757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>0.100719</td>\n",
       "      <td>0.995962</td>\n",
       "      <td>2.817568</td>\n",
       "      <td>2.817568</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995964</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995965</td>\n",
       "      <td>0.141892</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>181.756757</td>\n",
       "      <td>181.756757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>0.151079</td>\n",
       "      <td>0.995953</td>\n",
       "      <td>2.817568</td>\n",
       "      <td>2.817568</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995959</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995963</td>\n",
       "      <td>0.141892</td>\n",
       "      <td>0.425676</td>\n",
       "      <td>181.756757</td>\n",
       "      <td>181.756757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "      <td>0.201439</td>\n",
       "      <td>0.995903</td>\n",
       "      <td>2.817568</td>\n",
       "      <td>2.817568</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995936</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995956</td>\n",
       "      <td>0.141892</td>\n",
       "      <td>0.567568</td>\n",
       "      <td>181.756757</td>\n",
       "      <td>181.756757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>0.299760</td>\n",
       "      <td>0.991648</td>\n",
       "      <td>2.817568</td>\n",
       "      <td>2.817568</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995118</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995681</td>\n",
       "      <td>0.277027</td>\n",
       "      <td>0.844595</td>\n",
       "      <td>181.756757</td>\n",
       "      <td>181.756757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>0.400480</td>\n",
       "      <td>0.026223</td>\n",
       "      <td>1.542954</td>\n",
       "      <td>2.497006</td>\n",
       "      <td>0.547619</td>\n",
       "      <td>0.508031</td>\n",
       "      <td>0.886228</td>\n",
       "      <td>0.873039</td>\n",
       "      <td>0.155405</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>54.295367</td>\n",
       "      <td>149.700599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>0.501199</td>\n",
       "      <td>0.010915</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.995215</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015392</td>\n",
       "      <td>0.708134</td>\n",
       "      <td>0.700689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>99.521531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.599520</td>\n",
       "      <td>0.009679</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.668000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010250</td>\n",
       "      <td>0.592000</td>\n",
       "      <td>0.587457</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>66.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.700240</td>\n",
       "      <td>0.009225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.428082</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009374</td>\n",
       "      <td>0.506849</td>\n",
       "      <td>0.504308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>42.808219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0.798561</td>\n",
       "      <td>0.009087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.252252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009145</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.443342</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>25.225225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>15</td>\n",
       "      <td>0.899281</td>\n",
       "      <td>0.009017</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.112000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009042</td>\n",
       "      <td>0.394667</td>\n",
       "      <td>0.394700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>11.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008989</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009003</td>\n",
       "      <td>0.354916</td>\n",
       "      <td>0.355853</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0         1                  0.011990         0.995966  2.817568   \n",
       "1         2                  0.021583         0.995966  2.817568   \n",
       "2         3                  0.031175         0.995965  2.817568   \n",
       "3         4                  0.040767         0.995965  2.817568   \n",
       "4         5                  0.050360         0.995965  2.817568   \n",
       "5         6                  0.100719         0.995962  2.817568   \n",
       "6         7                  0.151079         0.995953  2.817568   \n",
       "7         8                  0.201439         0.995903  2.817568   \n",
       "8         9                  0.299760         0.991648  2.817568   \n",
       "9        10                  0.400480         0.026223  1.542954   \n",
       "10       11                  0.501199         0.010915  0.000000   \n",
       "11       12                  0.599520         0.009679  0.000000   \n",
       "12       13                  0.700240         0.009225  0.000000   \n",
       "13       14                  0.798561         0.009087  0.000000   \n",
       "14       15                  0.899281         0.009017  0.000000   \n",
       "15       16                  1.000000         0.008989  0.000000   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0          2.817568       1.000000  0.995966                  1.000000   \n",
       "1          2.817568       1.000000  0.995966                  1.000000   \n",
       "2          2.817568       1.000000  0.995966                  1.000000   \n",
       "3          2.817568       1.000000  0.995965                  1.000000   \n",
       "4          2.817568       1.000000  0.995965                  1.000000   \n",
       "5          2.817568       1.000000  0.995964                  1.000000   \n",
       "6          2.817568       1.000000  0.995959                  1.000000   \n",
       "7          2.817568       1.000000  0.995936                  1.000000   \n",
       "8          2.817568       1.000000  0.995118                  1.000000   \n",
       "9          2.497006       0.547619  0.508031                  0.886228   \n",
       "10         1.995215       0.000000  0.015392                  0.708134   \n",
       "11         1.668000       0.000000  0.010250                  0.592000   \n",
       "12         1.428082       0.000000  0.009374                  0.506849   \n",
       "13         1.252252       0.000000  0.009145                  0.444444   \n",
       "14         1.112000       0.000000  0.009042                  0.394667   \n",
       "15         1.000000       0.000000  0.009003                  0.354916   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate        gain  \\\n",
       "0           0.995966      0.033784                 0.033784  181.756757   \n",
       "1           0.995966      0.027027                 0.060811  181.756757   \n",
       "2           0.995966      0.027027                 0.087838  181.756757   \n",
       "3           0.995966      0.027027                 0.114865  181.756757   \n",
       "4           0.995966      0.027027                 0.141892  181.756757   \n",
       "5           0.995965      0.141892                 0.283784  181.756757   \n",
       "6           0.995963      0.141892                 0.425676  181.756757   \n",
       "7           0.995956      0.141892                 0.567568  181.756757   \n",
       "8           0.995681      0.277027                 0.844595  181.756757   \n",
       "9           0.873039      0.155405                 1.000000   54.295367   \n",
       "10          0.700689      0.000000                 1.000000 -100.000000   \n",
       "11          0.587457      0.000000                 1.000000 -100.000000   \n",
       "12          0.504308      0.000000                 1.000000 -100.000000   \n",
       "13          0.443342      0.000000                 1.000000 -100.000000   \n",
       "14          0.394700      0.000000                 1.000000 -100.000000   \n",
       "15          0.355853      0.000000                 1.000000 -100.000000   \n",
       "\n",
       "    cumulative_gain  \n",
       "0        181.756757  \n",
       "1        181.756757  \n",
       "2        181.756757  \n",
       "3        181.756757  \n",
       "4        181.756757  \n",
       "5        181.756757  \n",
       "6        181.756757  \n",
       "7        181.756757  \n",
       "8        181.756757  \n",
       "9        149.700599  \n",
       "10        99.521531  \n",
       "11        66.800000  \n",
       "12        42.808219  \n",
       "13        25.225225  \n",
       "14        11.200000  \n",
       "15         0.000000  "
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "se_gain_lift = mod_best.gains_lift().as_data_frame()\n",
    "se_gain_lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stackedensemble prediction progress: |████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>predict  </th><th style=\"text-align: right;\">         B</th><th style=\"text-align: right;\">        M</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>M        </td><td style=\"text-align: right;\">0.00507991</td><td style=\"text-align: right;\">0.99492  </td></tr>\n",
       "<tr><td>M        </td><td style=\"text-align: right;\">0.0042037 </td><td style=\"text-align: right;\">0.995796 </td></tr>\n",
       "<tr><td>M        </td><td style=\"text-align: right;\">0.00491119</td><td style=\"text-align: right;\">0.995089 </td></tr>\n",
       "<tr><td>M        </td><td style=\"text-align: right;\">0.00403938</td><td style=\"text-align: right;\">0.995961 </td></tr>\n",
       "<tr><td>M        </td><td style=\"text-align: right;\">0.00406082</td><td style=\"text-align: right;\">0.995939 </td></tr>\n",
       "<tr><td>B        </td><td style=\"text-align: right;\">0.975727  </td><td style=\"text-align: right;\">0.024273 </td></tr>\n",
       "<tr><td>B        </td><td style=\"text-align: right;\">0.590578  </td><td style=\"text-align: right;\">0.409422 </td></tr>\n",
       "<tr><td>M        </td><td style=\"text-align: right;\">0.123469  </td><td style=\"text-align: right;\">0.876531 </td></tr>\n",
       "<tr><td>B        </td><td style=\"text-align: right;\">0.967328  </td><td style=\"text-align: right;\">0.0326719</td></tr>\n",
       "<tr><td>M        </td><td style=\"text-align: right;\">0.00418946</td><td style=\"text-align: right;\">0.995811 </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "se_prediction_df=predictions_test(mod_best,test,run_id)\n",
    "se_prediction_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:58\n",
      "Cols:3\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th>predict  </th><th>B                    </th><th>M                   </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>type   </td><td>enum     </td><td>real                 </td><td>real                </td></tr>\n",
       "<tr><td>mins   </td><td>         </td><td>0.004035958691330999 </td><td>0.009007318316260095</td></tr>\n",
       "<tr><td>mean   </td><td>         </td><td>0.5880640097366142   </td><td>0.41193599026338573 </td></tr>\n",
       "<tr><td>maxs   </td><td>         </td><td>0.9909926816837399   </td><td>0.995964041308669   </td></tr>\n",
       "<tr><td>sigma  </td><td>         </td><td>0.4632005683318037   </td><td>0.4632005683318037  </td></tr>\n",
       "<tr><td>zeros  </td><td>         </td><td>0                    </td><td>0                   </td></tr>\n",
       "<tr><td>missing</td><td>0        </td><td>0                    </td><td>0                   </td></tr>\n",
       "<tr><td>0      </td><td>M        </td><td>0.005079913903096589 </td><td>0.9949200860969034  </td></tr>\n",
       "<tr><td>1      </td><td>M        </td><td>0.004203699504640723 </td><td>0.9957963004953593  </td></tr>\n",
       "<tr><td>2      </td><td>M        </td><td>0.004911187283380136 </td><td>0.9950888127166199  </td></tr>\n",
       "<tr><td>3      </td><td>M        </td><td>0.0040393800520887035</td><td>0.9959606199479113  </td></tr>\n",
       "<tr><td>4      </td><td>M        </td><td>0.004060818375854147 </td><td>0.9959391816241459  </td></tr>\n",
       "<tr><td>5      </td><td>B        </td><td>0.9757269724772991   </td><td>0.024273027522700892</td></tr>\n",
       "<tr><td>6      </td><td>B        </td><td>0.590578184244801    </td><td>0.4094218157551989  </td></tr>\n",
       "<tr><td>7      </td><td>M        </td><td>0.12346910878016681  </td><td>0.8765308912198332  </td></tr>\n",
       "<tr><td>8      </td><td>B        </td><td>0.9673280688704831   </td><td>0.03267193112951689 </td></tr>\n",
       "<tr><td>9      </td><td>M        </td><td>0.004189455082283522 </td><td>0.9958105449177165  </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "se_prediction_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred= gbm_predictions_df['predict'].as_data_frame()\n",
    "y_act= test['diagnosis'].as_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e8ee087278>"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAEFCAYAAAAG45eHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQggPJkVeCCE82P8DhWsnJ/56QxEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e8edb6c588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "# plot training logloss and auc\n",
    "#gbm_predictions_df.plot(x='cumulative_data_fraction',y = ['cumulative_capture_rate', 'cumulative_lift'])\n",
    "se_gain_lift.plot(x='cumulative_data_fraction',y = ['cumulative_capture_rate', 'cumulative_lift'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi4AAAGyCAYAAADDBk96AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSVIx/j9ZYDHtwFGOPQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e8ee1b84a8>"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi4AAAGyCAYAAADDBk96AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHnVJREFUeJzt3Xm4XGWV7/FvnSQkTOKsYNPtvPrKvZdJEZkSAQERREBF\nEAQREYQIMjVCFBlsZL4OLSAyidgNMogdwUYGQURABnGAu2SQQQa5zLMZOPeP2rGPMeecCpy9K+/Z\n3w9PPanadWrXSp4H+GWt9927Mzg4iCRJUgkG+l2AJElSrwwukiSpGAYXSZJUDIOLJEkqhsFFkiQV\nw+AiSZKKMbHfBYzmf//TVPdrS31w7a++1+8SpFZa/LXLd5r8vrH8/+xv7r6i9trtuEiSpGIs8h0X\nSZJUn06n0QbPS2bHRZIkFcOOiyRJLdbplNXDKKtaSZLUagYXSZJUDEdFkiS12ABlLc41uEiS1GLu\nKpIkSaqJHRdJklpsoLBdRQYXSZJazFGRJElSTQwukiSpGI6KJElqsU5h26HtuEiSpGLYcZEkqcXc\nVSRJkopR2q4ig4skSS02UFhwKas/JEmSWs3gIkmSiuGoSJKkFusU1sMwuEiSpEZExATgJCCAQWAX\n4HngtOr174DdMvOF4c5RVsySJEljqtPpjNmjB5sCZOaawAzgK8CxwIzMXBvoAJuNdAKDiyRJLTbQ\n6YzZYzSZ+UNg5+rlPwGPA6sCV1THLgLWH7HeF/9blSRJWjiZOSciTge+AZwJdDJzsHr7KWCZkT5v\ncJEkqcU6Y/hPrzJze+DtdNe7LD7kraXpdmGGZXCRJEmNiIjtIuIL1ctngReA6yNiWnXs/cDPRzqH\nu4okSVJTzgNOjYgrgUnAnsCtwEkRsVj1/JyRTmBwkSSpxZq8yWJmPgN8dAFvTe31HAYXSZJarLSb\nLLrGRZIkFcOOiyRJLVba3aENLpIktdjCbGNeFDgqkiRJxTC4SJKkYjgqkiSpxZrcDj0WyqpWkiS1\nmh0XSZJarLTruBhcJElqsdK2QzsqkiRJxbDjIklSi3kdF0mSpJoYXCRJUjEcFUmS1GLuKpIkScVw\nV5EkSVJN7LhIktRipe0qMrhIktRi3qtIkiSpJgYXSZJUDEdFkiS1WGnboe24SJKkYthxkSSpxUq7\njovBRZKkFittO7SjIkmSVAw7LpIktVhpoyI7LpIkqRgGF0mSVAxHRZIktVhp13ExuEiS1GKucZEk\nSaqJHRdJklqstOu4GFwkSWoxR0WSJEk1MbhIkqRiOCqSJKnFStsObcdFkiQVw46LJEktVtriXIOL\nJEktVtp2aEdFkiSpGHZcJElqsdJGRXZcJElSMey4SJLUYm6HliRJqokdF0mSWqy0NS4GF0mSWsxR\nkSRJUk3suEiS1GJegE6SJKkmBhdJklQMR0WSJLXYQFmTIoOLJElt5q4iSZKkmthxkSSpxbwAnSRJ\nKkZTo6KImAScArwRmAwcBtwLzARuq37s+Mw8a6TzGFwkSVITtgUeycztIuKVwK+BQ4BjM/OYXk9i\ncJEkSU34AXBO9bwDzAFWBSIiNqPbddkzM58a6SQuzpUkqcUG6IzZYySZ+XRmPhURS9MNMDOA64B9\nM3Md4E7goNHrlSRJakBELA9cDpyRmd8Hzs/MG6q3zwdWHu0ctY+KImJwvkOPABfQQztIkiTVq8HF\nua8DLgZ2z8xLq8P/FRHTM/M6YD3ghmFPUGlqjctHgZ8DE4DlgROBY4FPN/T9qtnAwAAHHbEvb3zz\n8gwODnLYAccyYeIEvnDwHsydO5dZs2Zz4F7/yqMPP9bvUqVxa+7cuRxy5LHcdc+f6HRgxj578tY3\nv6nfZWkR1+B26AOAVwBfjIgvVsf2Ao6LiNnAg8DOo52kqeDyWGY+WD2/LyIOB76NwWXcmLr+GgBs\nv+XuvHP1lZi+704s/bKlOPygr5G33M6Ht9mUHXfdhqMP/bc+VyqNX1f84hoATj/+a/zqpl/zzZNO\n4f8cfmifq5K6MnMPYI8FvLXmwpynX7uKnunT96oml198FVde+ksAlnvD63jqyac59MBjePihRwGY\nMHECs56f1c8SpXFv3XXWZJ01VgfggQcfYqmllupzRSpBYdefaz64RMSrgc8B32v6u1WvuXPnctgx\nX2DdDddm712/9NfQsuKqK7D19lvwyY9M73OF0vg3ceIEZnzlCC6/8hccdeiX+l2ONOaaCi7/GRFz\n6e7bXgJ4lG540TgzY+/DedVXT+TMHx7P5utvzzrrvYdP774du+3wLzz26BP9Lk9qhcMO/Bce3uVR\ntvvM7px3xsksvvji/S5JGjNNbYf+DLASsCKwGnAG8MuIeHtD36+abbL5Bnzqsx8H4PnnnmdwcJD1\nNlqHrbffgh232oP77n2gzxVK49/Mn/yUk8/4PgBTpkymMzBAZ8CrXmhkA53OmD2a0FTH5f7MvH3I\n619FxPvpLs7dt6EaVKNLf3Ilhxy9P6ee/XUmTprIEQd/g0OP3p8H7vszx53YXRx4w7U3863jTu1z\npdL4td7UtfjS4Uex4+6fZ86cOew7fVemTJ7c77K0iOuMcuG4RU0/L/nf6fP3aww999zz7Lvbl//m\n2NorbtqfYqSWWnzxxTnqENe1aHxrKji8IiJeXz1fHNgReCvd+xZIkqQ+aeoCdGOlqeBy9pDnzwM3\nA1tm5tUNfb8kSVqABi9ANyZqDy6ZWdafiCRJWmS5xkSSpBYrrOHi3aElSVI5DC6SJKkYjookSWox\nF+dKkqRilHYBOkdFkiSpGHZcJElqMUdFkiSpGIXlFkdFkiSpHAYXSZJUDEdFkiS1WGk3WbTjIkmS\nimHHRZKkFnNXkSRJKkZhucVRkSRJKocdF0mSWqy0UZEdF0mSVAyDiyRJKoajIkmSWqy0u0MbXCRJ\najEvQCdJklQTOy6SJLXYQFkNF4OLJElt5qhIkiSpJgYXSZJUDEdFkiS1WGmjIoOLJEktVtriXEdF\nkiSpGHZcJElqMUdFkiSpGIXlFkdFkiSpHAYXSZJUDEdFkiS12EBhsyI7LpIkqRh2XCRJarEOZXVc\nDC6SJLVYYZMiR0WSJKkcdlwkSWoxF+dKkiTVxOAiSZKK4ahIkqQW815FkiSpGIXlFkdFkiSpHHZc\nJElqMUdFkiSpGANl5RZHRZIkqRwGF0mSVAxHRZIktVhTa1wiYhJwCvBGYDJwGHALcBowCPwO2C0z\nXxjpPHZcJElSE7YFHsnMtYGNgG8CxwIzqmMdYLPRTmJwkSSpxTqdsXuM4gfAF+d9LTAHWBW4ojp2\nEbD+aCdxVCRJUos1dZPFzHwaICKWBs4BZgBHZ+Zg9SNPAcuMdh47LpIkqRERsTxwOXBGZn4fGLqe\nZWng8dHOYXCRJKnFOp3OmD1GEhGvAy4G/iUzT6kO3xQR06rn7wd+Plq9jookSVITDgBeAXwxIuat\nddkD+HpELAbcSneENCKDiyRJql1m7kE3qMxv6sKcx+AiSVKLFXarIoOLJEltVtpNFl2cK0mSimHH\nRZKkFius4WJwkSSpzZq6AN1YGTW4RMRqwFp07ykwE1gZ2CUzz625NkmSpL/RyxqXrwPXAx8GngVW\nAfavsyhJkqQF6SW4DGTmlcAHgHMz814cMUmSNC40eJPFMdFLcHk2IvYG1gNmRsQedG+EJEmS1Khe\ngsvHgSWBzTPzMWA5YJtaq5IkSY1o6l5FY2XU4JKZ9wGXAStGxGTgx5n5p9orkyRJtRt3o6JqNHQo\nsBewFHBiROxTd2GSJEnz62VUtAOwIfBMZj4CvAvYsc6iJElSM8bdqAiYm5mzhrx+HphbUz2SJEnD\n6iW4XBERRwNLRsSHgB8Bl9ZbliRJ0t/rJbjsC9wG3Ax8ArgQcI2LJEnjQGmLc3u5kNw/ABdVj3mW\nA+6ppSJJktSYcXevIuAKYLB6vhjweuAmuot0JUmSGjNqcMnMNw19Xd10cbfaKpIkSY0prOHS0xqX\nv5GZ1wGr1lCLJElqWGnboUftuETEl4a87ADvAP5cW0WSJEnD6KXj0hnyGKS75uUjdRYlSZK0IL2s\ncTm4iUIkSVLzSlvjMmxwiYgX+O/dREN1gMHMnFBbVZIkSQswbHDJzIVeuCtJksrS1KLasdLL4tzX\nAh+ne2foDjABeFNmfqLm2iRJUs0Kyy09Lc49D1gJ2BZYEvgg8EKdRUmSpGaUth26l+Dy6szcHvhP\nuiFmGrBCnUVJkiQtSC/B5bHq1wRWzMwngEn1lSRJkrRgvdyr6LKI+AHdO0JfHBGrAM/XW5YkSWrC\nuFvjkpkHAvtn5t3A1nQ7L1vUXZgkSdL8RrqOyw3Ad4DvZ+YdAJl5I3BjQ7VJkqSalbYdeqSOy+fp\n3kwxI+LMiFi3oZokSVJDOp2xezRhpAvQXQlcGRGTgQ8Be0XECcAZwGmZeW8zJUqSJHX1cq+ivwBn\nAWdVF6M7BLgDWKzm2gC4/rfnNfE1kuZz6i4n9bsEqZU+8/39G/2+gcJGRb3sKiIi3gZsA2wF3At4\n1VxJksaBwnLLiItzlwU+Rvdy/8sApwEbOiKSJEn9MlLHJeleKXfvzLyioXokSZKGNVJweUNmPtVY\nJZIkqXHjZju0oUWSJC1qelqcK0mSxqfCGi497ypaEngL8Ftgicx8ptaqJElSIzoDZSWXUe9VFBHr\nATcDFwCvB+6KiA3qLkySJGl+owYX4F+BtYDHM/MBYCpwVK1VSZKkRpR2yf9egstAZj4470Vm3lJj\nPZIkScPqZY3LnyJiE2AwIl4O7AbcU29ZkiRJf6+X4PIZ4GvA8sCdwKXAznUWJUmSmlHadVx6ucni\nQ8DWDdQiSZIaVlhuGT24RMQfgcH5j2fmm2upSJIkaRi9jIqmDXk+CdgcmFxLNZIkqVHjcVR093yH\njoqI64HD6ilJkiQ1pbDc0tOoaJ0hLzvACsDitVUkSZI0jF5GRQcPeT4IPAxsX085kiRJw+sluJyd\nmcfXXokkSWpeYbOiXq6cu1vtVUiSJPWgl47LvRFxGXAt8Ny8g5l5SG1VSZKkRjS9qygi3g0ckZnT\nImJlYCZwW/X28Zl51kif7yW4XDPkeVn9JEmSNKImc0tE7AdsBzxTHVoVODYzj+n1HMMGl4jYPjNP\nz8yDh/sZSZKkhXAHsAVwRvV6VSAiYjO6XZc9M/OpkU4w0hqXPcakREmStMjqDHTG7DGazDwXmD3k\n0HXAvpm5Dt37IR402jl6WZwrSZJUh/Mz84Z5z4GVR/vASGtcVoiIOxdwvAMMeq8iSZL0Ev1XREzP\nzOuA9YAbRvvASMHldmDjsapMkiQtevp8GZddgW9ExGzgQWDn0T4wUnCZtYD7FEmSpHGk6e3QmXkX\nsHr1/EZgzYX5/EhrXH7x4suSJEkae8N2XDJz9yYLkSRJzSvsiv89XYBOkiSNU02Pil4qt0NLkqRi\nGFwkSVIxHBVJktRihU2K7LhIkqRy2HGRJKnFSluca3CRJKnNCpu9FFauJElqMzsukiS1WGmjIjsu\nkiSpGAYXSZJUDEdFkiS1WGGTIoOLJElt5hoXSZKkmthxkSSpxQpruBhcJElqtcKSi6MiSZJUDIOL\nJEkqhqMiSZJarDNQ1qjI4CJJUosVtsTFUZEkSSqHHRdJklqstAvQGVwkSWqxwnKLoyJJklQOg4sk\nSSqGoyJJktqssFmRHRdJklQMOy6SJLWYF6CTJEnFKGxS5KhIkiSVw46LJEltVljLxY6LJEkqhsFF\nkiQVw1GRJEktVtikyOAiSVKblbYd2lGRJEkqhh0XSZJarFPYrMjgIklSm5WVWxwVSZKkchhcJElS\nMRwVSZLUYqWtcbHjIkmSimHHRZKkFiut42JwkSSpzQqbvRRWriRJajM7LpIktVhpoyI7LpIkqRgG\nF0mSVAxHRZIktVhpoyKDiyRJbVZWbnFUJEmSymHHRZKkFusMlNVyMbhIktRmha1xcVQkSZKKYcdF\nkiQ1JiLeDRyRmdMi4q3AacAg8Dtgt8x8YaTP23GRJKnFOp2xe4wmIvYDvgNMqQ4dC8zIzLXp7m/a\nbLRzGFwkSVJT7gC2GPJ6VeCK6vlFwPqjncDgIklSi3U6nTF7jCYzzwVmD/36zBysnj8FLDPaOWpb\n4xIR8wp5S2beOd97uwDHA1/JzBl11SBJkkbR3+3QQ9ezLA08PtoH6l6cOxvYFPjafMc/RHchjsah\n2XPm8KVDvsL9DzzIrFmz2HnHHXjv1LX7XZY0Lg1MGGDqzhuz9GuWYcKkCdx4/tXcfePtALxn2/V4\n/IFHuPXSX/e5SmlYN0XEtMz8GfB+4PLRPlB3cLkS+CBDgktEvAxYA7ip5u9Wn8y88Ce8fJllOPyQ\ng3jiiSf58Me3N7hINXnbWivwl6ef4/LjZzJ5ySlsefgn+fNt9/HeXTdhmWVfyeMzH+l3iVrE9fle\nRXsDJ0XEYsCtwDmjfaDu4HIBcExELJOZT1THNgZ+DixZ83erTzZcf102WO+9AAwODjJhwoQ+VySN\nX3dc83+589rsvujA4AuDTJqyGDecexXLr/SW/hYnLUBm3gWsXj3/AzB1YT5f9+LcW4G76LZ/5tkM\n+GHN36s+WmKJJVhyySV55pln2Gv/A5m+6879Lkkat+b8ZTazn5/FpCmL8b49NudXZ1/JU//vCR66\n44F+lybVooldRRfQXedCREwCNqyOaRx78ME/s+Ou09l04434wEYb9LscaVxb8pVLs+mMrbntqt9z\n+9W39LsclaYzho8GNHHl3AuAH0XERGBd4PeZ+VBENPDV6oeHH3mUnafvyQH77s3qq72z3+VI49ri\nL1uCD3xhK35x2k+57/d397scFajPa1wWWhPB5WpgDrAW3THR+Q18p/roO6eezpNPPsWJJ5/KiSef\nCsDxXzuWKVMm97kyafxZ+UNrMHnJKayy+ZqssvmaAFx4xNnMnT2nz5VJ9ag9uGTmCxExk+7uok2B\nder+TvXX/vt8nv33+Xy/y5Ba4ervXsLV371kge/dcO5VDVejEnX6ex2XhdbUTRYvAM4A7szMPzb0\nnZIkaTSFjYqauuT/T+mGJHcTSZKkF622jktmdoY8fxZYYr73p9X13ZIkqTelLc71JouSJKkYTa1x\nkSRJi6KyGi52XCRJUjnsuEiS1GJuh5YkSeVwca4kSVI97LhIktRiboeWJEmqicFFkiQVw1GRJElt\n5q4iSZJUCte4SJIk1cSOiyRJbVZWw8XgIklSmzkqkiRJqonBRZIkFcNRkSRJbVbYdmg7LpIkqRh2\nXCRJarHSFucaXCRJarPCgoujIkmSVAw7LpIktVhpoyI7LpIkqRgGF0mSVAxHRZIktVlh13ExuEiS\n1GKucZEkSaqJHRdJktqssI6LwUWSpBbrFLbGxVGRJEkqhsFFkiQVw1GRJEltVtgaFzsukiSpGHZc\nJElqsdKu42JwkSSpzQoLLo6KJElSMey4SJLUYl7HRZIkqSYGF0mSVAxHRZIktVlhi3MNLpIktVlh\nwcVRkSRJKoYdF0mSWswL0EmSpHK4HVqSJKkeBhdJklQMR0WSJLVYp1NWD8PgIkmSGhMRNwJPVi//\nmJmfXJjPG1wkSWqzBncVRcQUoJOZ017sOQwukiS1WMPboVcEloiIi+lmkAMy85qFOUFZgy1JklSy\nZ4GjgQ2BXYAzI2Khmih2XCRJarNmr+PyB+D2zBwE/hARjwDLAvf2egI7LpIkqSk7AscARMRywMuA\nBxbmBHZcJElSU04GTouIq4BBYMfMnLMwJzC4SJLUYk0uzs3MWcA2L+UcBhdJktrMmyxKkqRiFHbl\n3LKqlSRJrWbHRZKkFus0ux36JbPjIkmSimFwkSRJxXBUJElSm7mrSJIklaLhmyy+ZI6KJElSMey4\nSJLUZoVdx8XgIklSi7kdWpIkqSYGF0mSVAxHRZIktZm7iiRJkuphx0WSpBYr7TouBhdJktqssO3Q\nZVUrSZJazY6LJElt5nVcJEmS6mFwkSRJxXBUJElSi7mrSJIklcNdRZIkSfWw4yJJUos5KpIkSeVw\nVCRJklQPg4skSSqGoyJJklqs45VzJUmS6mHHRZKkNnNXkSRJKkXHXUWSJEn1sOMiSVKbFTYq6gwO\nDva7BkmSpJ44KpIkScUwuEiSpGIYXCRJUjEMLpIkqRgGF0mSVAyDiyRJKobBRZIkFcPgIkkFiIh/\n7HcN0qLA4KKeRcS7ImKliFhxyLGyLrkoFSgi9gfOiYh1+12L1G9eOVc9iYivAlsCg8DiwDcy88j+\nViWNfxGxDHAGsAlwJvDvmXlhf6uS+seOi0YVEccBuwDbAdsABwMHRsQmfS1MaoHMfAI4i+5fGt4E\nfDQiNupvVVL/GFw0oog4km5gWSszr8nM64GzgcuA10TElL4WKI1jETEAkJlnAicDs4B/BD4VERv0\nszapXwwuGla1GHAf4MjM/N2Q/4g+CSwD7AncEhEXRcRn+liqNC5l5gsRsVj18nzgWuA44JXAZyPi\nfX0rTuoTg4uGlZn3ABsDB0TEx4AO/HWh4LuB7wJfqI7vEhH/s1+1SuNFRBxUPVYDyMxZ1Vu/AtYC\nlge2BZYGdjW8qG1cnKtRVfP08+guDnw3sDewTWZeXL2/LPAnYJfMPKlvhUqFi4jlgburl5dUz6cD\nczNzdkSsApwCbF39zDeBh4HvZuaPm65X6gc7LhpVZv6E7o6iS4AvAttm5sUR0YmIicCzwC/p/gdU\n0ouUmfcC87Y8Pwy8k+6/W5+LiHdk5o3ATGD9zLwV2A94K7BVRCzRj5qlptlxUc8iYhrdRbmbAxdm\n5uzq+JeBT9JdwHtv3wqUxolq/HMu3YXxKwFvA9YB9gKWBXYCNsnMe6vrKj2emXcPdz5pPDG4aKFE\nxPvp/gd1+8z8QRVa9gfWqP42KGkMRMTGdK/f8ingerqj2r2AH9G9PMH3gM9n5nN9K1LqA0dFWiiZ\neRGwBfDtiJhJd73LmoYWaWxVF5nbjm5AeU9mngB8BLgLeBJYE5jQtwKlPrHjohel+tvgTGDVzLyp\n3/VI41XV5Twf+ERmnl0dWwp4dWbe1c/apH4wuOhFi4glMvPZftchjXfVzr6zgc8CP8jMv/S5JKlv\nDC6SVICI+CBwAhCZ+VS/65H6xeAiSYWIiKUy8+l+1yH1k8FFkiQVw11FkiSpGAYXSZJUDIOLJEkq\nhsFFkiQVY2K/C5DaJiLeCPwBuAUYBBYD7gc+mZl/epHn3AGYlpk7RMSFwE6Zef8wP3swcElm/nwh\nzj+YmZ0hr18G3Af8c2beN+T4VOC4zFyl13NJ0sKw4yL1x/2ZuVJmrpyZK9C9F803xuLEmbnxcKGl\nMpWXeKn4zHyS7tVcPzbfW58ATnkp55akkdhxkRYNVwIfBIiIu4Br6d4VeG1gI2BPun/RuAHYLTOf\nj4jtgBl071tzN/D0kM9PAx4E/g1YC5gNHApMBt4JfCciNgeeA44HXgU8C0zPzJuqrtD3gKWAa4ap\n+RTgmOpBREyheyPAfarXXwHWA14JPAxskZkPzvtwdYNOMvPL89V9L3BU9XwCcFpmHhcR/wCcCSwJ\nvAB8LjOHq03SOGXHReqziJgEbAX8YsjhizIzgNcAn6Z79+2VgIeAfSJiOeBIYB3gPcDSCzj1dLrB\n438A6wNfAv6Dbndnp8z8LXA6sF812tm5eh/gm3QDw0rz1TXUFcDLIyKq1x8CLsvMxyLircA/V3W/\nHbgd+HiPfySfBqhqWg3YLCLWpnuX5JmZ+U5gP7qBTFLL2HGR+mO5iPh19XwycB2w/5D3r61+fS/w\nNuCaKh8sBtwIrAFcnZl/BoiI79Htbgw1Ffh2Zr5At/uyQvWzVL8uBbwLOPW/swdLRcSr6HY7tq6O\nnQmcPP9vIDMHI+I0YBvgILp3Mj6ueu/2iNgb2KkKNu8B7ujpT6YbslaKiHXn1QT8L+AS4LyIWBn4\nMd1wJallDC5Sf9xfdTOG81z16wTg7Mz8HPw1bEykG1KGdkznLOAcs4e+qLog9ww5NAF4fmgd1Tjm\nUbqLhuedf5DuaGZBTgcujohvAQFcWp1nVeDfgWOBc4C5wPwLcod+B8CkIXXtl5nnVed6NfBMZj4X\nEe+gO47aCtgBeN8wdUkapxwVSYu2nwGbR8RrI6JDdz3KnsBVwOoR8YaIGKD7P/L5XQl8NCI6EfFa\nuqOdyXRDzsTMfAK4LSK2BYiI91WfgW53Y9vq+RbV5/5OZt5DNwwdApyRmfPuITIV+FlmnkB399QG\n/P2C4IeBd1TfvRqwbHX8MuDTETGpCmpXAe+OiCOB7TLzdGB3YNidS5LGL4OLtAjLzJuBg+n+z/z3\ndP+d/Wo1IppON2BcR3eB7vy+BTwD3Fz93PTqrsI/AU6IiDXorjvZKSJ+AxwObFWFj92BLavjGwMj\n3Y34VLrrT04bcuwsYMXq85cBvwHeNN/n/gN4VUTcUv1ebqqOnwDcVr2+Hjg1M39Gd9fVltWI7Xxg\n1xFqkjROeZNFSZJUDDsukiSpGAYXSZJUDIOLJEkqhsFFkiQVw+AiSZKKYXCRJEnFMLhIkqRiGFwk\nSVIx/j9ZYDHtwFGOPQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e8ee1b84a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_act,y_pred)\n",
    "class_name = ['B','M']\n",
    "print_confusion_matrix(cm,class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#se_varimp=pd.DataFrame(mod_best.varimp())\n",
    "#se_varimp.head()\n",
    "##variable\trelative_importance\tscaled_importance\tpercentage\n",
    "#se_varimp.rename(columns={0:\"variable\",1:\"relative_importance\",2:\"scaled_importance\",3:\"percentage\"}).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_set=aml_leaderboard_df['model_id']\n",
    "mod_best=h2o.get_model(model_set[16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DeepLearning_grid_0_AutoML_20181101_171828_model_0'"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep = mod_best._id\n",
    "deep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.09828394643134256: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>B</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>B</td>\n",
       "<td>267.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0074</td>\n",
       "<td> (2.0/269.0)</td></tr>\n",
       "<tr><td>M</td>\n",
       "<td>0.0</td>\n",
       "<td>148.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/148.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>267.0</td>\n",
       "<td>150.0</td>\n",
       "<td>0.0048</td>\n",
       "<td> (2.0/417.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       B    M    Error    Rate\n",
       "-----  ---  ---  -------  -----------\n",
       "B      267  2    0.0074   (2.0/269.0)\n",
       "M      0    148  0        (0.0/148.0)\n",
       "Total  267  150  0.0048   (2.0/417.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_best.confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.09828394643134256: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>B</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>B</td>\n",
       "<td>267.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0074</td>\n",
       "<td> (2.0/269.0)</td></tr>\n",
       "<tr><td>M</td>\n",
       "<td>0.0</td>\n",
       "<td>148.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/148.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>267.0</td>\n",
       "<td>150.0</td>\n",
       "<td>0.0048</td>\n",
       "<td> (2.0/417.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       B    M    Error    Rate\n",
       "-----  ---  ---  -------  -----------\n",
       "B      267  2    0.0074   (2.0/269.0)\n",
       "M      0    148  0        (0.0/148.0)\n",
       "Total  267  150  0.0048   (2.0/417.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.09828394643134256: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>B</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>B</td>\n",
       "<td>267.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0074</td>\n",
       "<td> (2.0/269.0)</td></tr>\n",
       "<tr><td>M</td>\n",
       "<td>0.0</td>\n",
       "<td>148.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/148.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>267.0</td>\n",
       "<td>150.0</td>\n",
       "<td>0.0048</td>\n",
       "<td> (2.0/417.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       B    M    Error    Rate\n",
       "-----  ---  ---  -------  -----------\n",
       "B      267  2    0.0074   (2.0/269.0)\n",
       "M      0    148  0        (0.0/148.0)\n",
       "Total  267  150  0.0048   (2.0/417.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Act/Pred) for max f0point5 @ threshold = 0.9886645951195379: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>B</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>B</td>\n",
       "<td>269.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/269.0)</td></tr>\n",
       "<tr><td>M</td>\n",
       "<td>4.0</td>\n",
       "<td>144.0</td>\n",
       "<td>0.027</td>\n",
       "<td> (4.0/148.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>273.0</td>\n",
       "<td>144.0</td>\n",
       "<td>0.0096</td>\n",
       "<td> (4.0/417.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       B    M    Error    Rate\n",
       "-----  ---  ---  -------  -----------\n",
       "B      269  0    0        (0.0/269.0)\n",
       "M      4    144  0.027    (4.0/148.0)\n",
       "Total  273  144  0.0096   (4.0/417.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.09828394643134256: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>B</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>B</td>\n",
       "<td>267.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0074</td>\n",
       "<td> (2.0/269.0)</td></tr>\n",
       "<tr><td>M</td>\n",
       "<td>0.0</td>\n",
       "<td>148.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/148.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>267.0</td>\n",
       "<td>150.0</td>\n",
       "<td>0.0048</td>\n",
       "<td> (2.0/417.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       B    M    Error    Rate\n",
       "-----  ---  ---  -------  -----------\n",
       "B      267  2    0.0074   (2.0/269.0)\n",
       "M      0    148  0        (0.0/148.0)\n",
       "Total  267  150  0.0048   (2.0/417.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Act/Pred) for max precision @ threshold = 0.9999999990311449: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>B</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>B</td>\n",
       "<td>269.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/269.0)</td></tr>\n",
       "<tr><td>M</td>\n",
       "<td>19.0</td>\n",
       "<td>129.0</td>\n",
       "<td>0.1284</td>\n",
       "<td> (19.0/148.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>288.0</td>\n",
       "<td>129.0</td>\n",
       "<td>0.0456</td>\n",
       "<td> (19.0/417.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       B    M    Error    Rate\n",
       "-----  ---  ---  -------  ------------\n",
       "B      269  0    0        (0.0/269.0)\n",
       "M      19   129  0.1284   (19.0/148.0)\n",
       "Total  288  129  0.0456   (19.0/417.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.09828394643134256: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>B</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>B</td>\n",
       "<td>267.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0074</td>\n",
       "<td> (2.0/269.0)</td></tr>\n",
       "<tr><td>M</td>\n",
       "<td>0.0</td>\n",
       "<td>148.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/148.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>267.0</td>\n",
       "<td>150.0</td>\n",
       "<td>0.0048</td>\n",
       "<td> (2.0/417.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       B    M    Error    Rate\n",
       "-----  ---  ---  -------  -----------\n",
       "B      267  2    0.0074   (2.0/269.0)\n",
       "M      0    148  0        (0.0/148.0)\n",
       "Total  267  150  0.0048   (2.0/417.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Act/Pred) for max precision @ threshold = 0.9999999990311449: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>B</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>B</td>\n",
       "<td>269.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/269.0)</td></tr>\n",
       "<tr><td>M</td>\n",
       "<td>19.0</td>\n",
       "<td>129.0</td>\n",
       "<td>0.1284</td>\n",
       "<td> (19.0/148.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>288.0</td>\n",
       "<td>129.0</td>\n",
       "<td>0.0456</td>\n",
       "<td> (19.0/417.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       B    M    Error    Rate\n",
       "-----  ---  ---  -------  ------------\n",
       "B      269  0    0        (0.0/269.0)\n",
       "M      19   129  0.1284   (19.0/148.0)\n",
       "Total  288  129  0.0456   (19.0/417.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.09828394643134256: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>B</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>B</td>\n",
       "<td>267.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0074</td>\n",
       "<td> (2.0/269.0)</td></tr>\n",
       "<tr><td>M</td>\n",
       "<td>0.0</td>\n",
       "<td>148.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/148.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>267.0</td>\n",
       "<td>150.0</td>\n",
       "<td>0.0048</td>\n",
       "<td> (2.0/417.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       B    M    Error    Rate\n",
       "-----  ---  ---  -------  -----------\n",
       "B      267  2    0.0074   (2.0/269.0)\n",
       "M      0    148  0        (0.0/148.0)\n",
       "Total  267  150  0.0048   (2.0/417.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Act/Pred) for max min_per_class_accuracy @ threshold = 0.11208374333751887: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>B</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>B</td>\n",
       "<td>267.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0074</td>\n",
       "<td> (2.0/269.0)</td></tr>\n",
       "<tr><td>M</td>\n",
       "<td>1.0</td>\n",
       "<td>147.0</td>\n",
       "<td>0.0068</td>\n",
       "<td> (1.0/148.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>268.0</td>\n",
       "<td>149.0</td>\n",
       "<td>0.0072</td>\n",
       "<td> (3.0/417.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       B    M    Error    Rate\n",
       "-----  ---  ---  -------  -----------\n",
       "B      267  2    0.0074   (2.0/269.0)\n",
       "M      1    147  0.0068   (1.0/148.0)\n",
       "Total  268  149  0.0072   (3.0/417.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.09828394643134256: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>B</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>B</td>\n",
       "<td>267.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0074</td>\n",
       "<td> (2.0/269.0)</td></tr>\n",
       "<tr><td>M</td>\n",
       "<td>0.0</td>\n",
       "<td>148.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/148.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>267.0</td>\n",
       "<td>150.0</td>\n",
       "<td>0.0048</td>\n",
       "<td> (2.0/417.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       B    M    Error    Rate\n",
       "-----  ---  ---  -------  -----------\n",
       "B      267  2    0.0074   (2.0/269.0)\n",
       "M      0    148  0        (0.0/148.0)\n",
       "Total  267  150  0.0048   (2.0/417.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[, , , , , , , , , ]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_best.confusion_matrix(metrics=[\"f1\",\"f2\",\"f0point5\",\"accuracy\",\"precision\",\"recall\",\"specificity\",\"absolute_mcc\",\"min_per_class_accuracy\",\"mean_per_class_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2ODeepLearningEstimator :  Deep Learning\n",
      "Model Key:  DeepLearning_grid_0_AutoML_20181101_171828_model_0\n",
      "\n",
      "\n",
      "ModelMetricsBinomial: deeplearning\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.007912352516752276\n",
      "RMSE: 0.0889514053669321\n",
      "LogLoss: 0.023663911885297664\n",
      "Mean Per-Class Error: 0.0037174721189591198\n",
      "AUC: 0.9998241736159952\n",
      "Gini: 0.9996483472319904\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.09828394643134256: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>B</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>B</td>\n",
       "<td>267.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0074</td>\n",
       "<td> (2.0/269.0)</td></tr>\n",
       "<tr><td>M</td>\n",
       "<td>0.0</td>\n",
       "<td>148.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/148.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>267.0</td>\n",
       "<td>150.0</td>\n",
       "<td>0.0048</td>\n",
       "<td> (2.0/417.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       B    M    Error    Rate\n",
       "-----  ---  ---  -------  -----------\n",
       "B      267  2    0.0074   (2.0/269.0)\n",
       "M      0    148  0        (0.0/148.0)\n",
       "Total  267  150  0.0048   (2.0/417.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.0982839</td>\n",
       "<td>0.9932886</td>\n",
       "<td>21.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.0982839</td>\n",
       "<td>0.9973046</td>\n",
       "<td>21.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.9886646</td>\n",
       "<td>0.9944751</td>\n",
       "<td>15.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.0982839</td>\n",
       "<td>0.9952038</td>\n",
       "<td>21.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0982839</td>\n",
       "<td>1.0</td>\n",
       "<td>21.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.0982839</td>\n",
       "<td>0.9896115</td>\n",
       "<td>21.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.1120837</td>\n",
       "<td>0.9925651</td>\n",
       "<td>20.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.0982839</td>\n",
       "<td>0.9962825</td>\n",
       "<td>21.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.0982839    0.993289  21\n",
       "max f2                       0.0982839    0.997305  21\n",
       "max f0point5                 0.988665     0.994475  15\n",
       "max accuracy                 0.0982839    0.995204  21\n",
       "max precision                1            1         0\n",
       "max recall                   0.0982839    1         21\n",
       "max specificity              1            1         0\n",
       "max absolute_mcc             0.0982839    0.989611  21\n",
       "max min_per_class_accuracy   0.112084     0.992565  20\n",
       "max mean_per_class_accuracy  0.0982839    0.996283  21"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 35.49 %, avg score: 35.28 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.2326139</td>\n",
       "<td>1.0</td>\n",
       "<td>2.8175676</td>\n",
       "<td>2.8175676</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.6554054</td>\n",
       "<td>0.6554054</td>\n",
       "<td>181.7567568</td>\n",
       "<td>181.7567568</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.2997602</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.8175676</td>\n",
       "<td>2.8175676</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.1891892</td>\n",
       "<td>0.8445946</td>\n",
       "<td>181.7567568</td>\n",
       "<td>181.7567568</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.4004796</td>\n",
       "<td>0.0017456</td>\n",
       "<td>1.5429537</td>\n",
       "<td>2.4970060</td>\n",
       "<td>0.5476190</td>\n",
       "<td>0.5266650</td>\n",
       "<td>0.8862275</td>\n",
       "<td>0.8809577</td>\n",
       "<td>0.1554054</td>\n",
       "<td>1.0</td>\n",
       "<td>54.2953668</td>\n",
       "<td>149.7005988</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.5011990</td>\n",
       "<td>0.0000003</td>\n",
       "<td>0.0</td>\n",
       "<td>1.9952153</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001351</td>\n",
       "<td>0.7081340</td>\n",
       "<td>0.7039503</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>99.5215311</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.5995204</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.668</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.592</td>\n",
       "<td>0.5885024</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.8</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.7002398</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4280822</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.5068493</td>\n",
       "<td>0.5038548</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.8082192</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.7985612</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2522523</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.4444444</td>\n",
       "<td>0.4418186</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.2252252</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.8992806</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1120000</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.3946667</td>\n",
       "<td>0.3923349</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.2000000</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.3549161</td>\n",
       "<td>0.3528192</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain\n",
       "--  -------  --------------------------  -----------------  -------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------\n",
       "    1        0.232614                    1                  2.81757  2.81757            1                1            1                           1                   0.655405        0.655405                   181.757  181.757\n",
       "    2        0.29976                     1                  2.81757  2.81757            1                1            1                           1                   0.189189        0.844595                   181.757  181.757\n",
       "    3        0.40048                     0.00174565         1.54295  2.49701            0.547619         0.526665     0.886228                    0.880958            0.155405        1                          54.2954  149.701\n",
       "    4        0.501199                    2.92342e-07        0        1.99522            0                0.000135133  0.708134                    0.70395             0               1                          -100     99.5215\n",
       "    5        0.59952                     5.13315e-10        0        1.668              0                2.26632e-08  0.592                       0.588502            0               1                          -100     66.8\n",
       "    6        0.70024                     6.49623e-12        0        1.42808            0                9.98717e-11  0.506849                    0.503855            0               1                          -100     42.8082\n",
       "    7        0.798561                    8.89369e-14        0        1.25225            0                1.53902e-12  0.444444                    0.441819            0               1                          -100     25.2252\n",
       "    8        0.899281                    3.76223e-16        0        1.112              0                1.4373e-14   0.394667                    0.392335            0               1                          -100     11.2\n",
       "    9        1                           9.30926e-22        0        1                  0                7.17485e-17  0.354916                    0.352819            0               1                          -100     0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: deeplearning\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 0.0006555664485382642\n",
      "RMSE: 0.02560403188051179\n",
      "LogLoss: 0.004296450984575728\n",
      "Mean Per-Class Error: 0.0\n",
      "AUC: 1.0\n",
      "Gini: 1.0\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.8826736770234279: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>B</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>B</td>\n",
       "<td>53.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/53.0)</td></tr>\n",
       "<tr><td>M</td>\n",
       "<td>0.0</td>\n",
       "<td>41.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/41.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>53.0</td>\n",
       "<td>41.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/94.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       B    M    Error    Rate\n",
       "-----  ---  ---  -------  ----------\n",
       "B      53   0    0        (0.0/53.0)\n",
       "M      0    41   0        (0.0/41.0)\n",
       "Total  53   41   0        (0.0/94.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.8826737</td>\n",
       "<td>1.0</td>\n",
       "<td>6.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.8826737</td>\n",
       "<td>1.0</td>\n",
       "<td>6.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.8826737</td>\n",
       "<td>1.0</td>\n",
       "<td>6.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.8826737</td>\n",
       "<td>1.0</td>\n",
       "<td>6.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.8826737</td>\n",
       "<td>1.0</td>\n",
       "<td>6.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.8826737</td>\n",
       "<td>1.0</td>\n",
       "<td>6.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.8826737</td>\n",
       "<td>1.0</td>\n",
       "<td>6.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.8826737</td>\n",
       "<td>1.0</td>\n",
       "<td>6.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value    idx\n",
       "---------------------------  -----------  -------  -----\n",
       "max f1                       0.882674     1        6\n",
       "max f2                       0.882674     1        6\n",
       "max f0point5                 0.882674     1        6\n",
       "max accuracy                 0.882674     1        6\n",
       "max precision                1            1        0\n",
       "max recall                   0.882674     1        6\n",
       "max specificity              1            1        0\n",
       "max absolute_mcc             0.882674     1        6\n",
       "max min_per_class_accuracy   0.882674     1        6\n",
       "max mean_per_class_accuracy  0.882674     1        6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 43.62 %, avg score: 43.76 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.2021277</td>\n",
       "<td>1.0</td>\n",
       "<td>2.2926829</td>\n",
       "<td>2.2926829</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.4634146</td>\n",
       "<td>0.4634146</td>\n",
       "<td>129.2682927</td>\n",
       "<td>129.2682927</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.2021277</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>2.2926829</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4634146</td>\n",
       "<td>-100.0</td>\n",
       "<td>129.2682927</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.2978723</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.2926829</td>\n",
       "<td>2.2926829</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.2195122</td>\n",
       "<td>0.6829268</td>\n",
       "<td>129.2682927</td>\n",
       "<td>129.2682927</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.4042553</td>\n",
       "<td>0.9998401</td>\n",
       "<td>2.2926829</td>\n",
       "<td>2.2926829</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999891</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999971</td>\n",
       "<td>0.2439024</td>\n",
       "<td>0.9268293</td>\n",
       "<td>129.2682927</td>\n",
       "<td>129.2682927</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0010950</td>\n",
       "<td>0.7642276</td>\n",
       "<td>2.0</td>\n",
       "<td>0.3333333</td>\n",
       "<td>0.3476743</td>\n",
       "<td>0.8723404</td>\n",
       "<td>0.8750843</td>\n",
       "<td>0.0731707</td>\n",
       "<td>1.0</td>\n",
       "<td>-23.5772358</td>\n",
       "<td>100.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.5957447</td>\n",
       "<td>0.0000003</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6785714</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000917</td>\n",
       "<td>0.7321429</td>\n",
       "<td>0.7344604</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>67.8571429</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.7021277</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4242424</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000001</td>\n",
       "<td>0.6212121</td>\n",
       "<td>0.6231786</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.4242424</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.7978723</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2533333</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.5466667</td>\n",
       "<td>0.5483971</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.3333333</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.8936170</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1190476</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.4880952</td>\n",
       "<td>0.4896403</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.9047619</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.4361702</td>\n",
       "<td>0.4375509</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  --------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.202128                    1                  2.29268   2.29268            1                1            1                           1                   0.463415        0.463415                   129.268   129.268\n",
       "    2        0.202128                    1                  0         2.29268            0                0            1                           1                   0               0.463415                   -100      129.268\n",
       "    3        0.297872                    1                  2.29268   2.29268            1                1            1                           1                   0.219512        0.682927                   129.268   129.268\n",
       "    4        0.404255                    0.99984            2.29268   2.29268            1                0.999989     1                           0.999997            0.243902        0.926829                   129.268   129.268\n",
       "    5        0.5                         0.00109501         0.764228  2                  0.333333         0.347674     0.87234                     0.875084            0.0731707       1                          -23.5772  100\n",
       "    6        0.595745                    3.43084e-07        0         1.67857            0                9.16873e-05  0.732143                    0.73446             0               1                          -100      67.8571\n",
       "    7        0.702128                    1.65458e-09        0         1.42424            0                7.35627e-08  0.621212                    0.623179            0               1                          -100      42.4242\n",
       "    8        0.797872                    1.57629e-12        0         1.25333            0                1.02446e-10  0.546667                    0.548397            0               1                          -100      25.3333\n",
       "    9        0.893617                    5.58958e-16        0         1.11905            0                2.43815e-13  0.488095                    0.48964             0               1                          -100      11.9048\n",
       "    10       1                           3.64765e-30        0         1                  0                8.38995e-17  0.43617                     0.437551            0               1                          -100      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: deeplearning\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.02355217550764335\n",
      "RMSE: 0.15346718055546388\n",
      "LogLoss: 0.23519699822060325\n",
      "Mean Per-Class Error: 0.024326836129810125\n",
      "AUC: 0.9908821460866071\n",
      "Gini: 0.9817642921732141\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.8636782443690625: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>B</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>B</td>\n",
       "<td>265.0</td>\n",
       "<td>4.0</td>\n",
       "<td>0.0149</td>\n",
       "<td> (4.0/269.0)</td></tr>\n",
       "<tr><td>M</td>\n",
       "<td>5.0</td>\n",
       "<td>143.0</td>\n",
       "<td>0.0338</td>\n",
       "<td> (5.0/148.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>270.0</td>\n",
       "<td>147.0</td>\n",
       "<td>0.0216</td>\n",
       "<td> (9.0/417.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       B    M    Error    Rate\n",
       "-----  ---  ---  -------  -----------\n",
       "B      265  4    0.0149   (4.0/269.0)\n",
       "M      5    143  0.0338   (5.0/148.0)\n",
       "Total  270  147  0.0216   (9.0/417.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.8636782</td>\n",
       "<td>0.9694915</td>\n",
       "<td>18.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.0197879</td>\n",
       "<td>0.9692513</td>\n",
       "<td>27.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.9985876</td>\n",
       "<td>0.9801136</td>\n",
       "<td>10.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.9769969</td>\n",
       "<td>0.9784173</td>\n",
       "<td>16.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>269.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.8636782</td>\n",
       "<td>0.9528073</td>\n",
       "<td>18.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.1327100</td>\n",
       "<td>0.9665428</td>\n",
       "<td>24.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.8636782</td>\n",
       "<td>0.9756732</td>\n",
       "<td>18.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.863678     0.969492  18\n",
       "max f2                       0.0197879    0.969251  27\n",
       "max f0point5                 0.998588     0.980114  10\n",
       "max accuracy                 0.976997     0.978417  16\n",
       "max precision                1            1         0\n",
       "max recall                   5.02928e-27  1         269\n",
       "max specificity              1            1         0\n",
       "max absolute_mcc             0.863678     0.952807  18\n",
       "max min_per_class_accuracy   0.13271      0.966543  24\n",
       "max mean_per_class_accuracy  0.863678     0.975673  18"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 35.49 %, avg score: 35.81 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.2517986</td>\n",
       "<td>1.0</td>\n",
       "<td>2.8175676</td>\n",
       "<td>2.8175676</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.7094595</td>\n",
       "<td>0.7094595</td>\n",
       "<td>181.7567568</td>\n",
       "<td>181.7567568</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.2997602</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.8175676</td>\n",
       "<td>2.8175676</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.1351351</td>\n",
       "<td>0.8445946</td>\n",
       "<td>181.7567568</td>\n",
       "<td>181.7567568</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.4004796</td>\n",
       "<td>0.0005083</td>\n",
       "<td>1.3416988</td>\n",
       "<td>2.4463910</td>\n",
       "<td>0.4761905</td>\n",
       "<td>0.5792734</td>\n",
       "<td>0.8682635</td>\n",
       "<td>0.8941885</td>\n",
       "<td>0.1351351</td>\n",
       "<td>0.9797297</td>\n",
       "<td>34.1698842</td>\n",
       "<td>144.6391002</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.5011990</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.1341699</td>\n",
       "<td>1.9817341</td>\n",
       "<td>0.0476190</td>\n",
       "<td>0.0000333</td>\n",
       "<td>0.7033493</td>\n",
       "<td>0.7145018</td>\n",
       "<td>0.0135135</td>\n",
       "<td>0.9932432</td>\n",
       "<td>-86.5830116</td>\n",
       "<td>98.1734126</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.5995204</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6567297</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.588</td>\n",
       "<td>0.5973235</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9932432</td>\n",
       "<td>-100.0</td>\n",
       "<td>65.6729730</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.7002398</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4184330</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.5034247</td>\n",
       "<td>0.5114071</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9932432</td>\n",
       "<td>-100.0</td>\n",
       "<td>41.8432988</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.7985612</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2437911</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.4414414</td>\n",
       "<td>0.4484411</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9932432</td>\n",
       "<td>-100.0</td>\n",
       "<td>24.3791088</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.8992806</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1044865</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.392</td>\n",
       "<td>0.3982157</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9932432</td>\n",
       "<td>-100.0</td>\n",
       "<td>10.4486486</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0670849</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0238095</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.3549161</td>\n",
       "<td>0.3581076</td>\n",
       "<td>0.0067568</td>\n",
       "<td>1.0</td>\n",
       "<td>-93.2915058</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.251799                    1                  2.81757    2.81757            1                1            1                           1                   0.709459        0.709459                   181.757   181.757\n",
       "    2        0.29976                     1                  2.81757    2.81757            1                1            1                           1                   0.135135        0.844595                   181.757   181.757\n",
       "    3        0.40048                     0.000508335        1.3417     2.44639            0.47619          0.579273     0.868263                    0.894189            0.135135        0.97973                    34.1699   144.639\n",
       "    4        0.501199                    1.68179e-09        0.13417    1.98173            0.047619         3.32801e-05  0.703349                    0.714502            0.0135135       0.993243                   -86.583   98.1734\n",
       "    5        0.59952                     3.63361e-12        0          1.65673            0                1.72554e-10  0.588                       0.597324            0               0.993243                   -100      65.673\n",
       "    6        0.70024                     3.1579e-15         0          1.41843            0                6.08128e-13  0.503425                    0.511407            0               0.993243                   -100      41.8433\n",
       "    7        0.798561                    1.59977e-17        0          1.24379            0                5.98786e-16  0.441441                    0.448441            0               0.993243                   -100      24.3791\n",
       "    8        0.899281                    9.23947e-22        0          1.10449            0                2.07673e-18  0.392                       0.398216            0               0.993243                   -100      10.4486\n",
       "    9        1                           1.79315e-36        0.0670849  1                  0.0238095        5.29136e-23  0.354916                    0.358108            0.00675676      1                          -93.2915  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>mean</b></td>\n",
       "<td><b>sd</b></td>\n",
       "<td><b>cv_1_valid</b></td>\n",
       "<td><b>cv_2_valid</b></td>\n",
       "<td><b>cv_3_valid</b></td>\n",
       "<td><b>cv_4_valid</b></td>\n",
       "<td><b>cv_5_valid</b></td></tr>\n",
       "<tr><td>accuracy</td>\n",
       "<td>0.9856282</td>\n",
       "<td>0.0063378</td>\n",
       "<td>0.9761905</td>\n",
       "<td>0.9880952</td>\n",
       "<td>0.9879518</td>\n",
       "<td>0.9759036</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.9917383</td>\n",
       "<td>0.0077355</td>\n",
       "<td>0.9964706</td>\n",
       "<td>0.9701389</td>\n",
       "<td>0.9974843</td>\n",
       "<td>0.9945979</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.0143718</td>\n",
       "<td>0.0063378</td>\n",
       "<td>0.0238095</td>\n",
       "<td>0.0119048</td>\n",
       "<td>0.0120482</td>\n",
       "<td>0.0240964</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>1.2</td>\n",
       "<td>0.5291503</td>\n",
       "<td>2.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>0.9851413</td>\n",
       "<td>0.0086454</td>\n",
       "<td>0.9705882</td>\n",
       "<td>0.9913793</td>\n",
       "<td>0.9931507</td>\n",
       "<td>0.9705882</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>0.9805902</td>\n",
       "<td>0.0076574</td>\n",
       "<td>0.9705882</td>\n",
       "<td>0.9787234</td>\n",
       "<td>0.9830508</td>\n",
       "<td>0.9705882</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>0.9761435</td>\n",
       "<td>0.0085731</td>\n",
       "<td>0.9705882</td>\n",
       "<td>0.9663866</td>\n",
       "<td>0.9731544</td>\n",
       "<td>0.9705882</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>2.874148</td>\n",
       "<td>0.2923685</td>\n",
       "<td>2.4705882</td>\n",
       "<td>3.5</td>\n",
       "<td>2.7666667</td>\n",
       "<td>2.4411764</td>\n",
       "<td>3.1923077</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>0.2281309</td>\n",
       "<td>0.1315110</td>\n",
       "<td>0.1897195</td>\n",
       "<td>0.574412</td>\n",
       "<td>0.1465594</td>\n",
       "<td>0.2132317</td>\n",
       "<td>0.0167322</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.0267647</td>\n",
       "<td>0.0099779</td>\n",
       "<td>0.0294118</td>\n",
       "<td>0.0416667</td>\n",
       "<td>0.0333333</td>\n",
       "<td>0.0294118</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.9691404</td>\n",
       "<td>0.0129735</td>\n",
       "<td>0.9505882</td>\n",
       "<td>0.9708877</td>\n",
       "<td>0.9740459</td>\n",
       "<td>0.9501801</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.9825768</td>\n",
       "<td>0.0065181</td>\n",
       "<td>0.9752941</td>\n",
       "<td>0.9791667</td>\n",
       "<td>0.9833333</td>\n",
       "<td>0.97509</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.0174232</td>\n",
       "<td>0.0065181</td>\n",
       "<td>0.0247059</td>\n",
       "<td>0.0208333</td>\n",
       "<td>0.0166667</td>\n",
       "<td>0.0249100</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.0227571</td>\n",
       "<td>0.0070228</td>\n",
       "<td>0.0290988</td>\n",
       "<td>0.0356591</td>\n",
       "<td>0.0206193</td>\n",
       "<td>0.0224396</td>\n",
       "<td>0.0059687</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.9882353</td>\n",
       "<td>0.0101885</td>\n",
       "<td>0.9705882</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9705882</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.8989244</td>\n",
       "<td>0.0337593</td>\n",
       "<td>0.8792228</td>\n",
       "<td>0.8252705</td>\n",
       "<td>0.9106626</td>\n",
       "<td>0.9072111</td>\n",
       "<td>0.972255</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.9732353</td>\n",
       "<td>0.0099779</td>\n",
       "<td>0.9705882</td>\n",
       "<td>0.9583333</td>\n",
       "<td>0.9666666</td>\n",
       "<td>0.9705882</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.1460139</td>\n",
       "<td>0.0268050</td>\n",
       "<td>0.1705837</td>\n",
       "<td>0.1888361</td>\n",
       "<td>0.1435943</td>\n",
       "<td>0.1497985</td>\n",
       "<td>0.0772571</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.9919184</td>\n",
       "<td>0.0069995</td>\n",
       "<td>0.98</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9795919</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "                         mean       sd          cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "-----------------------  ---------  ----------  ------------  ------------  ------------  ------------  ------------\n",
       "accuracy                 0.985628   0.00633776  0.97619       0.988095      0.987952      0.975904      1\n",
       "auc                      0.991738   0.00773549  0.996471      0.970139      0.997484      0.994598      1\n",
       "err                      0.0143718  0.00633776  0.0238095     0.0119048     0.0120482     0.0240964     0\n",
       "err_count                1.2        0.52915     2             1             1             2             0\n",
       "f0point5                 0.985141   0.00864539  0.970588      0.991379      0.993151      0.970588      1\n",
       "f1                       0.98059    0.00765741  0.970588      0.978723      0.983051      0.970588      1\n",
       "f2                       0.976144   0.00857314  0.970588      0.966387      0.973154      0.970588      1\n",
       "lift_top_group           2.87415    0.292368    2.47059       3.5           2.76667       2.44118       3.19231\n",
       "logloss                  0.228131   0.131511    0.189719      0.574412      0.146559      0.213232      0.0167322\n",
       "max_per_class_error      0.0267647  0.00997787  0.0294118     0.0416667     0.0333333     0.0294118     0\n",
       "mcc                      0.96914    0.0129735   0.950588      0.970888      0.974046      0.95018       1\n",
       "mean_per_class_accuracy  0.982577   0.00651812  0.975294      0.979167      0.983333      0.97509       1\n",
       "mean_per_class_error     0.0174232  0.00651812  0.0247059     0.0208333     0.0166667     0.02491       0\n",
       "mse                      0.0227571  0.00702283  0.0290988     0.0356591     0.0206193     0.0224396     0.00596865\n",
       "precision                0.988235   0.0101885   0.970588      1             1             0.970588      1\n",
       "r2                       0.898924   0.0337593   0.879223      0.825271      0.910663      0.907211      0.972255\n",
       "recall                   0.973235   0.00997787  0.970588      0.958333      0.966667      0.970588      1\n",
       "rmse                     0.146014   0.026805    0.170584      0.188836      0.143594      0.149798      0.0772571\n",
       "specificity              0.991918   0.00699949  0.98          1             1             0.979592      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>training_speed</b></td>\n",
       "<td><b>epochs</b></td>\n",
       "<td><b>iterations</b></td>\n",
       "<td><b>samples</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_r2</b></td>\n",
       "<td><b>training_auc</b></td>\n",
       "<td><b>training_lift</b></td>\n",
       "<td><b>training_classification_error</b></td>\n",
       "<td><b>validation_rmse</b></td>\n",
       "<td><b>validation_logloss</b></td>\n",
       "<td><b>validation_r2</b></td>\n",
       "<td><b>validation_auc</b></td>\n",
       "<td><b>validation_lift</b></td>\n",
       "<td><b>validation_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-11-01 17:23:37</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-11-01 17:23:38</td>\n",
       "<td> 2 min  5.420 sec</td>\n",
       "<td>5366 obs/sec</td>\n",
       "<td>10.0</td>\n",
       "<td>1</td>\n",
       "<td>4170.0</td>\n",
       "<td>0.1173761</td>\n",
       "<td>0.0728845</td>\n",
       "<td>0.9398248</td>\n",
       "<td>0.9955290</td>\n",
       "<td>2.8175676</td>\n",
       "<td>0.0095923</td>\n",
       "<td>0.1098395</td>\n",
       "<td>0.0710273</td>\n",
       "<td>0.9509416</td>\n",
       "<td>0.9958583</td>\n",
       "<td>2.2926829</td>\n",
       "<td>0.0106383</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-11-01 17:23:43</td>\n",
       "<td> 2 min 10.689 sec</td>\n",
       "<td>5545 obs/sec</td>\n",
       "<td>80.0</td>\n",
       "<td>8</td>\n",
       "<td>33360.0</td>\n",
       "<td>0.0970624</td>\n",
       "<td>0.0628371</td>\n",
       "<td>0.9588509</td>\n",
       "<td>0.9978398</td>\n",
       "<td>2.8175676</td>\n",
       "<td>0.0095923</td>\n",
       "<td>0.0193484</td>\n",
       "<td>0.0041687</td>\n",
       "<td>0.9984778</td>\n",
       "<td>1.0</td>\n",
       "<td>2.2926829</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-11-01 17:23:49</td>\n",
       "<td> 2 min 15.965 sec</td>\n",
       "<td>5558 obs/sec</td>\n",
       "<td>150.0</td>\n",
       "<td>15</td>\n",
       "<td>62550.0</td>\n",
       "<td>0.1035580</td>\n",
       "<td>0.0498601</td>\n",
       "<td>0.9531591</td>\n",
       "<td>0.9987692</td>\n",
       "<td>2.8175676</td>\n",
       "<td>0.0119904</td>\n",
       "<td>0.0302904</td>\n",
       "<td>0.0058523</td>\n",
       "<td>0.9962692</td>\n",
       "<td>1.0</td>\n",
       "<td>2.2926829</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-11-01 17:23:54</td>\n",
       "<td> 2 min 21.152 sec</td>\n",
       "<td>5591 obs/sec</td>\n",
       "<td>220.0</td>\n",
       "<td>22</td>\n",
       "<td>91740.0</td>\n",
       "<td>0.0969616</td>\n",
       "<td>0.0371383</td>\n",
       "<td>0.9589363</td>\n",
       "<td>0.9991962</td>\n",
       "<td>2.8175676</td>\n",
       "<td>0.0095923</td>\n",
       "<td>0.0350589</td>\n",
       "<td>0.0062419</td>\n",
       "<td>0.9950020</td>\n",
       "<td>1.0</td>\n",
       "<td>2.2926829</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-11-01 17:23:59</td>\n",
       "<td> 2 min 26.817 sec</td>\n",
       "<td>5675 obs/sec</td>\n",
       "<td>300.0</td>\n",
       "<td>30</td>\n",
       "<td>125100.0</td>\n",
       "<td>0.1012699</td>\n",
       "<td>0.0625070</td>\n",
       "<td>0.9552061</td>\n",
       "<td>0.9991711</td>\n",
       "<td>2.8175676</td>\n",
       "<td>0.0095923</td>\n",
       "<td>0.0287745</td>\n",
       "<td>0.0046420</td>\n",
       "<td>0.9966332</td>\n",
       "<td>1.0</td>\n",
       "<td>2.2926829</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-11-01 17:24:04</td>\n",
       "<td> 2 min 31.766 sec</td>\n",
       "<td>5722 obs/sec</td>\n",
       "<td>370.0</td>\n",
       "<td>37</td>\n",
       "<td>154290.0</td>\n",
       "<td>0.0889514</td>\n",
       "<td>0.0236639</td>\n",
       "<td>0.9654408</td>\n",
       "<td>0.9998242</td>\n",
       "<td>2.8175676</td>\n",
       "<td>0.0047962</td>\n",
       "<td>0.0256040</td>\n",
       "<td>0.0042965</td>\n",
       "<td>0.9973343</td>\n",
       "<td>1.0</td>\n",
       "<td>2.2926829</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_lift    validation_classification_error\n",
       "--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -----------------  ---------------------------------\n",
       "    2018-11-01 17:23:37  0.000 sec                           0         0             0          nan              nan                 nan            nan             nan              nan                              nan                nan                   nan              nan               nan                nan\n",
       "    2018-11-01 17:23:38  2 min  5.420 sec  5366 obs/sec      10        1             4170       0.117376         0.0728845           0.939825       0.995529        2.81757          0.00959233                       0.10984            0.0710273             0.950942         0.995858          2.29268            0.0106383\n",
       "    2018-11-01 17:23:43  2 min 10.689 sec  5545 obs/sec      80        8             33360      0.0970624        0.0628371           0.958851       0.99784         2.81757          0.00959233                       0.0193484          0.00416865            0.998478         1                 2.29268            0\n",
       "    2018-11-01 17:23:49  2 min 15.965 sec  5558 obs/sec      150       15            62550      0.103558         0.0498601           0.953159       0.998769        2.81757          0.0119904                        0.0302904          0.00585232            0.996269         1                 2.29268            0\n",
       "    2018-11-01 17:23:54  2 min 21.152 sec  5591 obs/sec      220       22            91740      0.0969616        0.0371383           0.958936       0.999196        2.81757          0.00959233                       0.0350589          0.00624191            0.995002         1                 2.29268            0\n",
       "    2018-11-01 17:23:59  2 min 26.817 sec  5675 obs/sec      300       30            125100     0.10127          0.062507            0.955206       0.999171        2.81757          0.00959233                       0.0287745          0.00464204            0.996633         1                 2.29268            0\n",
       "    2018-11-01 17:24:04  2 min 31.766 sec  5722 obs/sec      370       37            154290     0.0889514        0.0236639           0.965441       0.999824        2.81757          0.00479616                       0.025604           0.00429645            0.997334         1                 2.29268            0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>concave points_mean</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0445672</td></tr>\n",
       "<tr><td>area_se</td>\n",
       "<td>0.9952375</td>\n",
       "<td>0.9952375</td>\n",
       "<td>0.0443550</td></tr>\n",
       "<tr><td>perimeter_worst</td>\n",
       "<td>0.9751168</td>\n",
       "<td>0.9751168</td>\n",
       "<td>0.0434583</td></tr>\n",
       "<tr><td>radius_worst</td>\n",
       "<td>0.8804989</td>\n",
       "<td>0.8804989</td>\n",
       "<td>0.0392414</td></tr>\n",
       "<tr><td>texture_worst</td>\n",
       "<td>0.8079737</td>\n",
       "<td>0.8079737</td>\n",
       "<td>0.0360092</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>concavity_se</td>\n",
       "<td>0.6504522</td>\n",
       "<td>0.6504522</td>\n",
       "<td>0.0289889</td></tr>\n",
       "<tr><td>compactness_mean</td>\n",
       "<td>0.6464164</td>\n",
       "<td>0.6464164</td>\n",
       "<td>0.0288090</td></tr>\n",
       "<tr><td>compactness_worst</td>\n",
       "<td>0.6448309</td>\n",
       "<td>0.6448309</td>\n",
       "<td>0.0287383</td></tr>\n",
       "<tr><td>concave points_worst</td>\n",
       "<td>0.6445645</td>\n",
       "<td>0.6445645</td>\n",
       "<td>0.0287265</td></tr>\n",
       "<tr><td>symmetry_worst</td>\n",
       "<td>0.6232811</td>\n",
       "<td>0.6232811</td>\n",
       "<td>0.0277779</td></tr></table></div>"
      ],
      "text/plain": [
       "variable              relative_importance    scaled_importance    percentage\n",
       "--------------------  ---------------------  -------------------  --------------------\n",
       "concave points_mean   1.0                    1.0                  0.04456724270248423\n",
       "area_se               0.9952374696731567     0.9952374696731567   0.044354989857529864\n",
       "perimeter_worst       0.9751168489456177     0.9751168489456177   0.043458269270241\n",
       "radius_worst          0.8804989457130432     0.8804989457130432   0.03924141021287469\n",
       "texture_worst         0.8079737424850464     0.8079737424850464   0.03600916187856556\n",
       "---                   ---                    ---                  ---\n",
       "concavity_se          0.650452196598053      0.650452196598053    0.028988860912149417\n",
       "compactness_mean      0.646416425704956      0.646416425704956    0.028808997731265145\n",
       "compactness_worst     0.6448308825492859     0.6448308825492859   0.028738334444631128\n",
       "concave points_worst  0.6445645093917847     0.6445645093917847   0.028726462927471344\n",
       "symmetry_worst        0.6232810616493225     0.6232810616493225   0.027777918346387393"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n",
      "<bound method ModelBase.coef_norm of >\n"
     ]
    }
   ],
   "source": [
    "mod_best._get_metrics\n",
    "type(mod_best)\n",
    "mods=mod_best.coef_norm\n",
    "print(mods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gain Lift Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deep_gain_lift = mod_best.gains_lift().as_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.232614</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.817568</td>\n",
       "      <td>2.817568</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.655405</td>\n",
       "      <td>0.655405</td>\n",
       "      <td>181.756757</td>\n",
       "      <td>181.756757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0.299760</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.817568</td>\n",
       "      <td>2.817568</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.189189</td>\n",
       "      <td>0.844595</td>\n",
       "      <td>181.756757</td>\n",
       "      <td>181.756757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>0.400480</td>\n",
       "      <td>1.745649e-03</td>\n",
       "      <td>1.542954</td>\n",
       "      <td>2.497006</td>\n",
       "      <td>0.547619</td>\n",
       "      <td>5.266650e-01</td>\n",
       "      <td>0.886228</td>\n",
       "      <td>0.880958</td>\n",
       "      <td>0.155405</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>54.295367</td>\n",
       "      <td>149.700599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.501199</td>\n",
       "      <td>2.923415e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.995215</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.351329e-04</td>\n",
       "      <td>0.708134</td>\n",
       "      <td>0.703950</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>99.521531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>0.599520</td>\n",
       "      <td>5.133153e-10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.668000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.266321e-08</td>\n",
       "      <td>0.592000</td>\n",
       "      <td>0.588502</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>66.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>0.700240</td>\n",
       "      <td>6.496233e-12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.428082</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.987166e-11</td>\n",
       "      <td>0.506849</td>\n",
       "      <td>0.503855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>42.808219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>0.798561</td>\n",
       "      <td>8.893689e-14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.252252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.539017e-12</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.441819</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>25.225225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "      <td>0.899281</td>\n",
       "      <td>3.762232e-16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.112000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.437304e-14</td>\n",
       "      <td>0.394667</td>\n",
       "      <td>0.392335</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>11.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.309256e-22</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.174851e-17</td>\n",
       "      <td>0.354916</td>\n",
       "      <td>0.352819</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0        1                  0.232614     1.000000e+00  2.817568   \n",
       "1        2                  0.299760     1.000000e+00  2.817568   \n",
       "2        3                  0.400480     1.745649e-03  1.542954   \n",
       "3        4                  0.501199     2.923415e-07  0.000000   \n",
       "4        5                  0.599520     5.133153e-10  0.000000   \n",
       "5        6                  0.700240     6.496233e-12  0.000000   \n",
       "6        7                  0.798561     8.893689e-14  0.000000   \n",
       "7        8                  0.899281     3.762232e-16  0.000000   \n",
       "8        9                  1.000000     9.309256e-22  0.000000   \n",
       "\n",
       "   cumulative_lift  response_rate         score  cumulative_response_rate  \\\n",
       "0         2.817568       1.000000  1.000000e+00                  1.000000   \n",
       "1         2.817568       1.000000  1.000000e+00                  1.000000   \n",
       "2         2.497006       0.547619  5.266650e-01                  0.886228   \n",
       "3         1.995215       0.000000  1.351329e-04                  0.708134   \n",
       "4         1.668000       0.000000  2.266321e-08                  0.592000   \n",
       "5         1.428082       0.000000  9.987166e-11                  0.506849   \n",
       "6         1.252252       0.000000  1.539017e-12                  0.444444   \n",
       "7         1.112000       0.000000  1.437304e-14                  0.394667   \n",
       "8         1.000000       0.000000  7.174851e-17                  0.354916   \n",
       "\n",
       "   cumulative_score  capture_rate  cumulative_capture_rate        gain  \\\n",
       "0          1.000000      0.655405                 0.655405  181.756757   \n",
       "1          1.000000      0.189189                 0.844595  181.756757   \n",
       "2          0.880958      0.155405                 1.000000   54.295367   \n",
       "3          0.703950      0.000000                 1.000000 -100.000000   \n",
       "4          0.588502      0.000000                 1.000000 -100.000000   \n",
       "5          0.503855      0.000000                 1.000000 -100.000000   \n",
       "6          0.441819      0.000000                 1.000000 -100.000000   \n",
       "7          0.392335      0.000000                 1.000000 -100.000000   \n",
       "8          0.352819      0.000000                 1.000000 -100.000000   \n",
       "\n",
       "   cumulative_gain  \n",
       "0       181.756757  \n",
       "1       181.756757  \n",
       "2       149.700599  \n",
       "3        99.521531  \n",
       "4        66.800000  \n",
       "5        42.808219  \n",
       "6        25.225225  \n",
       "7        11.200000  \n",
       "8         0.000000  "
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_gain_lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning prediction progress: |███████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>predict  </th><th style=\"text-align: right;\">          B</th><th style=\"text-align: right;\">         M</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>M        </td><td style=\"text-align: right;\">3.1833e-18 </td><td style=\"text-align: right;\">1         </td></tr>\n",
       "<tr><td>M        </td><td style=\"text-align: right;\">1.62028e-15</td><td style=\"text-align: right;\">1         </td></tr>\n",
       "<tr><td>M        </td><td style=\"text-align: right;\">1.45922e-16</td><td style=\"text-align: right;\">1         </td></tr>\n",
       "<tr><td>M        </td><td style=\"text-align: right;\">1.01906e-27</td><td style=\"text-align: right;\">1         </td></tr>\n",
       "<tr><td>M        </td><td style=\"text-align: right;\">8.40619e-24</td><td style=\"text-align: right;\">1         </td></tr>\n",
       "<tr><td>B        </td><td style=\"text-align: right;\">0.978514   </td><td style=\"text-align: right;\">0.0214856 </td></tr>\n",
       "<tr><td>M        </td><td style=\"text-align: right;\">9.09322e-06</td><td style=\"text-align: right;\">0.999991  </td></tr>\n",
       "<tr><td>M        </td><td style=\"text-align: right;\">2.95068e-07</td><td style=\"text-align: right;\">1         </td></tr>\n",
       "<tr><td>B        </td><td style=\"text-align: right;\">0.996478   </td><td style=\"text-align: right;\">0.00352155</td></tr>\n",
       "<tr><td>M        </td><td style=\"text-align: right;\">1.17582e-17</td><td style=\"text-align: right;\">1         </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_predictions_df=predictions_test(mod_best,test,run_id)\n",
    "deep_predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:58\n",
      "Cols:3\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th>predict  </th><th>B                   </th><th>M                    </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>type   </td><td>enum     </td><td>real                </td><td>real                 </td></tr>\n",
       "<tr><td>mins   </td><td>         </td><td>0.002075135266529693</td><td>0.0010468100665216112</td></tr>\n",
       "<tr><td>mean   </td><td>         </td><td>0.6217691021177613  </td><td>0.3782308978822388   </td></tr>\n",
       "<tr><td>maxs   </td><td>         </td><td>0.9989531899334784  </td><td>0.9979248647334703   </td></tr>\n",
       "<tr><td>sigma  </td><td>         </td><td>0.4633146893404552  </td><td>0.4633146893404552   </td></tr>\n",
       "<tr><td>zeros  </td><td>         </td><td>0                   </td><td>0                    </td></tr>\n",
       "<tr><td>missing</td><td>0        </td><td>0                   </td><td>0                    </td></tr>\n",
       "<tr><td>0      </td><td>M        </td><td>0.025421766189176354</td><td>0.9745782338108236   </td></tr>\n",
       "<tr><td>1      </td><td>M        </td><td>0.003644810067294002</td><td>0.996355189932706    </td></tr>\n",
       "<tr><td>2      </td><td>M        </td><td>0.013119387444179398</td><td>0.9868806125558206   </td></tr>\n",
       "<tr><td>3      </td><td>M        </td><td>0.002075135266529693</td><td>0.9979248647334703   </td></tr>\n",
       "<tr><td>4      </td><td>M        </td><td>0.00273858551707884 </td><td>0.9972614144829212   </td></tr>\n",
       "<tr><td>5      </td><td>B        </td><td>0.984860620822154   </td><td>0.015139379177846038 </td></tr>\n",
       "<tr><td>6      </td><td>B        </td><td>0.9741375533459156  </td><td>0.02586244665408444  </td></tr>\n",
       "<tr><td>7      </td><td>M        </td><td>0.7567958587559884  </td><td>0.24320414124401152  </td></tr>\n",
       "<tr><td>8      </td><td>B        </td><td>0.9551978574969431  </td><td>0.04480214250305695  </td></tr>\n",
       "<tr><td>9      </td><td>M        </td><td>0.005920848110712584</td><td>0.9940791518892874   </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gbm_predictions_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred= gbm_predictions_df['predict'].as_data_frame()\n",
    "y_act= test['diagnosis'].as_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e8ee332a20>"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAEFCAYAAAAG45eHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhRDCjf0/x4e6N2KD3A4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e8ee396400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "# plot training logloss and auc\n",
    "#gbm_predictions_df.plot(x='cumulative_data_fraction',y = ['cumulative_capture_rate', 'cumulative_lift'])\n",
    "deep_gain_lift.plot(x='cumulative_data_fraction',y = ['cumulative_capture_rate', 'cumulative_lift'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi4AAAGyCAYAAADDBk96AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSVIx/j9ZYDHtwFGOPQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e8ef4ce978>"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi4AAAGyCAYAAADDBk96AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSVIx/j9ZYDHtwFGOPQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e8ef4ce978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_act,y_pred)\n",
    "class_name = ['B','M']\n",
    "print_confusion_matrix(cm,class_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>concave points_mean</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.044567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>area_se</td>\n",
       "      <td>0.995237</td>\n",
       "      <td>0.995237</td>\n",
       "      <td>0.044355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>perimeter_worst</td>\n",
       "      <td>0.975117</td>\n",
       "      <td>0.975117</td>\n",
       "      <td>0.043458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>radius_worst</td>\n",
       "      <td>0.880499</td>\n",
       "      <td>0.880499</td>\n",
       "      <td>0.039241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>texture_worst</td>\n",
       "      <td>0.807974</td>\n",
       "      <td>0.807974</td>\n",
       "      <td>0.036009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0         1         2         3\n",
       "0  concave points_mean  1.000000  1.000000  0.044567\n",
       "1              area_se  0.995237  0.995237  0.044355\n",
       "2      perimeter_worst  0.975117  0.975117  0.043458\n",
       "3         radius_worst  0.880499  0.880499  0.039241\n",
       "4        texture_worst  0.807974  0.807974  0.036009"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_varimp=pd.DataFrame(mod_best.varimp())\n",
    "deep_varimp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>relative_importance</th>\n",
       "      <th>scaled_importance</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>concave points_mean</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.044567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>area_se</td>\n",
       "      <td>0.995237</td>\n",
       "      <td>0.995237</td>\n",
       "      <td>0.044355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>perimeter_worst</td>\n",
       "      <td>0.975117</td>\n",
       "      <td>0.975117</td>\n",
       "      <td>0.043458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>radius_worst</td>\n",
       "      <td>0.880499</td>\n",
       "      <td>0.880499</td>\n",
       "      <td>0.039241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>texture_worst</td>\n",
       "      <td>0.807974</td>\n",
       "      <td>0.807974</td>\n",
       "      <td>0.036009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              variable  relative_importance  scaled_importance  percentage\n",
       "0  concave points_mean             1.000000           1.000000    0.044567\n",
       "1              area_se             0.995237           0.995237    0.044355\n",
       "2      perimeter_worst             0.975117           0.975117    0.043458\n",
       "3         radius_worst             0.880499           0.880499    0.039241\n",
       "4        texture_worst             0.807974           0.807974    0.036009"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#variable\trelative_importance\tscaled_importance\tpercentage\n",
    "deep_varimp.rename(columns={0:\"variable\",1:\"relative_importance\",2:\"scaled_importance\",3:\"percentage\"}).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1e8ef5735c0>"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAFqCAYAAAATGI1bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e8ef7592e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "deep_varimp.plot.bar(x=0,y=[1])\n",
    "plt.xlabel('Variables')\n",
    "plt.ylabel('Relative_Importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extremely Randomized Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model_set=aml_leaderboard_df['model_id']\n",
    "mod_best=h2o.get_model(model_set[25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'XRT_0_AutoML_20181101_171828'"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xrt = mod_best._id\n",
    "xrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>B</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>B</td>\n",
       "<td>251.0</td>\n",
       "<td>15.0</td>\n",
       "<td>0.0564</td>\n",
       "<td> (15.0/266.0)</td></tr>\n",
       "<tr><td>M</td>\n",
       "<td>5.0</td>\n",
       "<td>137.0</td>\n",
       "<td>0.0352</td>\n",
       "<td> (5.0/142.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>256.0</td>\n",
       "<td>152.0</td>\n",
       "<td>0.049</td>\n",
       "<td> (20.0/408.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       B    M    Error    Rate\n",
       "-----  ---  ---  -------  ------------\n",
       "B      251  15   0.0564   (15.0/266.0)\n",
       "M      5    137  0.0352   (5.0/142.0)\n",
       "Total  256  152  0.049    (20.0/408.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_best.confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find exact threshold 0.0; using closest threshold found 0.0.\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>B</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>B</td>\n",
       "<td>251.0</td>\n",
       "<td>15.0</td>\n",
       "<td>0.0564</td>\n",
       "<td> (15.0/266.0)</td></tr>\n",
       "<tr><td>M</td>\n",
       "<td>5.0</td>\n",
       "<td>137.0</td>\n",
       "<td>0.0352</td>\n",
       "<td> (5.0/142.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>256.0</td>\n",
       "<td>152.0</td>\n",
       "<td>0.049</td>\n",
       "<td> (20.0/408.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       B    M    Error    Rate\n",
       "-----  ---  ---  -------  ------------\n",
       "B      251  15   0.0564   (15.0/266.0)\n",
       "M      5    137  0.0352   (5.0/142.0)\n",
       "Total  256  152  0.049    (20.0/408.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>B</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>B</td>\n",
       "<td>251.0</td>\n",
       "<td>15.0</td>\n",
       "<td>0.0564</td>\n",
       "<td> (15.0/266.0)</td></tr>\n",
       "<tr><td>M</td>\n",
       "<td>5.0</td>\n",
       "<td>137.0</td>\n",
       "<td>0.0352</td>\n",
       "<td> (5.0/142.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>256.0</td>\n",
       "<td>152.0</td>\n",
       "<td>0.049</td>\n",
       "<td> (20.0/408.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       B    M    Error    Rate\n",
       "-----  ---  ---  -------  ------------\n",
       "B      251  15   0.0564   (15.0/266.0)\n",
       "M      5    137  0.0352   (5.0/142.0)\n",
       "Total  256  152  0.049    (20.0/408.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Act/Pred) for max f0point5 @ threshold = 0.75: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>B</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>B</td>\n",
       "<td>263.0</td>\n",
       "<td>3.0</td>\n",
       "<td>0.0113</td>\n",
       "<td> (3.0/266.0)</td></tr>\n",
       "<tr><td>M</td>\n",
       "<td>22.0</td>\n",
       "<td>120.0</td>\n",
       "<td>0.1549</td>\n",
       "<td> (22.0/142.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>285.0</td>\n",
       "<td>123.0</td>\n",
       "<td>0.0613</td>\n",
       "<td> (25.0/408.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       B    M    Error    Rate\n",
       "-----  ---  ---  -------  ------------\n",
       "B      263  3    0.0113   (3.0/266.0)\n",
       "M      22   120  0.1549   (22.0/142.0)\n",
       "Total  285  123  0.0613   (25.0/408.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Act/Pred) for max accuracy @ threshold = 0.6666666666666669: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>B</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>B</td>\n",
       "<td>260.0</td>\n",
       "<td>6.0</td>\n",
       "<td>0.0226</td>\n",
       "<td> (6.0/266.0)</td></tr>\n",
       "<tr><td>M</td>\n",
       "<td>14.0</td>\n",
       "<td>128.0</td>\n",
       "<td>0.0986</td>\n",
       "<td> (14.0/142.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>274.0</td>\n",
       "<td>134.0</td>\n",
       "<td>0.049</td>\n",
       "<td> (20.0/408.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       B    M    Error    Rate\n",
       "-----  ---  ---  -------  ------------\n",
       "B      260  6    0.0226   (6.0/266.0)\n",
       "M      14   128  0.0986   (14.0/142.0)\n",
       "Total  274  134  0.049    (20.0/408.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Act/Pred) for max f0point5 @ threshold = 0.75: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>B</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>B</td>\n",
       "<td>263.0</td>\n",
       "<td>3.0</td>\n",
       "<td>0.0113</td>\n",
       "<td> (3.0/266.0)</td></tr>\n",
       "<tr><td>M</td>\n",
       "<td>22.0</td>\n",
       "<td>120.0</td>\n",
       "<td>0.1549</td>\n",
       "<td> (22.0/142.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>285.0</td>\n",
       "<td>123.0</td>\n",
       "<td>0.0613</td>\n",
       "<td> (25.0/408.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       B    M    Error    Rate\n",
       "-----  ---  ---  -------  ------------\n",
       "B      263  3    0.0113   (3.0/266.0)\n",
       "M      22   120  0.1549   (22.0/142.0)\n",
       "Total  285  123  0.0613   (25.0/408.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Act/Pred) for max recall @ threshold = 0.0: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>B</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>B</td>\n",
       "<td>0.0</td>\n",
       "<td>266.0</td>\n",
       "<td>1.0</td>\n",
       "<td> (266.0/266.0)</td></tr>\n",
       "<tr><td>M</td>\n",
       "<td>0.0</td>\n",
       "<td>142.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/142.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>0.0</td>\n",
       "<td>408.0</td>\n",
       "<td>0.652</td>\n",
       "<td> (266.0/408.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       B    M    Error    Rate\n",
       "-----  ---  ---  -------  -------------\n",
       "B      0    266  1        (266.0/266.0)\n",
       "M      0    142  0        (0.0/142.0)\n",
       "Total  0    408  0.652    (266.0/408.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Act/Pred) for max specificity @ threshold = 1.0: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>B</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>B</td>\n",
       "<td>263.0</td>\n",
       "<td>3.0</td>\n",
       "<td>0.0113</td>\n",
       "<td> (3.0/266.0)</td></tr>\n",
       "<tr><td>M</td>\n",
       "<td>25.0</td>\n",
       "<td>117.0</td>\n",
       "<td>0.1761</td>\n",
       "<td> (25.0/142.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>288.0</td>\n",
       "<td>120.0</td>\n",
       "<td>0.0686</td>\n",
       "<td> (28.0/408.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       B    M    Error    Rate\n",
       "-----  ---  ---  -------  ------------\n",
       "B      263  3    0.0113   (3.0/266.0)\n",
       "M      25   117  0.1761   (25.0/142.0)\n",
       "Total  288  120  0.0686   (28.0/408.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>B</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>B</td>\n",
       "<td>251.0</td>\n",
       "<td>15.0</td>\n",
       "<td>0.0564</td>\n",
       "<td> (15.0/266.0)</td></tr>\n",
       "<tr><td>M</td>\n",
       "<td>5.0</td>\n",
       "<td>137.0</td>\n",
       "<td>0.0352</td>\n",
       "<td> (5.0/142.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>256.0</td>\n",
       "<td>152.0</td>\n",
       "<td>0.049</td>\n",
       "<td> (20.0/408.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       B    M    Error    Rate\n",
       "-----  ---  ---  -------  ------------\n",
       "B      251  15   0.0564   (15.0/266.0)\n",
       "M      5    137  0.0352   (5.0/142.0)\n",
       "Total  256  152  0.049    (20.0/408.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Act/Pred) for max min_per_class_accuracy @ threshold = 0.5: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>B</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>B</td>\n",
       "<td>251.0</td>\n",
       "<td>15.0</td>\n",
       "<td>0.0564</td>\n",
       "<td> (15.0/266.0)</td></tr>\n",
       "<tr><td>M</td>\n",
       "<td>6.0</td>\n",
       "<td>136.0</td>\n",
       "<td>0.0423</td>\n",
       "<td> (6.0/142.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>257.0</td>\n",
       "<td>151.0</td>\n",
       "<td>0.0515</td>\n",
       "<td> (21.0/408.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       B    M    Error    Rate\n",
       "-----  ---  ---  -------  ------------\n",
       "B      251  15   0.0564   (15.0/266.0)\n",
       "M      6    136  0.0423   (6.0/142.0)\n",
       "Total  257  151  0.0515   (21.0/408.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>B</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>B</td>\n",
       "<td>251.0</td>\n",
       "<td>15.0</td>\n",
       "<td>0.0564</td>\n",
       "<td> (15.0/266.0)</td></tr>\n",
       "<tr><td>M</td>\n",
       "<td>5.0</td>\n",
       "<td>137.0</td>\n",
       "<td>0.0352</td>\n",
       "<td> (5.0/142.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>256.0</td>\n",
       "<td>152.0</td>\n",
       "<td>0.049</td>\n",
       "<td> (20.0/408.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       B    M    Error    Rate\n",
       "-----  ---  ---  -------  ------------\n",
       "B      251  15   0.0564   (15.0/266.0)\n",
       "M      5    137  0.0352   (5.0/142.0)\n",
       "Total  256  152  0.049    (20.0/408.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[, , , , , , , , , ]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_best.confusion_matrix(metrics=[\"f1\",\"f2\",\"f0point5\",\"accuracy\",\"precision\",\"recall\",\"specificity\",\"absolute_mcc\",\"min_per_class_accuracy\",\"mean_per_class_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2ORandomForestEstimator :  Distributed Random Forest\n",
      "Model Key:  XRT_0_AutoML_20181101_171828\n",
      "\n",
      "\n",
      "ModelMetricsBinomial: drf\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.03926979124983327\n",
      "RMSE: 0.19816606987532773\n",
      "LogLoss: 0.6590704091656039\n",
      "Mean Per-Class Error: 0.04580112252462132\n",
      "AUC: 0.9747961452928094\n",
      "Gini: 0.9495922905856189\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>B</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>B</td>\n",
       "<td>251.0</td>\n",
       "<td>15.0</td>\n",
       "<td>0.0564</td>\n",
       "<td> (15.0/266.0)</td></tr>\n",
       "<tr><td>M</td>\n",
       "<td>5.0</td>\n",
       "<td>137.0</td>\n",
       "<td>0.0352</td>\n",
       "<td> (5.0/142.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>256.0</td>\n",
       "<td>152.0</td>\n",
       "<td>0.049</td>\n",
       "<td> (20.0/408.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       B    M    Error    Rate\n",
       "-----  ---  ---  -------  ------------\n",
       "B      251  15   0.0564   (15.0/266.0)\n",
       "M      5    137  0.0352   (5.0/142.0)\n",
       "Total  256  152  0.049    (20.0/408.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.4</td>\n",
       "<td>0.9319728</td>\n",
       "<td>7.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.4</td>\n",
       "<td>0.9513889</td>\n",
       "<td>7.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.75</td>\n",
       "<td>0.9463722</td>\n",
       "<td>3.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.6666667</td>\n",
       "<td>0.9509804</td>\n",
       "<td>4.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.75</td>\n",
       "<td>0.9756098</td>\n",
       "<td>3.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>12.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9887218</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4</td>\n",
       "<td>0.8949922</td>\n",
       "<td>7.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.5</td>\n",
       "<td>0.9436090</td>\n",
       "<td>6.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.4</td>\n",
       "<td>0.9541989</td>\n",
       "<td>7.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.4          0.931973  7\n",
       "max f2                       0.4          0.951389  7\n",
       "max f0point5                 0.75         0.946372  3\n",
       "max accuracy                 0.666667     0.95098   4\n",
       "max precision                0.75         0.97561   3\n",
       "max recall                   0            1         12\n",
       "max specificity              1            0.988722  0\n",
       "max absolute_mcc             0.4          0.894992  7\n",
       "max min_per_class_accuracy   0.5          0.943609  6\n",
       "max mean_per_class_accuracy  0.4          0.954199  7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 35.49 %, avg score: 34.39 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.2877698</td>\n",
       "<td>1.0</td>\n",
       "<td>2.7471284</td>\n",
       "<td>2.7471284</td>\n",
       "<td>0.975</td>\n",
       "<td>1.0</td>\n",
       "<td>0.975</td>\n",
       "<td>1.0</td>\n",
       "<td>0.7905405</td>\n",
       "<td>0.7905405</td>\n",
       "<td>174.7128378</td>\n",
       "<td>174.7128378</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.3213429</td>\n",
       "<td>0.6666667</td>\n",
       "<td>2.2138031</td>\n",
       "<td>2.6914078</td>\n",
       "<td>0.7857143</td>\n",
       "<td>0.6940476</td>\n",
       "<td>0.9552239</td>\n",
       "<td>0.9680348</td>\n",
       "<td>0.0743243</td>\n",
       "<td>0.8648649</td>\n",
       "<td>121.3803089</td>\n",
       "<td>169.1407826</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.4052758</td>\n",
       "<td>0.2000000</td>\n",
       "<td>0.8050193</td>\n",
       "<td>2.3007356</td>\n",
       "<td>0.2857143</td>\n",
       "<td>0.3871429</td>\n",
       "<td>0.8165680</td>\n",
       "<td>0.8477318</td>\n",
       "<td>0.0675676</td>\n",
       "<td>0.9324324</td>\n",
       "<td>-19.4980695</td>\n",
       "<td>130.0735647</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1136116</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0403226</td>\n",
       "<td>0.0005760</td>\n",
       "<td>0.3549161</td>\n",
       "<td>0.3439077</td>\n",
       "<td>0.0675676</td>\n",
       "<td>1.0</td>\n",
       "<td>-88.6388405</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  --------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.28777                     1                  2.74713   2.74713            0.975            1            0.975                       1                   0.790541        0.790541                   174.713   174.713\n",
       "    2        0.321343                    0.666667           2.2138    2.69141            0.785714         0.694048     0.955224                    0.968035            0.0743243       0.864865                   121.38    169.141\n",
       "    3        0.405276                    0.2                0.805019  2.30074            0.285714         0.387143     0.816568                    0.847732            0.0675676       0.932432                   -19.4981  130.074\n",
       "    4        1                           0                  0.113612  1                  0.0403226        0.000576037  0.354916                    0.343908            0.0675676       1                          -88.6388  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: drf\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 0.043866561597058054\n",
      "RMSE: 0.2094434568017298\n",
      "LogLoss: 0.1387344024459384\n",
      "Mean Per-Class Error: 0.0460193281178094\n",
      "AUC: 0.9903359410952599\n",
      "Gini: 0.9806718821905198\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4444444444444444: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>B</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>B</td>\n",
       "<td>52.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0189</td>\n",
       "<td> (1.0/53.0)</td></tr>\n",
       "<tr><td>M</td>\n",
       "<td>3.0</td>\n",
       "<td>38.0</td>\n",
       "<td>0.0732</td>\n",
       "<td> (3.0/41.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>55.0</td>\n",
       "<td>39.0</td>\n",
       "<td>0.0426</td>\n",
       "<td> (4.0/94.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       B    M    Error    Rate\n",
       "-----  ---  ---  -------  ----------\n",
       "B      52   1    0.0189   (1.0/53.0)\n",
       "M      3    38   0.0732   (3.0/41.0)\n",
       "Total  55   39   0.0426   (4.0/94.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.4444444</td>\n",
       "<td>0.9500000</td>\n",
       "<td>5.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.2222222</td>\n",
       "<td>0.9478673</td>\n",
       "<td>7.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.4444444</td>\n",
       "<td>0.9644670</td>\n",
       "<td>5.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4444444</td>\n",
       "<td>0.9574468</td>\n",
       "<td>5.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.1111111</td>\n",
       "<td>1.0</td>\n",
       "<td>8.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4444444</td>\n",
       "<td>0.9138682</td>\n",
       "<td>5.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.3333333</td>\n",
       "<td>0.9433962</td>\n",
       "<td>6.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.4444444</td>\n",
       "<td>0.9539807</td>\n",
       "<td>5.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.444444     0.95      5\n",
       "max f2                       0.222222     0.947867  7\n",
       "max f0point5                 0.444444     0.964467  5\n",
       "max accuracy                 0.444444     0.957447  5\n",
       "max precision                1            1         0\n",
       "max recall                   0.111111     1         8\n",
       "max specificity              1            1         0\n",
       "max absolute_mcc             0.444444     0.913868  5\n",
       "max min_per_class_accuracy   0.333333     0.943396  6\n",
       "max mean_per_class_accuracy  0.444444     0.953981  5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 43.62 %, avg score: 40.31 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.2659574</td>\n",
       "<td>1.0</td>\n",
       "<td>2.2926829</td>\n",
       "<td>2.2926829</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.6097561</td>\n",
       "<td>0.6097561</td>\n",
       "<td>129.2682927</td>\n",
       "<td>129.2682927</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.3297872</td>\n",
       "<td>0.8888889</td>\n",
       "<td>2.2926829</td>\n",
       "<td>2.2926829</td>\n",
       "<td>1.0</td>\n",
       "<td>0.8888889</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9784946</td>\n",
       "<td>0.1463415</td>\n",
       "<td>0.7560976</td>\n",
       "<td>129.2682927</td>\n",
       "<td>129.2682927</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.4148936</td>\n",
       "<td>0.4444444</td>\n",
       "<td>2.0060976</td>\n",
       "<td>2.2338962</td>\n",
       "<td>0.875</td>\n",
       "<td>0.5694444</td>\n",
       "<td>0.9743590</td>\n",
       "<td>0.8945869</td>\n",
       "<td>0.1707317</td>\n",
       "<td>0.9268293</td>\n",
       "<td>100.6097561</td>\n",
       "<td>123.3896185</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.5</td>\n",
       "<td>0.1666667</td>\n",
       "<td>0.5731707</td>\n",
       "<td>1.9512195</td>\n",
       "<td>0.25</td>\n",
       "<td>0.2638889</td>\n",
       "<td>0.8510638</td>\n",
       "<td>0.7872340</td>\n",
       "<td>0.0487805</td>\n",
       "<td>0.9756098</td>\n",
       "<td>-42.6829268</td>\n",
       "<td>95.1219512</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0487805</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0212766</td>\n",
       "<td>0.0189125</td>\n",
       "<td>0.4361702</td>\n",
       "<td>0.4030733</td>\n",
       "<td>0.0243902</td>\n",
       "<td>1.0</td>\n",
       "<td>-95.1219512</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.265957                    1                  2.29268    2.29268            1                1          1                           1                   0.609756        0.609756                   129.268   129.268\n",
       "    2        0.329787                    0.888889           2.29268    2.29268            1                0.888889   1                           0.978495            0.146341        0.756098                   129.268   129.268\n",
       "    3        0.414894                    0.444444           2.0061     2.2339             0.875            0.569444   0.974359                    0.894587            0.170732        0.926829                   100.61    123.39\n",
       "    4        0.5                         0.166667           0.573171   1.95122            0.25             0.263889   0.851064                    0.787234            0.0487805       0.97561                    -42.6829  95.122\n",
       "    5        1                           0                  0.0487805  1                  0.0212766        0.0189125  0.43617                     0.403073            0.0243902       1                          -95.122   0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: drf\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.027812934837315333\n",
      "RMSE: 0.1667721044938731\n",
      "LogLoss: 0.24492272906853052\n",
      "Mean Per-Class Error: 0.02956395056766803\n",
      "AUC: 0.9882447503265346\n",
      "Gini: 0.9764895006530692\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5555555555555556: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>B</b></td>\n",
       "<td><b>M</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>B</td>\n",
       "<td>264.0</td>\n",
       "<td>5.0</td>\n",
       "<td>0.0186</td>\n",
       "<td> (5.0/269.0)</td></tr>\n",
       "<tr><td>M</td>\n",
       "<td>6.0</td>\n",
       "<td>142.0</td>\n",
       "<td>0.0405</td>\n",
       "<td> (6.0/148.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>270.0</td>\n",
       "<td>147.0</td>\n",
       "<td>0.0264</td>\n",
       "<td> (11.0/417.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       B    M    Error    Rate\n",
       "-----  ---  ---  -------  ------------\n",
       "B      264  5    0.0186   (5.0/269.0)\n",
       "M      6    142  0.0405   (6.0/148.0)\n",
       "Total  270  147  0.0264   (11.0/417.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.5555556</td>\n",
       "<td>0.9627119</td>\n",
       "<td>10.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.5</td>\n",
       "<td>0.9636119</td>\n",
       "<td>11.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.5833333</td>\n",
       "<td>0.9668508</td>\n",
       "<td>9.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.5555556</td>\n",
       "<td>0.9736211</td>\n",
       "<td>10.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>22.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.5555556</td>\n",
       "<td>0.9423170</td>\n",
       "<td>10.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.5</td>\n",
       "<td>0.9662162</td>\n",
       "<td>11.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.5555556</td>\n",
       "<td>0.9704360</td>\n",
       "<td>10.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.555556     0.962712  10\n",
       "max f2                       0.5          0.963612  11\n",
       "max f0point5                 0.583333     0.966851  9\n",
       "max accuracy                 0.555556     0.973621  10\n",
       "max precision                1            1         0\n",
       "max recall                   0            1         22\n",
       "max specificity              1            1         0\n",
       "max absolute_mcc             0.555556     0.942317  10\n",
       "max min_per_class_accuracy   0.5          0.966216  11\n",
       "max mean_per_class_accuracy  0.555556     0.970436  10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 35.49 %, avg score: 35.25 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.2470024</td>\n",
       "<td>1.0</td>\n",
       "<td>2.8175676</td>\n",
       "<td>2.8175676</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.6959459</td>\n",
       "<td>0.6959459</td>\n",
       "<td>181.7567568</td>\n",
       "<td>181.7567568</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.3045564</td>\n",
       "<td>0.8333333</td>\n",
       "<td>2.7001689</td>\n",
       "<td>2.7953820</td>\n",
       "<td>0.9583333</td>\n",
       "<td>0.8807870</td>\n",
       "<td>0.9921260</td>\n",
       "<td>0.9774716</td>\n",
       "<td>0.1554054</td>\n",
       "<td>0.8513514</td>\n",
       "<td>170.0168919</td>\n",
       "<td>179.5381996</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.4052758</td>\n",
       "<td>0.2222222</td>\n",
       "<td>1.2075290</td>\n",
       "<td>2.4007676</td>\n",
       "<td>0.4285714</td>\n",
       "<td>0.4828042</td>\n",
       "<td>0.8520710</td>\n",
       "<td>0.8545365</td>\n",
       "<td>0.1216216</td>\n",
       "<td>0.9729730</td>\n",
       "<td>20.7528958</td>\n",
       "<td>140.0767632</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0454446</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0161290</td>\n",
       "<td>0.0104167</td>\n",
       "<td>0.3549161</td>\n",
       "<td>0.3525180</td>\n",
       "<td>0.0270270</td>\n",
       "<td>1.0</td>\n",
       "<td>-95.4555362</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.247002                    1                  2.81757    2.81757            1                1          1                           1                   0.695946        0.695946                   181.757   181.757\n",
       "    2        0.304556                    0.833333           2.70017    2.79538            0.958333         0.880787   0.992126                    0.977472            0.155405        0.851351                   170.017   179.538\n",
       "    3        0.405276                    0.222222           1.20753    2.40077            0.428571         0.482804   0.852071                    0.854536            0.121622        0.972973                   20.7529   140.077\n",
       "    4        1                           0                  0.0454446  1                  0.016129         0.0104167  0.354916                    0.352518            0.027027        1                          -95.4555  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>mean</b></td>\n",
       "<td><b>sd</b></td>\n",
       "<td><b>cv_1_valid</b></td>\n",
       "<td><b>cv_2_valid</b></td>\n",
       "<td><b>cv_3_valid</b></td>\n",
       "<td><b>cv_4_valid</b></td>\n",
       "<td><b>cv_5_valid</b></td></tr>\n",
       "<tr><td>accuracy</td>\n",
       "<td>0.9784567</td>\n",
       "<td>0.0062673</td>\n",
       "<td>0.9642857</td>\n",
       "<td>0.9761905</td>\n",
       "<td>0.9879518</td>\n",
       "<td>0.9759036</td>\n",
       "<td>0.9879518</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.9872668</td>\n",
       "<td>0.0061133</td>\n",
       "<td>0.9926470</td>\n",
       "<td>0.9743056</td>\n",
       "<td>0.981761</td>\n",
       "<td>0.9882953</td>\n",
       "<td>0.9993252</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.0215433</td>\n",
       "<td>0.0062673</td>\n",
       "<td>0.0357143</td>\n",
       "<td>0.0238095</td>\n",
       "<td>0.0120482</td>\n",
       "<td>0.0240964</td>\n",
       "<td>0.0120482</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>1.8</td>\n",
       "<td>0.5291503</td>\n",
       "<td>3.0</td>\n",
       "<td>2.0</td>\n",
       "<td>1.0</td>\n",
       "<td>2.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>0.9652575</td>\n",
       "<td>0.0136060</td>\n",
       "<td>0.9340659</td>\n",
       "<td>0.9583333</td>\n",
       "<td>0.9931507</td>\n",
       "<td>0.9705882</td>\n",
       "<td>0.9701493</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>0.9701702</td>\n",
       "<td>0.0076204</td>\n",
       "<td>0.9577465</td>\n",
       "<td>0.9583333</td>\n",
       "<td>0.9830508</td>\n",
       "<td>0.9705882</td>\n",
       "<td>0.9811321</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>0.9754202</td>\n",
       "<td>0.0081241</td>\n",
       "<td>0.982659</td>\n",
       "<td>0.9583333</td>\n",
       "<td>0.9731544</td>\n",
       "<td>0.9705882</td>\n",
       "<td>0.9923664</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>2.874148</td>\n",
       "<td>0.2923685</td>\n",
       "<td>2.4705882</td>\n",
       "<td>3.5</td>\n",
       "<td>2.7666667</td>\n",
       "<td>2.4411764</td>\n",
       "<td>3.1923077</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>0.2446987</td>\n",
       "<td>0.1245262</td>\n",
       "<td>0.1090156</td>\n",
       "<td>0.4737836</td>\n",
       "<td>0.4440402</td>\n",
       "<td>0.1265383</td>\n",
       "<td>0.0701159</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.0363911</td>\n",
       "<td>0.0099925</td>\n",
       "<td>0.06</td>\n",
       "<td>0.0416667</td>\n",
       "<td>0.0333333</td>\n",
       "<td>0.0294118</td>\n",
       "<td>0.0175439</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.9535906</td>\n",
       "<td>0.0123333</td>\n",
       "<td>0.9293997</td>\n",
       "<td>0.9416667</td>\n",
       "<td>0.9740459</td>\n",
       "<td>0.9501801</td>\n",
       "<td>0.9726607</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.9780970</td>\n",
       "<td>0.0057202</td>\n",
       "<td>0.97</td>\n",
       "<td>0.9708334</td>\n",
       "<td>0.9833333</td>\n",
       "<td>0.97509</td>\n",
       "<td>0.9912280</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.0219030</td>\n",
       "<td>0.0057202</td>\n",
       "<td>0.03</td>\n",
       "<td>0.0291667</td>\n",
       "<td>0.0166667</td>\n",
       "<td>0.0249100</td>\n",
       "<td>0.0087719</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.0277858</td>\n",
       "<td>0.0059015</td>\n",
       "<td>0.0371197</td>\n",
       "<td>0.0297619</td>\n",
       "<td>0.0180723</td>\n",
       "<td>0.0359772</td>\n",
       "<td>0.0179979</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.9621607</td>\n",
       "<td>0.0184065</td>\n",
       "<td>0.9189189</td>\n",
       "<td>0.9583333</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9705882</td>\n",
       "<td>0.962963</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.8778732</td>\n",
       "<td>0.0238582</td>\n",
       "<td>0.8459313</td>\n",
       "<td>0.8541667</td>\n",
       "<td>0.9216981</td>\n",
       "<td>0.8512322</td>\n",
       "<td>0.9163376</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.9791176</td>\n",
       "<td>0.0123770</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9583333</td>\n",
       "<td>0.9666666</td>\n",
       "<td>0.9705882</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.1646895</td>\n",
       "<td>0.0182098</td>\n",
       "<td>0.1926648</td>\n",
       "<td>0.1725164</td>\n",
       "<td>0.1344332</td>\n",
       "<td>0.1896767</td>\n",
       "<td>0.1341563</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.9770762</td>\n",
       "<td>0.0140519</td>\n",
       "<td>0.94</td>\n",
       "<td>0.9833333</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9795919</td>\n",
       "<td>0.9824561</td></tr></table></div>"
      ],
      "text/plain": [
       "                         mean       sd          cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "-----------------------  ---------  ----------  ------------  ------------  ------------  ------------  ------------\n",
       "accuracy                 0.978457   0.00626726  0.964286      0.97619       0.987952      0.975904      0.987952\n",
       "auc                      0.987267   0.00611325  0.992647      0.974306      0.981761      0.988295      0.999325\n",
       "err                      0.0215433  0.00626726  0.0357143     0.0238095     0.0120482     0.0240964     0.0120482\n",
       "err_count                1.8        0.52915     3             2             1             2             1\n",
       "f0point5                 0.965257   0.013606    0.934066      0.958333      0.993151      0.970588      0.970149\n",
       "f1                       0.97017    0.00762043  0.957746      0.958333      0.983051      0.970588      0.981132\n",
       "f2                       0.97542    0.00812414  0.982659      0.958333      0.973154      0.970588      0.992366\n",
       "lift_top_group           2.87415    0.292368    2.47059       3.5           2.76667       2.44118       3.19231\n",
       "logloss                  0.244699   0.124526    0.109016      0.473784      0.44404       0.126538      0.0701159\n",
       "max_per_class_error      0.0363911  0.00999245  0.06          0.0416667     0.0333333     0.0294118     0.0175439\n",
       "mcc                      0.953591   0.0123333   0.9294        0.941667      0.974046      0.95018       0.972661\n",
       "mean_per_class_accuracy  0.978097   0.00572021  0.97          0.970833      0.983333      0.97509       0.991228\n",
       "mean_per_class_error     0.021903   0.00572021  0.03          0.0291667     0.0166667     0.02491       0.00877193\n",
       "mse                      0.0277858  0.00590154  0.0371197     0.0297619     0.0180723     0.0359772     0.0179979\n",
       "precision                0.962161   0.0184065   0.918919      0.958333      1             0.970588      0.962963\n",
       "r2                       0.877873   0.0238582   0.845931      0.854167      0.921698      0.851232      0.916338\n",
       "recall                   0.979118   0.012377    1             0.958333      0.966667      0.970588      1\n",
       "rmse                     0.164689   0.0182098   0.192665      0.172516      0.134433      0.189677      0.134156\n",
       "specificity              0.977076   0.0140519   0.94          0.983333      1             0.979592      0.982456"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_auc</b></td>\n",
       "<td><b>training_lift</b></td>\n",
       "<td><b>training_classification_error</b></td>\n",
       "<td><b>validation_rmse</b></td>\n",
       "<td><b>validation_logloss</b></td>\n",
       "<td><b>validation_auc</b></td>\n",
       "<td><b>validation_lift</b></td>\n",
       "<td><b>validation_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-11-01 17:18:31</td>\n",
       "<td> 1.169 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-11-01 17:18:31</td>\n",
       "<td> 1.187 sec</td>\n",
       "<td>1.0</td>\n",
       "<td>0.2348881</td>\n",
       "<td>1.9055877</td>\n",
       "<td>0.9477778</td>\n",
       "<td>2.4725593</td>\n",
       "<td>0.0551724</td>\n",
       "<td>0.3261640</td>\n",
       "<td>3.6743379</td>\n",
       "<td>0.8890934</td>\n",
       "<td>2.0575360</td>\n",
       "<td>0.1063830</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-11-01 17:18:31</td>\n",
       "<td> 1.204 sec</td>\n",
       "<td>2.0</td>\n",
       "<td>0.2710524</td>\n",
       "<td>2.4078848</td>\n",
       "<td>0.9288295</td>\n",
       "<td>2.3726885</td>\n",
       "<td>0.0734694</td>\n",
       "<td>0.2629619</td>\n",
       "<td>1.2055361</td>\n",
       "<td>0.9473079</td>\n",
       "<td>2.2926829</td>\n",
       "<td>0.1063830</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-11-01 17:18:31</td>\n",
       "<td> 1.221 sec</td>\n",
       "<td>3.0</td>\n",
       "<td>0.2281189</td>\n",
       "<td>1.4855761</td>\n",
       "<td>0.9581033</td>\n",
       "<td>2.5300607</td>\n",
       "<td>0.0551948</td>\n",
       "<td>0.2201439</td>\n",
       "<td>0.4831986</td>\n",
       "<td>0.9774505</td>\n",
       "<td>2.2926829</td>\n",
       "<td>0.0531915</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-11-01 17:18:31</td>\n",
       "<td> 1.235 sec</td>\n",
       "<td>4.0</td>\n",
       "<td>0.2288689</td>\n",
       "<td>1.3254672</td>\n",
       "<td>0.9594112</td>\n",
       "<td>2.5891161</td>\n",
       "<td>0.0542857</td>\n",
       "<td>0.2262671</td>\n",
       "<td>0.1522018</td>\n",
       "<td>0.9832029</td>\n",
       "<td>2.2926829</td>\n",
       "<td>0.0638298</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-11-01 17:18:31</td>\n",
       "<td> 1.246 sec</td>\n",
       "<td>5.0</td>\n",
       "<td>0.2301919</td>\n",
       "<td>1.4152341</td>\n",
       "<td>0.9548104</td>\n",
       "<td>2.6114041</td>\n",
       "<td>0.0531915</td>\n",
       "<td>0.2133821</td>\n",
       "<td>0.1379536</td>\n",
       "<td>0.9894156</td>\n",
       "<td>2.2926829</td>\n",
       "<td>0.0531915</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-11-01 17:18:31</td>\n",
       "<td> 1.260 sec</td>\n",
       "<td>6.0</td>\n",
       "<td>0.2285558</td>\n",
       "<td>1.1940118</td>\n",
       "<td>0.9552103</td>\n",
       "<td>2.7001689</td>\n",
       "<td>0.0634518</td>\n",
       "<td>0.2153945</td>\n",
       "<td>0.1425226</td>\n",
       "<td>0.9891855</td>\n",
       "<td>2.2926829</td>\n",
       "<td>0.0531915</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-11-01 17:18:31</td>\n",
       "<td> 1.272 sec</td>\n",
       "<td>7.0</td>\n",
       "<td>0.2094852</td>\n",
       "<td>0.8376496</td>\n",
       "<td>0.9671304</td>\n",
       "<td>2.7482831</td>\n",
       "<td>0.0548628</td>\n",
       "<td>0.2094179</td>\n",
       "<td>0.1369925</td>\n",
       "<td>0.9912563</td>\n",
       "<td>2.2926829</td>\n",
       "<td>0.0531915</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-11-01 17:18:31</td>\n",
       "<td> 1.289 sec</td>\n",
       "<td>8.0</td>\n",
       "<td>0.1997827</td>\n",
       "<td>0.7420033</td>\n",
       "<td>0.9716042</td>\n",
       "<td>2.7477105</td>\n",
       "<td>0.0443350</td>\n",
       "<td>0.2078896</td>\n",
       "<td>0.1358712</td>\n",
       "<td>0.9919466</td>\n",
       "<td>2.2926829</td>\n",
       "<td>0.0319149</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-11-01 17:18:31</td>\n",
       "<td> 1.312 sec</td>\n",
       "<td>9.0</td>\n",
       "<td>0.1981661</td>\n",
       "<td>0.6590704</td>\n",
       "<td>0.9747961</td>\n",
       "<td>2.7471284</td>\n",
       "<td>0.0490196</td>\n",
       "<td>0.2094435</td>\n",
       "<td>0.1387344</td>\n",
       "<td>0.9903359</td>\n",
       "<td>2.2926829</td>\n",
       "<td>0.0425532</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration    number_of_trees    training_rmse    training_logloss    training_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_auc    validation_lift    validation_classification_error\n",
       "--  -------------------  ----------  -----------------  ---------------  ------------------  --------------  ---------------  -------------------------------  -----------------  --------------------  ----------------  -----------------  ---------------------------------\n",
       "    2018-11-01 17:18:31  1.169 sec   0                  nan              nan                 nan             nan              nan                              nan                nan                   nan               nan                nan\n",
       "    2018-11-01 17:18:31  1.187 sec   1                  0.234888         1.90559             0.947778        2.47256          0.0551724                        0.326164           3.67434               0.889093          2.05754            0.106383\n",
       "    2018-11-01 17:18:31  1.204 sec   2                  0.271052         2.40788             0.928829        2.37269          0.0734694                        0.262962           1.20554               0.947308          2.29268            0.106383\n",
       "    2018-11-01 17:18:31  1.221 sec   3                  0.228119         1.48558             0.958103        2.53006          0.0551948                        0.220144           0.483199              0.977451          2.29268            0.0531915\n",
       "    2018-11-01 17:18:31  1.235 sec   4                  0.228869         1.32547             0.959411        2.58912          0.0542857                        0.226267           0.152202              0.983203          2.29268            0.0638298\n",
       "    2018-11-01 17:18:31  1.246 sec   5                  0.230192         1.41523             0.95481         2.6114           0.0531915                        0.213382           0.137954              0.989416          2.29268            0.0531915\n",
       "    2018-11-01 17:18:31  1.260 sec   6                  0.228556         1.19401             0.95521         2.70017          0.0634518                        0.215395           0.142523              0.989185          2.29268            0.0531915\n",
       "    2018-11-01 17:18:31  1.272 sec   7                  0.209485         0.83765             0.96713         2.74828          0.0548628                        0.209418           0.136992              0.991256          2.29268            0.0531915\n",
       "    2018-11-01 17:18:31  1.289 sec   8                  0.199783         0.742003            0.971604        2.74771          0.044335                         0.20789            0.135871              0.991947          2.29268            0.0319149\n",
       "    2018-11-01 17:18:31  1.312 sec   9                  0.198166         0.65907             0.974796        2.74713          0.0490196                        0.209443           0.138734              0.990336          2.29268            0.0425532"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>concave points_mean</td>\n",
       "<td>208.5536804</td>\n",
       "<td>1.0</td>\n",
       "<td>0.2725254</td></tr>\n",
       "<tr><td>area_worst</td>\n",
       "<td>89.2118912</td>\n",
       "<td>0.4277646</td>\n",
       "<td>0.1165767</td></tr>\n",
       "<tr><td>perimeter_worst</td>\n",
       "<td>87.7009735</td>\n",
       "<td>0.4205199</td>\n",
       "<td>0.1146023</td></tr>\n",
       "<tr><td>perimeter_mean</td>\n",
       "<td>73.3544006</td>\n",
       "<td>0.3517291</td>\n",
       "<td>0.0958551</td></tr>\n",
       "<tr><td>area_mean</td>\n",
       "<td>65.0681152</td>\n",
       "<td>0.3119970</td>\n",
       "<td>0.0850271</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>smoothness_se</td>\n",
       "<td>0.9722222</td>\n",
       "<td>0.0046617</td>\n",
       "<td>0.0012704</td></tr>\n",
       "<tr><td>symmetry_worst</td>\n",
       "<td>0.9573960</td>\n",
       "<td>0.0045906</td>\n",
       "<td>0.0012511</td></tr>\n",
       "<tr><td>fractal_dimension_worst</td>\n",
       "<td>0.6666667</td>\n",
       "<td>0.0031966</td>\n",
       "<td>0.0008712</td></tr>\n",
       "<tr><td>fractal_dimension_mean</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>fractal_dimension_se</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "variable                 relative_importance    scaled_importance      percentage\n",
       "-----------------------  ---------------------  ---------------------  ---------------------\n",
       "concave points_mean      208.55368041992188     1.0                    0.27252538443506374\n",
       "area_worst               89.2118911743164       0.42776464550847854    0.11657672446492688\n",
       "perimeter_worst          87.70097351074219      0.4205199032410106     0.11460234829335221\n",
       "perimeter_mean           73.35440063476562      0.3517291111193381     0.09585511122480087\n",
       "area_mean                65.068115234375        0.31199696453862935    0.08502709270346291\n",
       "---                      ---                    ---                    ---\n",
       "smoothness_se            0.9722222089767456     0.004661736043301565   0.0012704414073355518\n",
       "symmetry_worst           0.9573960304260254     0.004590645576229165   0.0012510674504669778\n",
       "fractal_dimension_worst  0.6666666865348816     0.0031966191399382224  0.0008711598600041469\n",
       "fractal_dimension_mean   0.0                    0.0                    0.0\n",
       "fractal_dimension_se     0.0                    0.0                    0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n",
      "<bound method ModelBase.coef_norm of >\n"
     ]
    }
   ],
   "source": [
    "mod_best._get_metrics\n",
    "type(mod_best)\n",
    "mods=mod_best.coef_norm\n",
    "print(mods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gain Lift Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'XRT_0_AutoML_20181101_171828'"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xrt_gain_lift = mod_best.gains_lift().as_data_frame()\n",
    "xrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.287770</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.747128</td>\n",
       "      <td>2.747128</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.790541</td>\n",
       "      <td>0.790541</td>\n",
       "      <td>174.712838</td>\n",
       "      <td>174.712838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0.321343</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.213803</td>\n",
       "      <td>2.691408</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.694048</td>\n",
       "      <td>0.955224</td>\n",
       "      <td>0.968035</td>\n",
       "      <td>0.074324</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>121.380309</td>\n",
       "      <td>169.140783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>0.405276</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.805019</td>\n",
       "      <td>2.300736</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.387143</td>\n",
       "      <td>0.816568</td>\n",
       "      <td>0.847732</td>\n",
       "      <td>0.067568</td>\n",
       "      <td>0.932432</td>\n",
       "      <td>-19.498069</td>\n",
       "      <td>130.073565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.113612</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.040323</td>\n",
       "      <td>0.000576</td>\n",
       "      <td>0.354916</td>\n",
       "      <td>0.343908</td>\n",
       "      <td>0.067568</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-88.638840</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0        1                  0.287770         1.000000  2.747128   \n",
       "1        2                  0.321343         0.666667  2.213803   \n",
       "2        3                  0.405276         0.200000  0.805019   \n",
       "3        4                  1.000000         0.000000  0.113612   \n",
       "\n",
       "   cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0         2.747128       0.975000  1.000000                  0.975000   \n",
       "1         2.691408       0.785714  0.694048                  0.955224   \n",
       "2         2.300736       0.285714  0.387143                  0.816568   \n",
       "3         1.000000       0.040323  0.000576                  0.354916   \n",
       "\n",
       "   cumulative_score  capture_rate  cumulative_capture_rate        gain  \\\n",
       "0          1.000000      0.790541                 0.790541  174.712838   \n",
       "1          0.968035      0.074324                 0.864865  121.380309   \n",
       "2          0.847732      0.067568                 0.932432  -19.498069   \n",
       "3          0.343908      0.067568                 1.000000  -88.638840   \n",
       "\n",
       "   cumulative_gain  \n",
       "0       174.712838  \n",
       "1       169.140783  \n",
       "2       130.073565  \n",
       "3         0.000000  "
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xrt_gain_lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drf prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "xrt_predictions_df=predictions_test(mod_best,test,run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>predict  </th><th style=\"text-align: right;\">       B</th><th style=\"text-align: right;\">       M</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>M        </td><td style=\"text-align: right;\">0.111111</td><td style=\"text-align: right;\">0.888889</td></tr>\n",
       "<tr><td>M        </td><td style=\"text-align: right;\">0       </td><td style=\"text-align: right;\">1       </td></tr>\n",
       "<tr><td>M        </td><td style=\"text-align: right;\">0       </td><td style=\"text-align: right;\">1       </td></tr>\n",
       "<tr><td>M        </td><td style=\"text-align: right;\">0       </td><td style=\"text-align: right;\">1       </td></tr>\n",
       "<tr><td>M        </td><td style=\"text-align: right;\">0       </td><td style=\"text-align: right;\">1       </td></tr>\n",
       "<tr><td>B        </td><td style=\"text-align: right;\">0.888889</td><td style=\"text-align: right;\">0.111111</td></tr>\n",
       "<tr><td>B        </td><td style=\"text-align: right;\">0.666667</td><td style=\"text-align: right;\">0.333333</td></tr>\n",
       "<tr><td>M        </td><td style=\"text-align: right;\">0.444444</td><td style=\"text-align: right;\">0.555556</td></tr>\n",
       "<tr><td>B        </td><td style=\"text-align: right;\">0.888889</td><td style=\"text-align: right;\">0.111111</td></tr>\n",
       "<tr><td>M        </td><td style=\"text-align: right;\">0       </td><td style=\"text-align: right;\">1       </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xrt_predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:58\n",
      "Cols:3\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th>predict  </th><th>B                 </th><th>M                  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>type   </td><td>enum     </td><td>real              </td><td>real               </td></tr>\n",
       "<tr><td>mins   </td><td>         </td><td>0.0               </td><td>0.0                </td></tr>\n",
       "<tr><td>mean   </td><td>         </td><td>0.5881226053639846</td><td>0.41187739463601525</td></tr>\n",
       "<tr><td>maxs   </td><td>         </td><td>1.0               </td><td>1.0                </td></tr>\n",
       "<tr><td>sigma  </td><td>         </td><td>0.431090120612793 </td><td>0.43109012061279295</td></tr>\n",
       "<tr><td>zeros  </td><td>         </td><td>16                </td><td>21                 </td></tr>\n",
       "<tr><td>missing</td><td>0        </td><td>0                 </td><td>0                  </td></tr>\n",
       "<tr><td>0      </td><td>M        </td><td>0.1111111111111111</td><td>0.8888888888888888 </td></tr>\n",
       "<tr><td>1      </td><td>M        </td><td>0.0               </td><td>1.0                </td></tr>\n",
       "<tr><td>2      </td><td>M        </td><td>0.0               </td><td>1.0                </td></tr>\n",
       "<tr><td>3      </td><td>M        </td><td>0.0               </td><td>1.0                </td></tr>\n",
       "<tr><td>4      </td><td>M        </td><td>0.0               </td><td>1.0                </td></tr>\n",
       "<tr><td>5      </td><td>B        </td><td>0.8888888888888888</td><td>0.11111111111111116</td></tr>\n",
       "<tr><td>6      </td><td>B        </td><td>0.6666666666666666</td><td>0.33333333333333337</td></tr>\n",
       "<tr><td>7      </td><td>M        </td><td>0.4444444444444444</td><td>0.5555555555555556 </td></tr>\n",
       "<tr><td>8      </td><td>B        </td><td>0.8888888888888888</td><td>0.11111111111111116</td></tr>\n",
       "<tr><td>9      </td><td>M        </td><td>0.0               </td><td>1.0                </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xrt_predictions_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred= xrt_predictions_df['predict'].as_data_frame()\n",
    "y_act= test['diagnosis'].as_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e8ef7ed828>"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEFCAYAAADkP4z+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e8ef85d080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "# plot training logloss and auc\n",
    "#gbm_predictions_df.plot(x='cumulative_data_fraction',y = ['cumulative_capture_rate', 'cumulative_lift'])\n",
    "xrt_gain_lift.plot(x='cumulative_data_fraction',y = ['cumulative_capture_rate', 'cumulative_lift'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi4AAAGyCAYAAADDBk96AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e8ef910b00>"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi4AAAGyCAYAAADDBk96AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHeVJREFUeJzt3Xm0XGWV9/Fv3ZAECBjBEdRWX4fdr3a/MgmKIFEQhUYQ\naEUZRGlEFBFkEgREaHlRRGgFBZUhNGLLLDSKIqIEB0AGB5TeDDJEEG2QeZBAbv9RJ/Y15N5bgXvO\nyXPP98OqlapTt05tWIvkl72f55ze8PAwkiRJJRhquwBJkqRBGVwkSVIxDC6SJKkYBhdJklQMg4sk\nSSqGwUWSJBVjqbYLGM//e/F67teWWvDTOV9ruwSpk5Z78St7TX7fRP45+6tbL6m9djsukiSpGEt8\nx0WSJNWn12u0wfO02XGRJEnFsOMiSVKH9Xpl9TDKqlaSJHWawUWSJBXDUZEkSR02RFmLcw0ukiR1\nmLuKJEmSamLHRZKkDhtqcFdRREwBvgYEMAzsDDwKzK5eXwvskpnzRzuHHRdJkjqs1+tN2GMAbwfI\nzDcABwCHAkcCB2TmukAP2GysExhcJElSIzLzW8BO1csXA/cCqwOXVMcuADYY6xwGF0mS1JjMfDwi\nTgaOBk4Fepm54EaPDwAzx/q8wUWSpA7rTeA/g8rM7YFX0l/vssyIt5an34UZlcFFkiQ1IiK2i4j9\nqpcPA/OBKyNiVnVsI+DSsc7hriJJkjqsyV1FwNnASRExB5gK7A5cB3wtIqZVz88c6wQGF0mSOqzJ\nC9Bl5kPAuxbx1nqDnsPgIklShw155VxJkqR6GFwkSVIxHBVJktRhvcJ6GGVVK0mSOs2OiyRJHdbk\nrqKJYHCRJKnD3FUkSZJUEzsukiR12OLcY2hJYMdFkiQVw+AiSZKK4ahIkqQOa/gmi0+bwUWSpA4r\nbTt0WTFLkiR1mh0XSZI6rLTruBhcJEnqMLdDS5Ik1cTgIkmSiuGoSJKkDittO3RZ1UqSpE6z4yJJ\nUoeVdh0Xg4skSR1W2nZoR0WSJKkYdlwkSeowr+MiSZJUE4OLJEkqhqMiSZI6zF1FkiSpGO4qkiRJ\nqokdF0mSOqy0XUUGF0mSOsx7FUmSJNXE4CJJkorhqEiSpA4rbTu0HRdJklQMOy6SJHVYaddxMbhI\nktRhpW2HdlQkSZKKYcdFkqQOK21UZMdFkiQVw+AiSZKK4ahIkqQOK+06LgYXSZI6zDUukiRJNbHj\nIklSh5V2HReDiyRJHeaoSJIkqSYGF0mSVAxHRZIkdVhp26HtuEiSpGLYcZEkqcNKW5xrcJEkqcNK\n2w7tqEiSJBXDjoskSR1W2qjIjoskSSqGHRdJkjrM7dCSJEk1seMiSVKHNbXGJSKmAicCLwGmA58G\n5gLnAzdUP3ZsZp421nkMLpIkdViDo6Jtgbszc7uIWBH4BXAIcGRmfn7QkxhcJElSE84Azqye94DH\ngdWBiIjN6Hddds/MB8Y6iWtcJEnqsN4E/jOWzHwwMx+IiOXpB5gDgCuAvTPzjcDvgIPGq9fgIkmS\nGhERLwJ+CJySmd8AzsnMq6q3zwFWHe8cBhdJklS7iHgecCHw8cw8sTr8vYhYs3q+PnDVIj88gmtc\nJEnqsKHmLuPyCWAF4MCIOLA6tgdwVETMA+4EdhrvJAYXSZI6rKldRZm5G7DbIt56w+Kcx1GRJEkq\nhh0XSZI6rLSbLBpcJEnqMO9VJEmSVBODiyRJKoajIkmSOmxonCveLmnsuEiSpGLU3nGJiOGFDt0N\nnMsAN1KSJEn1cnHuor0LWAl4IbAJsAZwZEPfrQYMDQ1x8Oc+zslnHcPsM4/m5a986V/f2/vAXXjn\nNpu2WJ3ULX++51423vr93Hzb3LZLUQGGer0JezRSbyPfAvdk5p2ZeXtmXgYcBmzV0HerAettsDYA\n22/5EY454gR23XtHVlhxJl8++XBmvWWxLooo6WmY9/jjHPqFLzF9+rS2S5Fq0dbi3Ida+l7V5IcX\n/pg5P/gZACu/4Hk8cP+DLDtjGY496iTWmbVWy9VJ3fFvXz2RLTfZiNnfPKPtUlSIwiZFzS/OjYhn\nAx8Fvt70d6teTzzxBJ/+/H7se/BufPtb3+f2uXfy619c13ZZUmecd+FFrDBzJmuvsVrbpUi1aSq4\n/GdEPBgRDwH/DawGHN3Qd6tBB+x5GG9/07Yc9Jm9WWaZpdsuR+qU8757EZdffQ077bUfedPNHPS5\no7jrz/e0XZY0oZoaFX0Q+Gn1fAVgG+BnEbFmZl7fUA2q0Sabb8jzVnoOJ3z5VB595FGGh4eZP39+\n22VJnXL8kZ/56/Od9tqP/T76YZ694gotVqQSeK+iRbsjM28c8frnEbER8AFg74ZqUI1+8N05HHLE\nvpx0+hdZaupSfPbgo/nLXx5ruyxJ0jh6hV2Ars0r5/Za/n5NoEceeZS9d/nUIt879t9mN1qLJPjq\nEYe1XYJUi6aCwwoR8fzq+TLADsDLAZe9S5LUotIuQNdUcDl9xPNHgV8CW2bmT0f5eUmS1ADXuCwk\nM8v6LyJJkpZYrjGRJKnDCmu4eHdoSZJUDoOLJEkqhqMiSZI6zMW5kiSpGKVdgM5RkSRJKoYdF0mS\nOsxRkSRJKkZhucVRkSRJKofBRZIkFcNRkSRJHVbaTRbtuEiSpGLYcZEkqcPcVSRJkopRWG5xVCRJ\nksphx0WSpA4rbVRkx0WSJBXD4CJJkorhqEiSpA4r7e7QBhdJkjrMC9BJkiTVxI6LJEkdNlRWw8Xg\nIklSlzkqkiRJqonBRZIkFcNRkSRJHVbaqMjgIklSh5W2ONdRkSRJKoYdF0mSOsxRkSRJKkZhucVR\nkSRJKofBRZIkFcNRkSRJHTZU2KzIjoskSSqGHRdJkjqsR1kdF4OLJEkdVtikyFGRJEkqhx0XSZI6\nzMW5kiRJNbHjIkmSahcRU4ETgZcA04FPA78FZgPDwLXALpk5f6zz2HGRJKnDer3ehD3GsS1wd2au\nC7wNOAY4EjigOtYDNhvvJAYXSZI6rNebuMc4zgAOXPC1wOPA6sAl1bELgA3GO4mjIkmSVLvMfBAg\nIpYHzgQOAI7IzOHqRx4AZo53HjsukiR1WIOjIiLiRcAPgVMy8xvAyPUsywP3jncOg4skSR021Ju4\nx1gi4nnAhcDHM/PE6vA1ETGrer4RcOl49ToqkiRJTfgEsAJwYEQsWOuyG/DFiJgGXEd/hDQmg4sk\nSapdZu5GP6gsbL3FOY/BRZKkDhtkbcqSxDUukiSpGHZcJEnqsMIaLgYXSZK6zJssSpIk1cSOiyRJ\nHebiXEmSpJoYXCRJUjEcFUmS1GGFTYoMLpIkdZlrXCRJkmpix0WSpA4rrOFicJEkqctKuwDduMEl\nItYE1gGOAc4HVgV2zsyzaq5NkiTpbwyyxuWLwJXAPwMPA6sB+9ZZlCRJ0qIMElyGMnMO8E/AWZk5\nF0dMkiRNCr3exD2aMEhweTgi9gTWB86PiN2AB+otS5Ik6ckGCS7bADOAzTPzHmBlYOtaq5IkSY3o\n9XoT9mjCuMElM28HLgZeExHTgW9n5u9rr0ySJNVu0o2KqtHQvwJ7AMsBX4mIveouTJIkaWGDjIre\nB7wVeCgz7wZeC+xQZ1GSJKkZk25UBDyRmY+NeP0o8ERN9UiSJI1qkOBySUQcAcyIiHcA5wE/qLcs\nSZKkJxskuOwN3AD8Engv8B3ANS6SJE0CpS3OHeRCci8ELqgeC6wM3FZLRZIkqTGT7l5FwCXAcPV8\nGvB84Br6i3QlSZIaM25wycyXjnxd3XRxl9oqkiRJjSms4TLQGpe/kZlXAKvXUIskSWpYaduhx+24\nRMQnR7zsAa8C/lhbRZIkSaMYpOPSG/EYpr/m5Z11FiVJkrQog6xxObiJQiRJUvNKW+MyanCJiPn8\n726ikXrAcGZOqa0qSZKkRRg1uGTmYi/clSRJZWlqUe1EGWRx7nOBbejfGboHTAFempnvrbk2SZJU\ns8Jyy0CLc88GVgG2BWYAmwLz6yxKkiQ1o7Tt0IMEl2dn5vbAf9IPMbOAV9dZlCRJ0qIMElzuqX5N\n4DWZeR8wtb6SJEmSFm2QexVdHBFn0L8j9IURsRrwaL1lSZKkJky6NS6ZuT+wb2beCryHfudli7oL\nkyRJWthY13G5Cjge+EZm3gSQmVcDVzdUmyRJqllp26HH6rh8jP7NFDMiTo2INzdUkyRJakivN3GP\nJox1Abo5wJyImA68A9gjIo4DTgFmZ+bcZkqUJEnqG+ReRX8BTgNOqy5GdwhwEzCt5toAuPLXZzfx\nNZIW8pUPHNd2CVIn7Xra/o1+31Bho6JBdhUREa8Atga2AuYCXjVXkqRJoLDcMubi3JWAd9O/3P9M\nYDbwVkdEkiSpLWN1XJL+lXL3zMxLGqpHkiRpVGMFlxdk5gONVSJJkho3abZDG1okSdKSZqDFuZIk\naXIqrOEy8K6iGcDLgF8Dy2bmQ7VWJUmSGtEbKiu5jHuvoohYH/glcC7wfOCWiNiw7sIkSZIWNm5w\nAf4/sA5wb2b+AVgP+FytVUmSpEaUdsn/QYLLUGbeueBFZv62xnokSZJGNcgal99HxCbAcEQ8E9gF\nuK3esiRJkp5skODyQeALwIuA3wE/AHaqsyhJktSM0q7jMshNFv8EvKeBWiRJUsMKyy3jB5eIuBkY\nXvh4Zv6fWiqSJEkaxSCjolkjnk8FNgem11KNJElq1GQcFd260KHPRcSVwKfrKUmSJDWl6dwSEWsB\nn83MWRGxKnA+cEP19rGZedpYnx9kVPTGES97wKuBZZ5ivZIkqaMiYh9gO2DBFfhXB47MzM8Peo5B\nRkUHj3g+DNwFbD/oF0iSJFVuArYATqlerw5ERGxGv+uy+3g3eR4kuJyemcc+rTIlSdKSqcFZUWae\nFREvGXHoCuD4zLwqIvYHDgL2Guscg1w5d5enXqIkSdKozsnMqxY8B1Yd7wODdFzmRsTFwOXAIwsO\nZuYhT6lESZK0xGh5V9H3ImLXzLwCWB+4arwPDBJcLhvxvKw9U5IkaUwt74b+EHB0RMwD7mSAK/OP\nGlwiYvvMPDkzDx7tZyRJkhZHZt4CvK56fjXwhsX5/FhrXHZ76mVJkqQS9IZ6E/ZowiCLcyVJkpYI\nY61xeXVE/G4Rx3vAsPcqkiRJTRsruNwIbNxUIZIkqXmF3apozODy2CLuUyRJkiaR0m6yONYal580\nVoUkSdIARu24ZOZHmixEkiQ1r7CGy0AXoJMkSZPUZBoVSZIkLVEMLpIkqRiOiiRJ6rDCJkV2XCRJ\nUjnsuEiS1GGlLc41uEiS1GWFzV4KK1eSJHWZHRdJkjqstFGRHRdJklQMg4skSSqGoyJJkjqssEmR\nwUWSpC5zjYskSVJN7LhIktRhhTVcDC6SJHVaYcnFUZEkSSqGwUWSJBXDUZEkSR3WGyprVGRwkSSp\nwwpb4uKoSJIklcOOiyRJHVbaBegMLpIkdVhhucVRkSRJKofBRZIkFcNRkSRJXVbYrMiOiyRJKoYd\nF0mSOswL0EmSpGIUNilyVCRJksphx0WSpC4rrOVix0WSJBXD4CJJkorhqEiSpA4rbFJkcJEkqctK\n2w7tqEiSJBXDjoskSR3WK2xWZHCRJKnLysotjookSVI5DC6SJKkYjookSeqw0ta42HGRJEnFsOMi\nSVKHldZxMbhIktRlhc1eCitXkiR1mR0XSZI6rLRRkR0XSZJUDIOLJEkqhqMiSZI6rLRRkcFFkqQu\nKyu3GFwkSVJzImIt4LOZOSsiXg7MBoaBa4FdMnP+WJ93jYskSR3WG+pN2GM8EbEPcDywdHXoSOCA\nzFyXfu9ns/HOYXCRJKnLer2Je4zvJmCLEa9XBy6pnl8AbDDeCQwukiSpEZl5FjBvxKFeZg5Xzx8A\nZo53DoOLJElqy8j1LMsD9473AYOLJEkd1uyk6EmuiYhZ1fONgEvH+4C7iiRJUlv2BL4WEdOA64Az\nx/uAwUWSpA5r+gJ0mXkL8Lrq+fXAeovz+dqCS0QsWGzzssz83ULv7QwcCxyamQfUVYMkSRrHANuY\nlyR1d1zmAW8HvrDQ8XfQv9iMJqF5jz/OJw85lDv+cCePPfYYO+3wPt603rptlyVNSkNThlh/5014\nxnNmMmXqUvz87B9z81U3ALDOezfg3jv+zLUXXd1yldLEqTu4zAE2ZURwiYhnAGsD19T83WrJ+d/5\nLs+cOZPDDjmI++67n3/eZnuDi1STWPcfePTBR/j+l85j+oylec/hO/KH629nw1025ZkrrcjVd1zW\ndolawnmvor91LvD5iJiZmfdVxzamv2p4Rs3frZa8dYM3s+H6bwJgeHiYKVOmtFyRNHnd+LPruPGy\n/wL6fwDNf2I+05aeyuVnzuHFq7ys5eqkiVf3dujrgFvob3FaYDPgWzV/r1q07LLLMmPGDB566CH2\n2Hd/dv3QTm2XJE1a8/4yj3mPPsbUpaex0R5bcNlpl3D/f9/HH2+8o+3SpFo0cR2Xc+mvcyEipgJv\nrY5pErvzzj+yw4d25e0bv41/etuGbZcjTWrLPWt5Nv/ktvzXnGu5/ie/absclaY3gY8GNLEd+lzg\nvIhYCngz8JvM/FNENPDVasNdd/+ZnXbdnU/svSevW3ONtsuRJrVlZs5gs/235pITv8fvr72l7XJU\nINe4PNlPgceBdeiPic5p4DvVouNPOpn773+Ar5xwEl854SQAjv3CkSy99PSWK5MmnzXesTbTZyzN\na7dYh9dusQ4A5x32TZ6Y93jLlUn1qD24ZOb8iDif/u6itwNvrPs71a599/oY++71sbbLkDrh0pO/\nz6Unf3+R711x5rhXT5foeR2XRToXOAX4XWbe3NB3SpKk8RQ2KmrqJovfpx+S3E0kSZKesto6LpnZ\nG/H8YWDZhd6fVdd3S5KkwZS2OLepjoskSdLT5t2hJUnqsrIaLnZcJElSOey4SJLUYW6HliRJ5XBx\nriRJUj3suEiS1GFuh5YkSaqJwUWSJBXDUZEkSV3mriJJklQK17hIkiTVxI6LJEldVlbDxeAiSVKX\nOSqSJEmqicFFkiQVw1GRJEldVth2aDsukiSpGHZcJEnqsNIW5xpcJEnqssKCi6MiSZJUDDsukiR1\nWGmjIjsukiSpGAYXSZJUDEdFkiR1WWHXcTG4SJLUYa5xkSRJqokdF0mSuqywjovBRZKkDusVtsbF\nUZEkSSqGwUWSJBXDUZEkSV1W2BoXOy6SJKkYdlwkSeqw0q7jYnCRJKnLCgsujookSVIx7LhIktRh\nXsdFkiSpJgYXSZJUDEdFkiR1WWGLcw0ukiR1WWHBxVGRJEkqhh0XSZI6zAvQSZKkcrgdWpIkqR4G\nF0mSVAxHRZIkdViv12wPIyKuBu6vXt6cme9fnM8bXCRJUiMiYmmgl5mznuo5DC6SJHVZs7uKXgMs\nGxEX0s8gn8jMyxbnBK5xkSSpw3q93oQ9BvAwcATwVmBn4NSIWKwmih0XSZLUlOuBGzNzGLg+Iu4G\nVgLmDnoCg4skSV3W7HVcdgD+EfhwRKwMPAP4w+KcwOAiSZKacgIwOyJ+DAwDO2Tm44tzAoOLJElq\nRGY+Bmz9dM5hcJEkqcO8V5EkSSqHwUWSJBWj4SvnPl1lVStJkjrNjoskSR3Wa3Y79NNmx0WSJBXD\n4CJJkorhqEiSpC5zV5EkSSpFaddxcVQkSZKKYcdFkqQuK+w6LgYXSZI6zO3QkiRJNTG4SJKkYjgq\nkiSpy9xVJEmSVA87LpIkdVhp13ExuEiS1GWFbYcuq1pJktRpdlwkSeoyr+MiSZJUD4OLJEkqhqMi\nSZI6zF1FkiSpHO4qkiRJqocdF0mSOsxRkSRJKoejIkmSpHoYXCRJUjEcFUmS1GE9r5wrSZJUDzsu\nkiR1mbuKJElSKXruKpIkSaqHHRdJkrqssFFRb3h4uO0aJEmSBuKoSJIkFcPgIkmSimFwkSRJxTC4\nSJKkYhhcJElSMQwukiSpGAYXSZJUDIOLJBUgIv6u7RqkJYHBRQOLiNdGxCoR8ZoRx8q65KJUoIjY\nFzgzIt7cdi1S27xyrgYSEZ8BtgSGgWWAozPz8Harkia/iJgJnAJsApwK/EdmfqfdqqT22HHRuCLi\nKGBnYDtga+BgYP+I2KTVwqQOyMz7gNPo/6XhpcC7IuJt7VYltcfgojFFxOH0A8s6mXlZZl4JnA5c\nDDwnIpZutUBpEouIIYDMPBU4AXgM+DvgXyJiwzZrk9picNGoqsWAewGHZ+a1I34TvR+YCewO/DYi\nLoiID7ZYqjQpZeb8iJhWvTwHuBw4ClgR+HBEvKW14qSWGFw0qsy8DdgY+EREvBvowV8XCq4F/Duw\nX3V854j4h7ZqlSaLiDioeqwJkJmPVW/9HFgHeBGwLbA88CHDi7rGxbkaVzVPP5v+4sC1gD2BrTPz\nwur9lYDfAztn5tdaK1QqXES8CLi1enlR9XxX4InMnBcRqwEnAu+pfuYY4C7g3zPz203XK7XBjovG\nlZnfpb+j6CLgQGDbzLwwInoRsRTwMPAz+r+BSnqKMnMusGDL813AGvT/3/poRLwqM68Gzgc2yMzr\ngH2AlwNbRcSybdQsNc2OiwYWEbPoL8rdHPhOZs6rjn8KeD/9BbxzWytQmiSq8c9Z9BfGrwK8Angj\nsAewErAjsElmzq2uq3RvZt462vmkycTgosUSERvR/w11+8w8owot+wJrV38blDQBImJj+tdv+Rfg\nSvqj2j2A8+hfnuDrwMcy85HWipRa4KhIiyUzLwC2AL4aEefTX+/yBkOLNLGqi8xtRz+gvD4zjwPe\nCdwC3A+8AZjSWoFSS+y46Cmp/jZ4PrB6Zl7Tdj3SZFV1Oc8B3puZp1fHlgOenZm3tFmb1AaDi56y\niFg2Mx9uuw5psqt29p0OfBg4IzP/0nJJUmsMLpJUgIjYFDgOiMx8oO16pLYYXCSpEBGxXGY+2HYd\nUpsMLpIkqRjuKpIkScUwuEiSpGIYXCRJUjEMLpIkqRhLtV2A1DUR8RLgeuC3wDAwDbgDeH9m/v4p\nnvN9wKzMfF9EfAfYMTPvGOVnDwYuysxLF+P8w5nZG/H6GcDtwN9n5u0jjq8HHJWZqw16LklaHHZc\npHbckZmrZOaqmflq+veiOXoiTpyZG48WWirr8TQvFZ+Z99O/muu7F3rrvcCJT+fckjQWOy7SkmEO\nsClARNwCXE7/rsDrAm8Ddqf/F42rgF0y89GI2A44gP59a24FHhzx+VnAncCXgHWAecC/AtOBNYDj\nI2Jz4BHgWOBZwMPArpl5TdUV+jqwHHDZKDWfCHy+ehARS9O/EeBe1etDgfWBFYG7gC0y884FH65u\n0ElmfmqhuucCn6ueTwFmZ+ZREfFC4FRgBjAf+GhmjlabpEnKjovUsoiYCmwF/GTE4QsyM4DnAB+g\nf/ftVYA/AXtFxMrA4cAbgdcDyy/i1LvSDx7/F9gA+CTwTfrdnR0z89fAycA+1Whnp+p9gGPoB4ZV\nFqprpEuAZ0ZEVK/fAVycmfdExMuBv6/qfiVwI7DNgP9JPgBQ1bQmsFlErEv/LsnnZ+YawD70A5mk\njrHjIrVj5Yj4RfV8OnAFsO+I9y+vfn0T8ArgsiofTAOuBtYGfpqZfwSIiK/T726MtB7w1cycT7/7\n8urqZ6l+XQ54LXDS/2YPlouIZ9HvdrynOnYqcMLC/wKZORwRs4GtgYPo38n4qOq9GyNiT2DHKti8\nHrhpoP8y/ZC1SkS8eUFNwD8CFwFnR8SqwLfphytJHWNwkdpxR9XNGM0j1a9TgNMz86Pw17CxFP2Q\nMrJj+vgizjFv5IuqC3LbiENTgEdH1lGNY/5Mf9HwgvMP0x/NLMrJwIUR8WUggB9U51kd+A/gSOBM\n4Alg4QW5I78DYOqIuvbJzLOrcz0beCgzH4mIV9EfR20FvA94yyh1SZqkHBVJS7YfAZtHxHMjokd/\nPcruwI+B10XECyJiiP4f5AubA7wrInoR8Vz6o53p9EPOUpl5H3BDRGwLEBFvqT4D/e7GttXzLarP\nPUlm3kY/DB0CnJKZC+4hsh7wo8w8jv7uqQ158oLgu4BXVd+9JrBSdfxi4AMRMbUKaj8G1oqIw4Ht\nMvNk4CPAqDuXJE1eBhdpCZaZvwQOpv+H+W/o/z/7mWpEtCv9gHEF/QW6C/sy8BDwy+rndq3uKvxd\n4LiIWJv+upMdI+JXwGHAVlX4+AiwZXV8Y2CsuxGfRH/9yewRx04DXlN9/mLgV8BLF/rcN4FnRcRv\nq3+Xa6rjxwE3VK+vBE7KzB/R33W1ZTViOwf40Bg1SZqkvMmiJEkqhh0XSZJUDIOLJEkqhsFFkiQV\nw+AiSZKKYXCRJEnFMLhIkqRiGFwkSVIxDC6SJKkY/wOigwhc4dI6gQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e8ef910b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_act,y_pred)\n",
    "class_name = ['B','M']\n",
    "print_confusion_matrix(cm,class_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Variable Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>concave points_mean</td>\n",
       "      <td>208.553680</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.272525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>area_worst</td>\n",
       "      <td>89.211891</td>\n",
       "      <td>0.427765</td>\n",
       "      <td>0.116577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>perimeter_worst</td>\n",
       "      <td>87.700974</td>\n",
       "      <td>0.420520</td>\n",
       "      <td>0.114602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>perimeter_mean</td>\n",
       "      <td>73.354401</td>\n",
       "      <td>0.351729</td>\n",
       "      <td>0.095855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>area_mean</td>\n",
       "      <td>65.068115</td>\n",
       "      <td>0.311997</td>\n",
       "      <td>0.085027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0           1         2         3\n",
       "0  concave points_mean  208.553680  1.000000  0.272525\n",
       "1           area_worst   89.211891  0.427765  0.116577\n",
       "2      perimeter_worst   87.700974  0.420520  0.114602\n",
       "3       perimeter_mean   73.354401  0.351729  0.095855\n",
       "4            area_mean   65.068115  0.311997  0.085027"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xrt_varimp=pd.DataFrame(mod_best.varimp())\n",
    "xrt_varimp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>relative_importance</th>\n",
       "      <th>scaled_importance</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>concave points_mean</td>\n",
       "      <td>208.553680</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.272525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>area_worst</td>\n",
       "      <td>89.211891</td>\n",
       "      <td>0.427765</td>\n",
       "      <td>0.116577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>perimeter_worst</td>\n",
       "      <td>87.700974</td>\n",
       "      <td>0.420520</td>\n",
       "      <td>0.114602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>perimeter_mean</td>\n",
       "      <td>73.354401</td>\n",
       "      <td>0.351729</td>\n",
       "      <td>0.095855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>area_mean</td>\n",
       "      <td>65.068115</td>\n",
       "      <td>0.311997</td>\n",
       "      <td>0.085027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              variable  relative_importance  scaled_importance  percentage\n",
       "0  concave points_mean           208.553680           1.000000    0.272525\n",
       "1           area_worst            89.211891           0.427765    0.116577\n",
       "2      perimeter_worst            87.700974           0.420520    0.114602\n",
       "3       perimeter_mean            73.354401           0.351729    0.095855\n",
       "4            area_mean            65.068115           0.311997    0.085027"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#variable\trelative_importance\tscaled_importance\tpercentage\n",
    "xrt_varimp.rename(columns={0:\"variable\",1:\"relative_importance\",2:\"scaled_importance\",3:\"percentage\"}).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1e8efb58a58>"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAFqCAYAAAD4LzZYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMQAgyQtXYUFeF/1UsAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e8ef9f9358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xrt_varimp.plot.bar(x=0,y=[1])\n",
    "plt.xlabel('Variables')\n",
    "plt.ylabel('Relative_Importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
